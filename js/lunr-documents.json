[{
    "id": "0",
    "type": "tool",
    "title": "Toolbox - API Developer Weekly Newsletter",
    "url": "https://apihandyman.io/toolbox/api-developer-weekly-newsletter/",
    "banner": "https://apihandyman.io/images/toolbox/api-developer-weekly-newsletter/banner.png",
    "description": "Hundreds if not thousand of websites talk about APIs, I rely on James Higginbotham’s newsletter to stay up to date about what is happening in the API space thanks to his weekly selection of great posts.",
    "body": "Hundreds if not thousand of websites talk about APIs, I rely on James Higginbotham’s newsletter to stay up to date about what is happening in the API space thanks to his weekly selection of great posts.The API Developer Weekly is a weekly newsletter hyper-focused on the business, design, development, and deployment of APIs for web and mobile apps."
},{
    "id": "1",
    "type": "tool",
    "title": "Toolbox - API Evangelist",
    "url": "https://apihandyman.io/toolbox/apievangelist/",
    "banner": "https://apihandyman.io/images/toolbox/apievangelist/banner.png",
    "description": "API Handyman wouldn’t exist without the API Evangelist. It’s always a pleasure to read Kin Lane’s views on the API space. This site is a hyper-mega-huge source of information about ALL aspects of APIs from API definitions to monetization and governance and dozens of other topics.",
    "body": "API Handyman wouldn’t exist without the API Evangelist. It’s always a pleasure to read Kin Lane’s views on the API space. This site is a hyper-mega-huge source of information about ALL aspects of APIs from API definitions to monetization and governance and dozens of other topics.API Evangelist is a site dedicated to the technology, business, and politics of APIs. Beginning as a research site studying many different types of APIs, and then evolving towards developing an understanding of the common building blocks API providers are using across the API lifecycle."
},{
    "id": "2",
    "type": "tool",
    "title": "Toolbox - API Stylebook",
    "url": "https://apihandyman.io/toolbox/apistylebook/",
    "banner": "https://apihandyman.io/images/projects/apistylebook-1280-400.png",
    "description": "I started this project with a simple API Design Guidelines list in mind and ended with a fully analyzed collection of API design guidelines. I created it for others but I use it myself too. When I wonder how to handle some API design matters, I select the related topic and read how others handle it. To be honest, it needs some refresh, it is a real pain to update and maintain and could be more user friendly; that’s on my todo list.",
    "body": "I started this project with a simple API Design Guidelines list in mind and ended with a fully analyzed collection of API design guidelines. I created it for others but I use it myself too. When I wonder how to handle some API design matters, I select the related topic and read how others handle it. To be honest, it needs some refresh, it is a real pain to update and maintain and could be more user friendly; that’s on my todo list. The API Stylebook aims to help API Designers find answers to API design questions and build their own API design guidelines by providing quick and easy access to categorized and analyzed API Design Guidelines."
},{
    "id": "3",
    "type": "tool",
    "title": "Toolbox - Github Actions",
    "url": "https://apihandyman.io/toolbox/github-actions/",
    "banner": "https://apihandyman.io/images/toolbox/github-actions/banner.png",
    "description": "Github Actions allows to create workflows right in your Github repositories. I use them to manage the apihandyman.io blog build and (scheduled) publication.",
    "body": "Github Actions allows to create workflows right in your Github repositories. I use them to manage the apihandyman.io blog build and (scheduled) publication."
},{
    "id": "4",
    "type": "tool",
    "title": "Toolbox - JQ",
    "url": "https://apihandyman.io/toolbox/jq/",
    "banner": "https://apihandyman.io/images/toolbox/jq/banner.png",
    "description": "Ever wanted to quickly find, extract or modify data coming from some JSON documents on the command line? JQ is the tool you’re looking for. I use it every time I need to tranform, modify or extract some properties from an API’s response or analyze OpenAPI specification JSON files during my API reviews.",
    "body": "Ever wanted to quickly find, extract or modify data coming from some JSON documents on the command line? JQ is the tool you’re looking for. I use it every time I need to tranform, modify or extract some properties from an API’s response or analyze OpenAPI specification JSON files during my API reviews.JQ is like sed for JSON data - you can use it to slice and filter and map and transform structured data with the same ease that sed, awk, grep and friends let you play with text."
},{
    "id": "5",
    "type": "tool",
    "title": "Toolbox - Jekyll",
    "url": "https://apihandyman.io/toolbox/jekyll/",
    "banner": "https://apihandyman.io/images/toolbox/jekyll/banner.png",
    "description": "Jekyll is a static site generator powered by Ruby, Markdown and Liquid that I use the the apihandyman.io blog and the apistylebook.com website.",
    "body": "Jekyll is a static site generator powered by Ruby, Markdown and Liquid that I use the the apihandyman.io blog and the apistylebook.com website."
},{
    "id": "6",
    "type": "tool",
    "title": "Toolbox - Net API Events",
    "url": "https://apihandyman.io/toolbox/net-api-events/",
    "banner": "https://apihandyman.io/images/toolbox/net-api-events/banner.png",
    "description": "Thanks to Matthew Reinbold’s Net API events, I stay up to date regarding upcoming API related conferences.",
    "body": "Thanks to Matthew Reinbold’s Net API events, I stay up to date regarding upcoming API related conferences. The Latest Upcoming, In-Person API Events. Events are culled from Twitter hearsay, select Meetup.com groups, and/or directly from kind individuals looking to grow their community. Have something not listed here? Submit an event!"
},{
    "id": "7",
    "type": "tool",
    "title": "Toolbox - Net API Notes Newsletter",
    "url": "https://apihandyman.io/toolbox/net-api-notes-newsletter/",
    "banner": "https://apihandyman.io/images/toolbox/net-api-notes-newsletter/banner.png",
    "description": "I always read Matthew Reinbold’s Net API Notes Newsletter with delight. It’s not just a bunck of links; every week Matthew actually writes a letter in which he shares his thoughts accompanied with links to relevant posts of the past week.",
    "body": "I always read Matthew Reinbold’s Net API Notes Newsletter with delight. It’s not just a bunck of links; every week Matthew actually writes a letter in which he shares his thoughts accompanied with links to relevant posts of the past week.Keeping up with every single API tidbit and microservice dalliance that pops up on the web can be time consuming. Net API Notes, an email newsletter from the curator of NetAPI.events, is a semi-regular digest of only the must-have insights."
},{
    "id": "8",
    "type": "tool",
    "title": "Toolbox - Newman",
    "url": "https://apihandyman.io/toolbox/newman/",
    "banner": "https://apihandyman.io/images/toolbox/newman/banner.png",
    "description": "Newman is the command line counter part of Postman. I use it to run Postman’s collection in the terminal, especially to batch API calls based on CSV data.",
    "body": "Newman is the command line counter part of Postman. I use it to run Postman’s collection in the terminal, especially to batch API calls based on CSV data."
},{
    "id": "9",
    "type": "tool",
    "title": "Toolbox - OpenAPI Map",
    "url": "https://apihandyman.io/toolbox/openapi-map/",
    "banner": "https://apihandyman.io/images/projects/openapimap-1280-400.png",
    "description": "I built the OpenAPI map because I was constantly searching for “how do this with the OpenAPI spec” and also “but where is that thing” in the specification. Having the OpenAPI specification represented as a tree given essential information and quick access to source documentation of each element saved me countless time.",
    "body": "I built the OpenAPI map because I was constantly searching for “how do this with the OpenAPI spec” and also “but where is that thing” in the specification. Having the OpenAPI specification represented as a tree given essential information and quick access to source documentation of each element saved me countless time.The OpenAPI map helps people find their way in the OpenAPI Specification. It provides a simple view of the specification and an easy access to the documentation of all of its elements."
},{
    "id": "10",
    "type": "tool",
    "title": "Toolbox - OpenAPI Specification",
    "url": "https://apihandyman.io/toolbox/openapi-specification/",
    "banner": "https://apihandyman.io/images/toolbox/openapi-specification/banner.png",
    "description": "Without the OpenAPI Specification (fka. Swagger Specification), my job would be a total nightmare. It is a machine readable API description format that I use when I design APIs, when reviewing API designs, documentating APIs, checking that implementation conforms to design and build implementation.",
    "body": "Without the OpenAPI Specification (fka. Swagger Specification), my job would be a total nightmare. It is a machine readable API description format that I use when I design APIs, when reviewing API designs, documentating APIs, checking that implementation conforms to design and build implementation."
},{
    "id": "11",
    "type": "tool",
    "title": "Toolbox - Postman",
    "url": "https://apihandyman.io/toolbox/postman/",
    "banner": "https://apihandyman.io/images/toolbox/postman/banner.png",
    "description": "I use Postman to do API call when I learn to use a new API. It’s also very powerful and convenient to document API, I try to always have a Postman collection in the code repositories of the APIs I build. It’s runner feature is incredibly useful to batch API calls with data coming from CSV files.",
    "body": "I use Postman to do API call when I learn to use a new API. It’s also very powerful and convenient to document API, I try to always have a Postman collection in the code repositories of the APIs I build. It’s runner feature is incredibly useful to batch API calls with data coming from CSV files."
},{
    "id": "12",
    "type": "tool",
    "title": "Toolbox - Spectral",
    "url": "https://apihandyman.io/toolbox/spectral/",
    "banner": "https://apihandyman.io/images/toolbox/spectral/banner.png",
    "description": "I use Spectral while designing APIs and during API design reviews. It is a JSON/YAML linter with built-in support for OpenAPI 2 and 3 (and also AsyncAPI). I use it to check that API designs conform to my guidelines and also to spot unusual design patterns that needs to be discussed with the people in charge of the API. It really speeds up my reviews and help me avoid oversights.",
    "body": "I use Spectral while designing APIs and during API design reviews. It is a JSON/YAML linter with built-in support for OpenAPI 2 and 3 (and also AsyncAPI). I use it to check that API designs conform to my guidelines and also to spot unusual design patterns that needs to be discussed with the people in charge of the API. It really speeds up my reviews and help me avoid oversights."
},{
    "id": "13",
    "type": "tool",
    "title": "Toolbox - Studio",
    "url": "https://apihandyman.io/toolbox/studio/",
    "banner": "https://apihandyman.io/images/toolbox/studio/banner.png",
    "description": "I use Spectral while designing APIs and during API design reviews. It is API an design UI that supports OpenAPI 2 and 3. It comes with a totally awesome Spectral (OpenAPI linter) integration. The UI does not cover all features of the OpenAPI formats, but it’s not a problem for most users: this is the most complete and the best tool of his kind. And I love being able to switch between UI and code views (this also helps to do what you can’t do with the UI).",
    "body": "I use Spectral while designing APIs and during API design reviews. It is API an design UI that supports OpenAPI 2 and 3. It comes with a totally awesome Spectral (OpenAPI linter) integration. The UI does not cover all features of the OpenAPI formats, but it’s not a problem for most users: this is the most complete and the best tool of his kind. And I love being able to switch between UI and code views (this also helps to do what you can’t do with the UI)."
},{
    "id": "14",
    "type": "tool",
    "title": "Toolbox - Technology Radar",
    "url": "https://apihandyman.io/toolbox/thoughtworks-technology-radar/",
    "banner": "https://apihandyman.io/images/toolbox/thoughtworks-technology-radar/banner.png",
    "description": "Thoughtworks is a quite famous software consultancy company, brilliant minds such as Martin Fowler are working there. Every 6 months, they publish their Technology Radar that I enjoy reading to discover new trends, techniques and tools and also to confront my own views to theirs about topics I’m already aware of.",
    "body": "Thoughtworks is a quite famous software consultancy company, brilliant minds such as Martin Fowler are working there.Every 6 months, they publish their Technology Radar that I enjoy reading to discover new trends, techniques and tools and also to confront my own views to theirs about topics I’m already aware of.  The Radar is a document that sets out the changes that we think are currently interesting in software development - things in motion that we think you should pay attention to and consider using in your projects. It reflects the idiosyncratic opinion of a bunch of senior technologists and is based on our day-to-day work and experiences. While we think this is interesting, it shouldn’t be taken as a deep market analysis."
},{
    "id": "15",
    "type": "tool",
    "title": "Toolbox - Web Concepts",
    "url": "https://apihandyman.io/toolbox/webconcepts/",
    "banner": "https://apihandyman.io/images/toolbox/webconcepts/banner.png",
    "description": "If you wonder what means a 418 HTTP status code or which RFC defines the txn JWT claim, Web concepts is what you’re looking for. I just stopped doing HTTP/web/RFC related search, I now always check Erik Wilde’s web concepts first and usually find what I’m looking for instantly. Icing on the cake, all data is also available in JSON format.",
    "body": "If you wonder what means a 418 HTTP status code or which RFC defines the txn JWT claim, Web concepts is what you’re looking for. I just stopped doing HTTP/web/RFC related search, I now always check Erik Wilde’s web concepts first and usually find what I’m looking for instantly. Icing on the cake, all data is also available in JSON format.The Web’s Uniform Interface is based on a large and growing set of specifications. These specifications establish the shared concepts that providers and consumers of Web services can rely on. Web Concepts is providing an overview of these concepts and of the specifications defining them."
},{
    "id": "16",
    "type": "post",
    "title": "Surviving my first (recorded) live coding session Series - Part 2 - Preparing session content and realizing it's not working well",
    "url": "https://apihandyman.io/preparing-session-content-and-realizing-its-not-working-well/",
    "banner": "https://apihandyman.io/images/preparing-session-content-and-realizing-its-not-working-well/banner.jpg",
    "description": "Second post about my first ever (recorded) live coding session. So, here I was in my previous post: ready to record myself coding and talking without any slides… But I didn’t told the whole story, I actually struggled a lot before actually being able to record myself coding and talking. In the beginning, I had planned to do far more stuff and differently than what people had seen. In this post, I’ll talk about how I prepared content and realized that it was not working well.",
    "body": "Second post about my first ever (recorded) live coding session.So, here I was in my previous post: ready to record myself coding and talking without any slides…But I didn’t told the whole story, I actually struggled a lot before actually being able to record myself coding and talking.In the beginning, I had planned to do far more stuff and differently than what people had seen.In this post, I’ll talk about how I prepared content and realized that it was not working well.      Surviving my first (recorded) live coding session Series                      I did my first ever (recorded) live coding session at the Manning API confernce.It was about the OpenAPI Specification, how to use it efficiently when designing and documenting API.The idea was to write an OpenAPI Specification document and show the spec basic to advanced features, tips and tricks and use a few tools around all that.This post series aim to share all what I’ve learned preparing this session.Spoiler alert!You can get all VS Code stuff explained in this series in my supercharged-openapi github repository.It is the one that I actually used during the session.Note that I’ll soon start an OpenAPI Tips &amp; Trick series including this session contents and a few other things I couldn’t show during this session.                                                      1 - Setting up everything to record myself coding and talking                                      2 - Preparing session content and realizing it's not working well                                                                                                        3 - Slide deck like live coding with titles and speaker's notes using OBS and VS Code (coming soon)                                                          4 - Live coding at light speed with VS Code (coming soon)                                                          5 - Improving live coding session tuning and rehearsing with VS Code (coming soon)                              Preparing content almost as usualI actually worked on the content before tinkering with OBS, VS Code and all other stuff.I treated this session’s content almost like I usually do for my regular slides-based talks.Usually, I list the topics I want to talk about and then sort them in order to tell a story with a beginning and an end.I go deeper into the story by writing a detailed table of content.Then I write my full speech exactly as I will say it.It need to be precise because (Fr)English is a second language for me and I want to avoid stumble on words.After that, I do the slides using a (pop culture) theme that usually had popped in my mind while working on topics, toc or speech.Here, the topics were the OpenAPI Specification features and tools I wanted to show.Building the story was made first by organizing the features in two categories: interface contract features and documentation features.Then in each category, I sorted the features from simple/beginner to complex/advanced.I added some extra entries in both categories to showcase various tools. With that, I had my table of content.Then instead of writing my speech, I wrote an OpenAPI file adding each feature one by one.I had to think about an example. I wanted to keep things simple in order to have a simple CRUD API, but as always I added some pop culture reference … and ended with the Masters of the Universe API, an API providing information about characters and toys from the franchise.The OpenAPI file did not came right at first try, I had to rework it several times.I improved it while working the “how to show that”, but it was more complicated than expected.Indeed, my original plan for “how to show that” had not worked well.Too much, too complicated, a bit off topicThe plan was to write the OpenAPI document using Stoplight Studio, not for its GUI feature that allows to NOT write OpenAPI code (and that I use everyday).            But because it provides a cool renderer that updates itself smartly as you write code.Indeed when using renderers such as Redoc or Swagger UI, even embedded in VS Code (using the really good 42 Crunch OpenAPI Editor extension), the experience is not so good.For instance in Swagger UI, if you had opened an operation and selected the schema panel, modify something and the page is reloaded, still on the operation but you’ll have to re-switch to schema panel yourself.There’s no such problem in Studio.I also wanted to show how the API I was designing would work.            Studio comes with an embedded mock server powered by Stoplight Prism.Prism is quite cool, feed it an OpenAPI file and it will magically generate a (basic) API mock server simulating the API described in the OpenAPI file.The idea was to call this mocked API in Postman one of the best API GUI playground out there.I made a few test, writing code in Studio, importing the created OpenAPI file in Postman so it generated a ready to use collection targeting the Prism mock.Mostly to showcase various ways of using an OpenAPI document.While all those tools are great and all this actually worked … it was too long, too complicated to switch between tools.And on top of that, my research for the best zoom level to use in order to keep code readable ended with being unable to have both code and rendering visible in Studio.All that actually helped me realized that I was probably also going a bit off topic in the way of presenting things.Focusing on the real topicWhat I wanted to show was more the OpenAPI Specification itself and its inner possibilities rather than showing tools using it just to show them using it.I needed to focus on the real topic of the session and do that efficiently using tools only to showcase the features I was using.So, that’s why I chose to  Use only VS Code, showing only OpenAPI code most of the time without anything else  Show rendering with Redoc or Swagger UI only when actually needed (using 42 Crunch OpenAPI Editor extension)  Use Stoplight Prism and httpie in VS Code embedded terminal only to illustrate OpenAPI features I was actually using with dummy API callsThat way I was able to do everything inside VS Code with a clean (but stylish, see previous post) interface focusing on code.            Being able to open two terminals side by side revealed to be convenient when comparing API calls result to talk about inconsistencies.            Still not working well and terrible new ideaBut even taking those decisions, it was still hard to deliver the session smoothly and in the given time frame.There was still probably too much content.Also, it was taking me an awfully long time to type everything or do copy/paste and fix indentation.I was struggling to switch between writing code and going to the terminal.I realized that I was often forgetting things to do or not doing them the right way.During a rehearsal that was starting very well, I lost all my means because I forget to do a modification and so was totally puzzled, not understanding at all why it was not working suddenly.It was not going well and as it was difficult to work on specific sections of the sessions to train myself or improve the content, I was starting to loose my temper and my confidence.And as if I didn’t have enough problems, I had a terrible new idea.I was really missing having titles like on my slides.I feared attendees would be lost without visual indication about what was happening.I decided to do something about that.In the next posts, I’ll explain how I solved all those problems."
},{
    "id": "17",
    "type": "post",
    "title": "Surviving my first (recorded) live coding session Series - Part 1 - Setting up everything to record myself coding and talking",
    "url": "https://apihandyman.io/setting-up-everything-to-record-myself-coding-and-talking/",
    "banner": "https://apihandyman.io/images/setting-up-everything-to-record-myself-coding-and-talking/banner.jpg",
    "description": "I did my first ever (recorded) live coding session at the Manning API conference. During 30 minutes I talked and coded … without any slides; that was totally new to me. While it started well, preparing and recording this session turned out to be quite complicated. At some moment, I was totally desperate and I thought I wasn’t going to make it. But I did it and learned a lot of stuff that deserves to be shared. In this first post, I’ll talk about how “it started well”: setting up OBS, mic, cam and VS Code to record myself speaking and coding.",
    "body": "I did my first ever (recorded) live coding session at the Manning API conference.During 30 minutes I talked and coded … without any slides; that was totally new to me.While it started well, preparing and recording this session turned out to be quite complicated.At some moment, I was totally desperate and I thought I wasn’t going to make it.But I did it and learned a lot of stuff that deserves to be shared.In this first post, I’ll talk about how “it started well”: setting up OBS, mic, cam and VS Code to record myself speaking and coding.      Surviving my first (recorded) live coding session Series                      I did my first ever (recorded) live coding session at the Manning API confernce.It was about the OpenAPI Specification, how to use it efficiently when designing and documenting API.The idea was to write an OpenAPI Specification document and show the spec basic to advanced features, tips and tricks and use a few tools around all that.This post series aim to share all what I’ve learned preparing this session.Spoiler alert!You can get all VS Code stuff explained in this series in my supercharged-openapi github repository.It is the one that I actually used during the session.Note that I’ll soon start an OpenAPI Tips &amp; Trick series including this session contents and a few other things I couldn’t show during this session.                                                      1 - Setting up everything to record myself coding and talking                                      2 - Preparing session content and realizing it's not working well                                                                                                        3 - Slide deck like live coding with titles and speaker's notes using OBS and VS Code (coming soon)                                                          4 - Live coding at light speed with VS Code (coming soon)                                                          5 - Improving live coding session tuning and rehearsing with VS Code (coming soon)                              Discovering OBS StudioManning recommended using OBS Studio to record the session.It is a free and open source software for video recording and live streaming.It comes out of the box with many features that will be enough to start but it can be easily extended with plugins for powerusers.Besides being used to stream or record a video, OBS can also be used as a virtual camera in tools such as Zoom ou Teams for instance.Note that a company called Streamlabs does a fork of OBS, called Streamlabs OBS, adding some features but apparently also adding some CPU usage (I did not verify it myself though).I already tinkered with OBS briefly a few month ago but did not do much with it.With this session to record, I could put my hands on it more seriously and I was quite impressed.            Scenes and sourcesYou can create various scenes, each one showing different sources such as your webcam (or any other camera plugged to your computer), static text or images, browser window and display capture. You can place and size each item as you wish.In a matter of seconds I was able to create a few scenes mixing display capture cropped on specific windows, image, text and my webcam.For this session, Manning provided me a PNG image with 3 black (transparent) zones, my cam going on the top right zone and what I want to show on the big left one as you can see in the capture above.The image, “Manning front” in sources, is above the “Camera” (MBP webcam) and “MacbookDisplay” sources, that way nothing overflows outside of the reserved spaces.Automatic Advanced scene switchingThough I didn’t keep that in the final version of my session, I tested using multiple scenes.When handling multiple scenes, you can switch from one to another using keyboard shortcuts, but you can also use automatic switching (in menu bar choose Tools → Automatic Scene Switcher).It allows to switch to a scene based on active window title.It’s really impressive, you feel like a TV show director AND a magician doing so!While testing the standard Automatic Scene Switcher, I was a little bit annoyed by some limitations especially one regarding its activation.Indeed, you have to not forget to start it before starting a recording.Hopefully, everything was solved once I found the Advanced Scene Switcher plugin.This one propose more powerful features but also a simple one: “start advanced scene switch when recording/streaming starts”.Reusable group of sourcesAlso because I tested using multiple scenes reusing the same sources (foreground image and webcam), I created a folder containing both of them.That way I could reuse them across various scene being sure they were always placed and sized in the same way.Audio mixerLast but not least, the audio mixer allows to capture audio from different sources and set volume for each one (like any mixer).Icing on the cake, OBS allow to add some audio filters on any audio source, just hit the ⚙️ icon on the audio source to open the filters configuration.And for those who regularly use some DAWs, know you can even use VST plugins.Sounding betterSpeaking of audio, I did a few recording test While tinkering with OBS and realized that my sound was just terrible.Trying OBS noise suppressionI’m using a 16” MacBook Pro (MBP) and when using a second screen and some CPU consuming apps its fans start to make some noise.This background noise was clearly audible on the recording.I gave a try to the OBS noise suppression audio filter, it actually suppressed the fan noise but I had some strange sound variation and distortion when it was activated.To make it short: my audio sucked.Choosing a new micAs I wanted to buy a decent mic for a long time for future audio/video projects, it didn’t took me long to decide to buy one.Manning recommended the very reasonably priced Audio Technica AT2005USB and I also asked my Twitter friends and had the following recommendations:  Blue Yeti: A reference for Podcasters  Tula Mic: A mic and autonomous audio recorder with an incredible look (though my wife took it for a cheese rasp)  Shure MV7: Recommended by someone who was not happy with the Yeti picking too much background noise  Shure SM7B: A studio legend which is also used by many podcastersAfter making some research, I was hesitating between both Shure, and the winner was … the Shure SM7B.This review helped me make my mind, it’s full of very interesting information.I choose the pricier SM7B because of its quality and because I already had all that was need to use it.Indeed this mic requires a 60db amplifier and my Line 6 Helix Floor guitar effect and amp simulator has a mic input that can handle that.For a lower budget, the MV7 seems very good (and is more plug and play).To hold it, I bought the Rode PSA1 boom arm based on a good friend recommendation and hundreds of good reviews.Be careful when manipulating this boom, its spring are strong and the arm can cause some damage when you remove the mic from it without holding the arm firmly.I almost destroyed my guitar which is hanging on the wall doing so 😱, hopefully the arm hit the wall a few centimeters away.Also, if you consider buying this boom, double check if your mic weights enough, if it’s not the case, it will be complicated to adjust its position (because of the strong springs).There’s no such problem with the Shure SM7B which weights enough.            Once I recovered from my emotions and finished fixing, plugin and configuring the mic (the 60db gain),I realized that I could use all of the Helix effects, such as input gate (to filter background noises below a given level), compressor (dyn, to keep audio level in a given db range by boosting or reducing volume) or preamp (pre, to add/remove bass or medium for instance).In order to avoid hurting my back by bending in two under the desk, I use the HX Edit application (shown below) to configure the Helix.My audio can still probably be improved as I didn’t took much time to tweak it but it definitely rocked (compared to MBP mic) even without any effect activated but the input gate.            Looking good enoughThat’s not a secret, the MBP webcam is not the best one to say the least.It’s probably the same hardware on all Macbooks since more than 10 yearsIPhone as webcam … or notI did a few tests using my iPhone as a webcam using the EpocCam application.It was not working well over wifi, there we some random deconnections.But when plugged on my MBP with a lightning to USB cable it worked perfectly.The image was far better than with the webcam BUT positioning the iPhone on my desk was complicated.I put it on top of a stack of books behind my MBP but I was not satisfied.I thought buying a stand for it but realized that as the zone for the camera on the Manning template was small, the difference between the “not so good but well placed webcam” and “the better but complicated to position iPhone” was not so noticeable so I used the webcam (I also gave up because I was in rush to do the recording, but that’s a story for next post).(Virtual) Green screen … or notI finally did not used it but EpocCam provides a virtual green screen that do the trick.You can take advantage of it in OBS using the chroma key effect filter on your video source.            To do what you see above:  Activate virtual green screen on your camera (or put a real one behind you)  Open the (Effect) filters configuration screen by selecting your camera source and clicking on “Filters” above the source panel (or right-click on camera source and select filters)  Click on + in “Effect Filters” and select “Chroma Key”Coding with styleI always try to do beautiful and readable slides for my sessions … but this time I was going to use VS Code.            Zooming enoughWhat worried me the most at that stage was the font size.Indeed if you capture your 36K hyper-ultra-mage-wide screen with regular font size, nobody will be able to read what you type on a 1920x1080 video which may not be viewed in full screen.In my case, I also had to be careful because the actual place reserved for my screen capture was smaller than the video size, only 1340x750.In VS Code (like in many Electron apps), you can use ⌘+ (Mac) or ctrl+ (Windows) to zoom in (make things bigger) and  ⌘- (Mac) or ctrl- (Windows) to zoom out (make things smaller).In order to set an adapted zoom level, I made some test recording and compared them with someone writing code at a previous Manning conference available on YouTube.I tried to keep thing readable even the video is not in full screen (regular YouTube embedded video size).I also tinkered with the Accessibility zoom feature of MacOS, you can make appear or zooming lens zone (the size you want) using a keyboard shortcut.I finally didn’t needed it but I keep that in mind for another time.Styling VS CodeI wanted something that look different from my good old VS Code standard theme and discovered many 80s theme in the marketplace.I finally choose Synthwave x Fluoromachine which comes with a nice background image for the editor.To make it fully work you’ll need Custom CSS and JS Loader.As I have done many tests, I don’t remember if that theme was the actual cause but as I had some standard VS code CSS customized, “Unsupported” appeared in the window’s title.To get rid of it, I used Fix VSCodeCheckums, it fixes VS code files checksum and make the “Unsupported” disappear.And I also use the Indent Rainbow extension that obviously colors indentations. Besides being pretty that’s very useful.Drawing on screenAnd last but not least, the mouse cursor is not always that visible when you want to show something.So I looked for a tool allowing to draw on screen.I found ScreenBrush which is totally amazing and was a perfect match with the Synthwave x Fluoromachine theme.I didn’t used it extensively during the session, I only drew a few rectangles, but it has some many cool features that I will probably use in th future.If you’re on MacOs and looking for a tool to draw on screen, this is the one.Setting VS Code window title (useful for OBS)You can’t see it in the recording but I have customized the VS Code window title to make it static and show the session’s title.This is done by adding a .vscode/settings.json file in your workspace containing the following configuration:                      .vscode/settings.json                                                                  {    &quot;window.title&quot;: &quot;Supercharged OpenAPI&quot;,}  Check VS code documentation to see all what you can do with window.title.At the beginning I did that to have my session’s title there but that was actually useful for OBS configuration.Indeed, you can crop screen capture to a window by using its name.But if the window’s name changes … problem starts.So making it static solves the problem.To be continuedBesides the mic and cam “problems”, which were not a real problems, it was starting well.I was ready to record myself coding and talking.So I started to actually work on the content for the recording and realized it was more than just coding and talking.But it’s a story that will be told in next post."
},{
    "id": "18",
    "type": "post",
    "title": "An API gateway must be a dumb pipe",
    "url": "https://apihandyman.io/an-api-gateway-must-be-a-dumb-pipe/",
    "banner": "https://apihandyman.io/images/an-api-gateway-must-be-a-dumb-pipe/banner.jpg",
    "description": "An API gateway is a proxy that sits between API providers and their consumers. Its main role is to ensure that only authorized consumers consume some APIs. But API gateways usually come also with features such as request/response transformation and some of them even allow to code complex orchestration. Such transformation features can be very useful if used wisely. But they also can give terrible ideas with terrible consequences.",
    "body": "An API gateway is a proxy that sits between API providers and their consumers.Its main role is to ensure that only authorized consumers consume some APIs.But API gateways usually come also with features such as request/response transformation and some of them even allow to code complex orchestration.Such transformation features can be very useful if used wisely.But they also can give terrible ideas with terrible consequences.Good transformation and orchestrationThe most basic API gateway will allow to expose an API on https://api.motu.com/v1 while it’s implementation is exposed on https/under.lying.server.prod/whatever/path.Before transmitting the request to the underlying server https/under.lying.server.prod, it will modify the path, replacing v1 by /whatever/path.As security is probably not handled the same way before and after the gateway, it may remove the original Authorization header containing a meaningless access token and replace by another one containing a JWT token holding information such as which consumer app made this call and in the name of who.If it takes advantage of an API description format such as the OpenAPI Specification, it may strip the a GET https://api.motu.com/v1/characters?unknownFilter=skeletor request from the unknownFilter query parameter which is not declared in the interface contract.It may does the same on the response and strip any undeclared headers.Possibly, it may seamlessly handle a POST /whatever request coming with a X-HTTP-Method-Override: PUT header and turn it into a PUT /whatever. (See API Design Tips And Tricks - What if consumers can’t do PATCH, PUT or DELETE?)Beyond simple transformation, an API gateway may do some orchestration like sending request and response logs somewhere for instance.Bad transformation and orchestrationAll that basically means an API gateway allows to “write code”, real code using JavaScript, Java, Groovy or whatever language and/or pseudo-code using box and arrow based GUIs.And seeing that, some may have terrible ideas.When returning the response of GET /characters/he-man why not transforming \"type\": \"H\" to \"side\": \"hero\"?Why not taking the USD price in GET /toys/he-man response and convert it into EUR calling a third party API?Why not returning a subset of GET /characters/he-man and GET /toys/he-man when responding to GET /action-figures/he-man?Why not indeed?If you do that, you put business logic outside of its original domain, its original implementation.It’s not uncommon to have business logic split across various components but putting it in an API gateway can be a problem.It may simply introduce complexity in the development workflow.Coding on this component may be easy … but coding with all the CI/CD, quality checks, … stuff may not be that simple.Also, coding in that component may require special skills that the team owning the business logic, the team actually implementing the original underlying APIs may not have.So this team may have to delegate that code to someone else.And that may lead to organizational issue and a lack of ownership.The original team may think they don’t own that code and not really care about it.The other team coding on the gateway may not care as much as the original team, and even if it’s not the case, as they may not know the underlying business rules that can cause some bugs.An API gateway is a smart-dumb pipeIntroducing business logic in an API gateway basically transforms it into a good (or very bad I should say) old ESB.Remember them?Those bloated too smart pipes that ruined many information systems because they were so complicated to manage.So don’t do that, keep API gateways dumb.Well, not so dumb; as long as an API gateway do smart “API exposition related stuff” and stays dumb from a business perspective, that’s totally ok."
},{
    "id": "19",
    "type": "post",
    "title": "An API Gateway alone will not secure your API",
    "url": "https://apihandyman.io/an-api-gateway-alone-will-not-secure-your-api/",
    "banner": "https://apihandyman.io/images/an-api-gateway-alone-will-not-secure-your-api/banner.jpg",
    "description": "How many times people realized that an API was not so secured despite being exposed on an API gateway? Too many times. While being a must have to securely expose APIs, an API gateway will not do all the security work for you. Security in general, and API security in particular, is a matter for everyone. Let’s see what is the job of an API gateway and what you still have to do to actually securely expose APIs.",
    "body": "How many times people realized that an API was not so secured despite being exposed on an API gateway?Too many times.While being a must have to securely expose APIs, an API gateway will not do all the security work for you.Security in general, and API security in particular, is a matter for everyone.Let’s see what is the job of an API gateway and what you still have to do to actually securely expose APIs.What’s an API gateway’s job?In its most usual form, an API gateway is a proxy that sits between server applications exposing APIs and their consumer applications (they could be other server applications, mobile applications, web applications or whatever).An API gateway may bring features such as logging, monitoring, rate limiting, simple connection to API catalogue or API developer portal (sometimes bundled with it), request/response transformations (we’ll talk more about that terrible idea in a later post) and more.But these are only additional features, an API gateway’s core job is security.A guard at the gateAn API gateway’s fundamental role is to ensure that:  Only registered consumer applications can consume the exposed APIs  Each registered consumer application only consumes the API(s) it is allowed to  And each registered consumer application only use an API’s operations it is allowed toFor instance, if an API gateway exposes a CRM (Customer Relationship Management) and a Contract APIs:  Unregistered consumers won’t be able to consume any of those APIs  A registered consumer may be allowed to consume only the CRM API and not the Contract one.  This registered consumer allowed to consume the CRM API may be allowed to only call “Search customers” and “Read customer” operations but not the “Create customer” one.A “security languages” interpretIn order to make API calls, a consumer must provide a valid access token along with its requests.    You must return here with a shrubbery... or else you will never pass through this wood...         Knight of Ni, Monty Python's and The Holy Grail    A registered consumer request an access token using its credentials, if end users are involved the API gateway will talk to an identity provider to authenticate them.The obtained access token is a proof that this consumer is allowed to consume some APIs exposed on the gateway in the name of someone.On every call, the consumer sends this access token along with its request.A call will only be transmitted to the implementation if the token is still valid (it may have expired) and linked to a consumer being allowed to use the API’s operation mentioned in the request.To achieve that, an API gateway may have to speak “Oauth 1.0”, “Oauth 2.0”, “Oauth 2.1”, “SAML”, “OpenID Connect”, etc… with consumer applications and/or identity providers.It handles that complexity on the behalf of the server application exposing the API.This server application, the API’s implementation, will receive only authorized calls without having to care about which “security languages” are involved.What’s your job?An API gateway simplifies heavily the work for teams building the server applications exposing APIs as they don’t have to code to manage complex security protocols or frameworks.But it does not mean at all that an API gateway handles ALL security aspects.Yes, I’m deeply sorry, but even when using an API gateway, you still have to work on security.Configure and administrate consumersIt’s still up to you to actually configure and administrate consumers.Indeed, you must ensure that:  Adapted granularity is used when declaring consumers. For a “customer mobile application” will you declare a single consumer (terrible idea), or one for each mobile OS (less terrible but still terrible) or one for each OS and application version (better) or …  Only the API owners can actually let consumers use their APIs. It’s not unusual to forget that when building more or less centralized API gateway platform.  Consumers access rights are revoked when they should. When an old version of a mobile application becomes unsupported for instance.  Adapted security mode are used. Letting people use the Oauth 2.0 Customer Credentials flow in a mobile application or single page web application is a terrible idea that is too often seen.But even doing that is not enough, there is still work to do beyond the API gateway.Build secured implementationsWhen the API’s implementation receives a call from the API gateway that means the API gateway considers it’s a valid one.But that does not means it’s actually valid from the implementation’s perspective.Basically, at implementation level you have to check every single piece of data to ensure that it is coherent with what you know about the consumer and end user.If a consumer sends a GET /crm/customers/12345, the gateway checks the access token is linked to a consumer that is allowed to call the CRM API and more precisely the “Read customer” operation, hence GET /crm/customers/{customerId}.But the API gateway will not check that the consumer or the end user (if any) are actually allowed to get information about that specific 12345 customer.It’s up to the implementation to check that.This can be done as long as the API gateway provides information about the consumer and end user along the transmitted request.And just in case: no, replacing 12345 by a more complex id such as 7a31bfa6-463e-47e0-bf20-193086d5a29d, does not allow to not do this check.And the same goes for a POST /contract/contracts request which is supposed to create a 1 billion Euros life insurance contract.It’s up to the implementation to check that consumer or end user are allowed to create a contract with such amount and not the API gateway.By the way, do we actually need to expose those two features?Design secured APIsBefore API implementation and API gateway, security must be dealt with during the design of APIs.It’s up to you to choose if you’ll create an API or not and which feature you’ll put in it or not.You’re under no obligation to create APIs for everything and expose every feature of any system.And once you’re sure about what you want to expose, be sure sure to choose secured design and representation.For instance avoid putting sensitive data such as personal data in path or query parameters, indeed a GET /customers/{socialSecurityNumber} will be logged by any equipment between consumer and provider.And last but not least, it is also up to you to choose how the access to the API will be partitioned.You have to design the scopes that grants access to all of or a subset of the API’s operations.These scopes will be used by the gateway to decide if a consumer is allowed to use an operation or not.For instance, you can put all of the read operations of the CRM API under the “crm:read_only” scope, the “Create customer” operation under the “crm:partner” and the “Create customer”, “Update customer” and “Delete customer” under the “crm:admin” scope.A consumer which has been granted the “crm:partner” scope can only do “Create customer” and not do “Search customers” or “Delete customer”.An API gateway is not the API security panaceaSo, putting an API gateway in front of your API’s implementation may makes your life easier but don’t be fooled, you’ll still have to actively work on security yourself.API security concerns the API gateway configuration (consumers, security mode, lifecycle), the implementation (application/fine grained security) and the design (what you expose and how you expose it)."
},{
    "id": "20",
    "type": "post",
    "title": "What's the problem with required query parameters?",
    "url": "https://apihandyman.io/what-s-the-problem-with-required-query-parameters/",
    "banner": "https://apihandyman.io/images/what-s-the-problem-with-required-query-parameters/banner.jpg",
    "description": "When reviewing API designs, I often encounter operations such as GET /resources?queryParameter=value where the query parameter is required. Consumers won’t be able to make that request without providing this parameter and a correct value; that’s usually a problem. Indeed, at best it will ruin developer experience and at worst it is a sign of design smell. Let’s see why.",
    "body": "When reviewing API designs, I often encounter operations such as GET /resources?queryParameter=value where the query parameter is required.Consumers won’t be able to make that request without providing this parameter and a correct value; that’s usually a problem.Indeed, at best it will ruin developer experience and at worst it is a sign of design smell.Let’s see why.What are query parameters and how they are usually usedAccording to RFC3986 Uniform Resource Identifier (URI): Generic Syntax, the “query component” of a URI is everything that goes after a question mark (?).The elements coming after that question mark are often in the form of a key=value pair. That means in https://api.eternia.com/characters?hasMagicalPowers=true, hasMagicalPowers is a query parameter and its value is true.Query parameters can be used in any type of HTTP requests but in most REST/RESTful/RESTish APIs, such query parameters are added on operations such as GET /characters, that represents something like “list characters” or “search for characters”, in order to allow consumers to filter the results.While a GET /characters is supposed to return all characters, a GET /characters?hasMagicalPowers=true will only return the ones having magical powers.    If you wonder why /characters and not /character, read /resources rules and /resource sucks ... or is it the other way around?Required query parameters ruin DXI have a rule of thumb when designing APIs: whatever the type of inputs, the less you request, the better because that help people do their first request and later ones without having to think too much.That is key when you want to build the best possible DX (developer experience).And query parameters are no exception.In the example above, turning hasMagicalPowers into a required query parameters will first lead to people failing their very first request because they expect that a GET /characters can be done without any query parameters.Why would they expect that?Because it’s the most encountered behavior.That does not seem much, that’s not exactly “ruining” the developer experience but that’s quite annoying.This could be the straw that breaks the camel’s back, people may go elsewhere especially if there are other APIs offering the same services without such silly behavior.And second problem, that leads to consumers having to make at least 2 requests in order to get all characters (pagination set aside), one to get those having magical powers and another one to those who haven’t.That is not really good for developer experience, it may actually ruin it.Obviously, in such situation, most of designers would never do that as beyond crippling developer experience, such design does not make any sense at all from this domain (Masters of the Universe franchise’s characters) perspective.But there are other use cases that are less obvious.The Masters of the Universe franchise had multiple TV cartoon installments (and no, the live action movie does not exist).Let’s take for granted that the original one made at the beginning of the 80s is the most known and loved one.Let’s take also for granted one that people looking for information about that franchise’s characters want to be able to get information about the characters of that specific version.That means when calling GET /characters, it could make sense to filter the results based on the TV show and so add a tvShow query parameter that could take values such as 80s_original_that_rules, 90s_version_that_sucks or all.Some designer could be tempted to make this query parameter a required one, letting consumers choose which characters list they want.But the rule of thumb is to request the less possible information to consumers.So let’s avoid this by keeping the tvShow parameter optional and using the most expected default value, obviously 80s_original_that_rules.That way, consumers could do a successful GET /characters without thinking much, the implementation filling the gap returning the results that would please most consumers (characters from the 80s version).After that, having read the documentation further, consumers may use the other possible values of tvShow.In a more real use case, the problem could come from a date filter on time series data.Let’s say that for performance reasons for instance, the implementation absolutely needs a date to returns a subset of all available data.In such a case, keep the parameter optional but choose the “best” default date to use if it is not provided by consumers.It could be today, first day of the month, last whatever processing date or whatever date will make sense from a business rule perspective and that will please most consumers.Whatever the query parameter, there is most of the time a way to keep it optional… if that parameter is not the sign of something more nasty.Required query parameters can be signs of design smellsIndeed besides possibly “ruining” the developer experience, a required parameter can be a sign of design smell.Let’s analyse the GET /enemies?of=characterId request which has an of required query parameter.It is supposed to return the enemies of someone, for example Skeletor and Beast Man are enemies of He-Man (GET /enemies?of=he-man) while He-Man and Teela are enemies of Beast Man (GET /enemies?of=beast-man).The of parameter being required, my API design reviewer senses tell me there’s something wrong without even thinking about the purpose of this operation.My first attempt is usually to check if the required parameter can be turned into an optional one.Here, returning the enemies of “no one” doesn’t make sense.Returning the enemies of a default character also makes no sense at all.So that does not smell good.Indeed, if any character can be seen as an enemy by any other character, the resource that should be manipulated when representing “listing the enemies of someone”, is not just “enemies” but the “enemies of someone”.That means the resource path should be something like /characters/{characterId}/enemies instead of just /enemies (the character).Based on my experience, when the query parameter cannot be removed that is most of the time the sign of a “wrong resource identified” and the fix is usually adding a level in the resource’s path hierarchy.Think twice before adding a required query parameterSo the next time you’re tempted to make a query parameter required, double check that you’re using the right resource and especially not missing a level in your resources hierarchy.If the parameter actually makes sense, think about what could be the more useful value for most consumers and use it as default when that parameter is not provided."
},{
    "id": "21",
    "type": "post",
    "title": "API Designer Experience, the other DX",
    "url": "https://apihandyman.io/api-designer-experience-the-other-dx/",
    "banner": "https://apihandyman.io/images/api-designer-experience-the-other-dx/banner.jpg",
    "description": "Nobody expects the API inquisition! Literally. When creating public or private APIs, an organization must work hard on creating the best possible developer experience or DX. That requires to ensure that API designers “do their job well”: creating APIs that fulfill actual needs and are easy to understand and use. This is the aim of governance which may help creating the best APIs or may slowly killing the organization, depending on the designer experience, the other DX, it provides.",
    "body": "Nobody expects the API inquisition!Literally.When creating public or private APIs, an organization must work hard on creating the best possible developer experience or DX.That requires to ensure that API designers “do their job well”: creating APIs that fulfill actual needs and are easy to understand and use.This is the aim of governance which may help creating the best APIs or may slowly killing the organization, depending on the designer experience, the other DX, it provides.What usually is DXIn the API world, DX stands for Developer eXperience.It consists in providing APIs that fullfil their needs but that also are easy to understand and easy to use in a matter of minutes if not seconds.Developers should be able to understand the purpose of an API in 3 seconds, identify the operation in 30 seconds and be able to make their first API call within 3 minutes.That latter time including creating an account, getting credentials and then calling the API.Achieving such a great DX does not only rely on the API itself, its purpose and its design.It relies also on everything that comes around:  The way people will find it  Its various documentations from high level description (that allows to understand what the API does) to instruction manual (ready to use recipes) and reference documentation (describing all operations and how the API works)  And the tools provided (in a broad sense: account creation and management, credentials, billing, …)Working on DX is basically aiming at making developers life simpler.That’s the usual DX, but there’s another one, that an organization creating public but also private APIs, should care about.The other DX: Designer eXperienceThose APIs are actually designed in order to make them easy to understand and easy to use.Succeeding in consistently and in the long run creating such APIs at scale requires governance.Governance implies defining rules, controls and processes that will ensure that all APIs will share a common look and feel, be consistent and have the same level of quality.The problem with governance is that sometimes it is so focused on rules, controls and processes that people, and especially API designers, actually dealing with it are totally forgotten resulting in the most terrible Design eXperience, the other DX.Create user friendly design guidelinesAPI design guidelines are the set of rules that will define the look and feel of an organization’s APIs.They can be compared to an organization’s graphic charter and also to design system, but instead of defining its visual identity that will be used when creating websites or mobile apps for instance, it defines its APIs identity.These guidelines are mandatory to build a good developer experience because consistent APIs are easier to understand and use.But they also matter for people who will design APIs. Defining a common design base allows each designer to avoid wasting time and trying to find a solution to a design problem that has already been solved. But that will only work if those guidelines apply the same principles used to create APIs: guidelines must be simple to understand, simple to use and fulfill actual designers needs.So do not reinvent the wheel, do not reuse your possibly outdated and highly specific practices, follow outside world standards and common practices. Define rules only when that is actually necessary, if you’re unable to explain a rule, don’t put it in your guidelines. Design rules must exist only to help people not unnecessarily constrain them.Do not write your guidelines in an “incomprehensible super expert that loves to hear themselves” style. Make them simple to use, just like you would do when creating API documentation. Once you have defined rules, create use case oriented design patterns describing in one place all rules that actually apply to a specific use case.And listen to people. Accept changes, evolutions. Rules are not set in stone, you must never hesitate to make them evolve by adjusting or completing them based on API designers and implementers feedback.Conduct user friendly design reviews workshopsBut even with the user friendly-est guidelines are not enough, designers may make mistakes and most important a consistent style is only a fraction of what makes an API a good one.Consistency goes beyond style, inside an API one must ensure that all data models are consistent for example, as we say in french, a cat must always be called a cat for instance.And worse, one can create an API complying a 100% to guidelines that will be a terrible one.Indeed, guidelines do not guarantee that an API will meet the right need in an efficient way. Do we have the right vision of the need? Is the resulting API really user friendly? Easy to understand, easy to use for someone outside the organization (another team or a partner or a customer)?So, irremediably coming along with guidelines, there are the mandatory API design reviews.It is important that several people can look at and challenge a design.An API must be analyzed from different perspectives: business, technical, developer experience to guarantee its success.And it is important that at least one “external” person, or one who can act as if, participates in this analysis, because we can quickly fall into the creation of specialist APIs like Kitchen Radar if we are not careful.But beware, this exercise can quickly turn into a counterproductive trial if you are not careful.A design review is not about policing and beating up on people because their design is “breaking the law”,  “non-compliant” or worse “sucks” from the reviewer’s perspective.An API design reviewer is not the inquisition of API design.Actually, nobody expects the API inquisition, literally.An API design review must be seen more as a design workshop.Being an API design reviewer is more about being a consultant, helping people identify their needs, choosing the best possible representation, helping them make decisions adapted to their context, explaining the consequences of going in one direction or another.Once everything is analyzed and explained, API designer reviewers must let designers choose because they are the owners of their APIs.API design reviewers must help designers and respect API ownership.Build user friendly organization, processes and toolsJust like a terrible registration process can ruin the best API’s developer experience, there are other aspects of API governance to take care of to ensure creating the best possible developer experience.Indeed, if guidelines and reviews are the most obvious aspects of API governance participating in building the better or the worst designer experience, wrong human organization, processes and tools can cripple all efforts.When possible, prefer decentralized organization, aim on training all designers in order to make them the most autonomous possible.It’s far better for the organization that people add to their expertise than having a small set of not always available experts.That can be done gradually by identifying local experts that will be trained and then help and train other themselves.When defining processes, never lose sight that governance is there to enable designers to the right thing simply.If it takes weeks if not month to do an API design review, it’s a terrible designer experience.If processes lead to designers losing ownership, it’s an even more terrible design experience.When creating tools, ensure they are user friendly.Take advantage of standard/common practices, using the OpenAPI specification instead of wiki pages or spreadsheet to describe an API for instance.Ensure also they are the most open possible, providing APIs for instance, so designers can use them in a wide range of context because not all teams build APIs in the same way.Fear the consequences of terrible Designer eXperienceJust in case you think that’s not something you should care about because you think governance should be strong and only care about ensuring nobody breaks the law, let’s briefly talk about the consequences of not caring about this other DX.A terrible designer experience will irremediably lead to designers not learning how to actually create good APIs, they may even loose interest in designing APIs and delegate that to the governance zealot henchmen.It will irremediably lead to terrible APIs created by outsider experts only caring about not breaking the law and totally not caring about creating actually good APIs.Terrible private APIs mean higher costs, increase of technical debt, less flexible IT, longer time to market.Terrible public APIs mean not used APIs…And in the end, people who actually care will just leave the organization that may just collapse in the end.So, don’t underestimate the importance of the other DX, Designer eXperience."
},{
    "id": "22",
    "type": "post",
    "title": "Automate all the things (like Cloudflare cache purge) with Github actions, Postman and APIs",
    "url": "https://apihandyman.io/automate-all-the-things-with-github-actions-postman-and-apis/",
    "banner": "https://apihandyman.io/images/automate-all-the-things-with-github-actions-postman-and-apis/banner.jpg",
    "description": "What if I tell you can run Postman collection inside Github Actions and so easily automate all the things as long as they provide APIs? Sounds interesting right? So let me show you how I migrated my Jekyll blog publication workflow to Github Actions and how I used Postman collection to clear my Cloudflare cache. Bonus: You may also learn a few things about DX and API design.",
    "body": "What if I tell you can run Postman collection inside Github Actions and so easily automate all the things as long as they provide APIs? Sounds interesting right? So let me show you how I migrated my Jekyll blog publication workflow to Github Actions and how I used Postman collection to clear my Cloudflare cache. Bonus: You may also learn a few things about DX and API design.Migrating to Github Actions and solving an old problemSince 2016, the API Handyman blog is powered by Jekyll, built by travis-ci.org, hosted on Github Pages and cached with Cloudflare CDN.On May 31, 2021, travis-ci.org has been shot down.This has been announced for quite a long time… but I managed to totally forgot to do something about it; I actually realized it simply because my 1st of June’s post has not been published. I was going to migrate to travis-ci.com but because (or thanks) to an obscure bug I wasn’t able to do it … and as I wanted to test Github Actions, I took the few necessary minutes to switch my build on it, and that was a blast. Ready to use actions that you can build upon, clear and simple format, good documentation, I was totally delighted.As changing the build system was faster than expected, I decided to tinker a bit more and solve a problem I had with my system: to ensure publication, I had to go to Cloudflare dashboard and manually clear the cache. If by chance Cloudflare propose an API, I thought I could include clearing cache after the build with a curl command, but as always I did a little bit more than that.Setting up a Jekyll Github Action WorflowMigrating from travis-ci.org to Github actions was done at the speed of light.I will not go through all details, Github Actions, format, UI and documentation are quite clear, but I will show you a few tips I discovered while setting up my first Github Workflow (yes, naming is hard, it’s called Github Actions but you create … Workflows, actually “actions” seems to be the reusable components that you can use in workflows).Default Jekyll workflowStarting with Github Actions as a total beginner is dead simple:  Go to your repository  Click on the Actions tab, you should see a “Get started with Github Actions” page  Scroll down to “Continuous integration workflows” and look for “Jekyll”That should create the following workflow in .github/workflows/jekyll.ymlin your repository:                      Default Jekyll workflow                                                                  name: Jekyll site CIon:  push:    branches: [ main ]  pull_request:    branches: [ main ]jobs:  build:    runs-on: ubuntu-latest    steps:    - uses: actions/checkout@v2    - name: Build the site in the jekyll/builder container      run: |        docker run \\        -v $:/srv/jekyll -v $/_site:/srv/jekyll/_site \\        jekyll/builder:latest /bin/bash -c &quot;chmod -R 777 /srv/jekyll &amp;&amp; jekyll build --future&quot;  According to the on property, This workflow will be triggered by pushes and pull requests on main branch.It contains a single job (in jobs) named build which is composed of 2 steps:  The first one checkouts the repo taking advantage of the actions/checkout@v2 action (that means you can call actions inside actions workflows! Check the Market Place, there are dozens of them already)  The second step runs a jekyll build using Docker (that will prove to be useful) but does not publish anything (you can basically run any Linux commands with run)Customizing Jekyll workflowMy publication workflow is quite simple, each Wednesday à noon (UTC) or on demand, I want to:  Checkout repository on default branch  Run Jekyll build  Commit build’s result on gh-pages branchSo I started by customizing the on section:  To schedule build every Wednesday at noon using cron syntax (Schedule Events documentation)  And I also activated “on demand” execution with the empty workflow_dispath (Manual Events documentation)                      Customized Jekyll workflow                                                                  name: Publishon:  schedule:    - cron: &quot;0 12 * * WED&quot;  workflow_dispatch:  Then I customized (and renamed) the build job as build_and_publish:  I added PUBLISH_BRANCH_FOLDER (target folder for build) and PUBLISH_BRANCH (publication branch) environment variables (documentation) in env. They are later used with the ${{env.VARIABLE_NAME}} syntax.  I tweaked the checkout step to make it faster by only downloading the last version of the code (fetch-depth: 1)  I removed the --future flag on Jekyll build step to avoid having future date being published (actually I did that after realizing that future post had been published)  I modified build target directory (the second -v in the Docker command) and set it to ${{ github.workspace }}/${{env.PUBLISH_BRANCH_FOLDER}}. The github.workspace is a variable of github context, this context provides information about the workflow and the event that triggered it.  And finally, I added the publication step which consists in pushing build on gh-pages. This is done using the wonderful JamesIves/github-pages-deploy-action which can take the content of any folder and push it on any repository’s branch (the clean: true is a very convenient option that removes what should be removed from the target branch based on source folder)                      Customized Jekyll workflow                                                                  jobs:  build_and_publish:    env:      PUBLISH_BRANCH: gh-pages      PUBLISH_BRANCH_FOLDER: _site    runs-on: ubuntu-latest    steps:    - name: ⬇️ Checkout current branch      uses: actions/checkout@v2      with:          fetch-depth: 1    - name: 👷🏻‍♂️ Build with jekyll/builder container      run: |        docker run \\        -v ${{ github.workspace }}:/srv/jekyll \\        -v ${{ github.workspace }}/${{env.PUBLISH_BRANCH_FOLDER}}:/srv/jekyll/_site \\        jekyll/builder:latest /bin/bash -c &quot;chmod -R 777 /srv/jekyll &amp;&amp; jekyll build&quot;    - name: 🚀 Push on ${{env.PUBLISH_BRANCH}}      uses: JamesIves/github-pages-deploy-action@4.1.4      with:        branch: ${{env.PUBLISH_BRANCH}} # The branch the action should deploy to.        folder: ${{ github.workspace }}/${{env.PUBLISH_BRANCH_FOLDER}} # The folder the action should deploy.                clean: true        commit-message: Publish  Clearing Cloudflare cache by API with PostmanNow that the blog is published, let’s see how to clear Cloudflare cache.Spoiler: Do Cloudflare offers a good DX (Developer eXperience)?Yes, definitely, I was able to do what I wanted in a matter of minutes.Finding the API documentationI opened cloudflare.com website to locate their API documentation but was quite disappointed, no mention of any Cloudflare API at all.That was not starting well; don’t do that at home, if you have API(s) advertize them on your homepage.Hopefully, I found the link to Cloudflare API documentation once I logged in my account and … scrolled all the way down to the page footer.            Log in your Cloudflare account and scroll all the way downTo be honest, I could simply have googled Clouflare API and I would have arrived directly on the documentation, searching “company name api” is the best way to find a company’s API documentation.Though, Cloudflare doesn’t advertize them on their homepage, they did a great job on their APIs.Crystal clear documentation going straight to the point; it took me a few seconds to arrive to the “Getting start -&gt; Requests” section explaining how to make API calls using an API token.Icing on the cake: the direct link to your user profile for token configuration.            How to do a Cloudflare API requestConfiguring an access tokenOnce arrived on the API Tokens tab of your profile, click on the Create Token blue button, the following page will appear:            Create Cloudflare API TokenCloudflare allows to create tailor made tokens with only the permissions you actually need which is great for security.The create token page propose pre-configured token templates which is good, but there was no template matching my need, so I created a custom token.Configuring a custom tokenConfiguring an access token is dead simple:  Give it a name (useful when wanting to delete a token)  Select permissions Zone -&gt; Cache Purge -&gt; Purge  Select resources to purge, I chose to include only the apihandyman.io domain  Click on continue to summary            Configure Cloudflare API TokenCloudflare allows to generate tokens with really fine grain permissions and the way they are organized and what you can do with them is crystal clear.Github should get inspired by this, their token configuration is light years behind this.Checking configurationOnce configuration is done, you’ll get a summary of permissions granted by this token.            Cloudflare API Token SummaryToken createdAnd when token is created, you can copy it to use it, but quite convenient, you get a ready to use curl command to check it actually works (I wouldn’t have designed the endpoint like this though, but that’s not the point here).            Cloudflare API Token CreatedNo interactive documentation is not a problem hereOk, Cloudflare could propose an interactive documentation using pre-generated tokens.But in that context and as the API is quite simple I was not annoyed at all by the static documentation.I even wonder if that would be a good idea to have such dynamic documentation based on the terrible actions you can trigger with their API.Verifying the TokenInstead of using curl to verify token, I used Postman.If you’re not familiar with Postman, follow the detailed steps described in my Batch (Github) API calls with CSV and Postman to setup workspace, collection and environment variablesI created a Cloudflare workspace and a Cloudflare Clear Cache collection in Postman to tinker with the Cloudflare API.I added a collection variable called root containing the url (https://api.cloudflare.com/client/v4) of Cloudflare API And I added a Cloudflare environment containing my newly created token (and saved and selected it in the upper right environment drop list!).In the collection, I set up Authorization type to Bearer Token (as stated by Cloudflare API documentation) and set the Token value to {{token}}.And the I created a Verify Token request as a GET {{root}}/user/tokens/verify.Before hitting the Send button, I added a Test snippet to check that the response is a 200 OK by going to the request’s Tests tab then click on the “Status code: Code is 200” snippet as shown below.            Verifying Cloudflare Token in PostmanReading purge cache documentationNow that we’re all set to make Cloudflare API calls, let’s see how to purge cache.Finding out how to do that is again dead simple, go to Cloudflare API documentation, type “purge” in the top left search box, and click on “Purge All Files”.Note that depending on your Cloudflare subscriptions, you can get access to more sophisticated purge cache features.As I have a small github hosted website, I can afford to do a brutal total cache purge, I may use the purge files by URL to make this more efficient.            Verifying Cloudflare Token in PostmanSo purging cache requires to send a POST {{root}}/zones/{zone identifier}/purge_cache request, according to the curl example, that will be the technical identifier of my apihandyman.io zone.I think I could get that identifier from the dashboard but I’m too lazy to do that.Guessing how Cloudflare API works thanks to its designThough I wouldn’t have design the Cloudflare API that way, it is still a little bit predictable.I can get what I want (my apihandyman.io zone identifier) without reading the documentation.First, based on the {{root}}/zones/{zone identifier}/purge_cache, I can guess that doing a GET {{root}}/zones will let me list all my zones, and the guess is correct!I get a list of zone and the name property contains the domain name, so let’s try a GET {{root}}/zones?name=apihandyman.io to get only the zone I need, that works too!            Getting apihandyman.io zone and storing in zone_id environment variableIn order to make all this reusable, I set the website name as an environment variable.And in the Tests tab, I add some code based on Postman’s snippets to check that I get a successful response with a non empty list and then I store the zone identifier in a environment variable.Now that I have my zone identifier, I can easily purge cache using the zone_id variable:            Purging apihandyman.io cacheI just add a new {{root}}/zones/{{zone_id_}}/purge_cache request with a body containing the purge_everything set to true and I’m done.Well, almost done, I also added a test to check that the request is successful using the snippet “code is 200”.Purge cache collectionNow I have collection that contains 3 requests:  Verify token  Get zone identifier for website name  Purge cacheThose requests relies on the following variables            Variable      Type      Description                  root      collection      The root URL of Cloudflare API (collection hard coded)              token      environment      The Cloudflare API bearer token (set by user)              website      environment      The website name to purge (set by user)              zone_id      environment      The zone identifier of the website (set by Get zone identifier request)      Now we know how to purge Cloudflare cache, let’s see how to do it with a Github action.Running a Postman collection within a Github actionIn the beginning my idea was to simply do a curl command to call cloudflare API and possibly use jq if needed between calls but once I have seen that you can use Docker withing Github Actions and so run almost anything you want, I came to the idea of using Newman, Postman’s CLI, to run a Postman collection.I exported my Cloudflare Clear Cache Postman collection as cloudflare-clearcache.postman_collection.json in the scripts folder of my apihandyman.io Github repository.Passing variables to NewmanRunning “Clearing Cloudflare cache” collection on the command line is as simple as running newman run scripts/cloudflare-clearcache.postman_collection.json:                      Failed run                                                                  Cloudflare Clear Cache→ Verify Token  GET https://api.cloudflare.com/client/v4/user/tokens/verify [400 Bad Request, 1.08KB, 1034ms]  1. Status code is 200  Oops, got a 400 instead of 200 when verifying token because there simply was no token provided.Newman is unaware of Postman’s environment variables.This is simply fixed as follow using --env-var name=value for each user defined variable of my Cloudflare Clear Cache Postman collection:                      Setting environment variables                                                                  newman run \\    --env-var token=REDACTED_CLOUDFLARE_TOKEN \\    --env-var website=apihandyman.io \\    scripts/cloudflare-clearcache.postman_collection.json  Running Newman with DockerRunning Newman with Docker is almost as simple using the postman/newman image.The thing you need to know is that when running a local collection file, the newman CLI inside  Docker expects to find it in /etc/newman.That’s why there’s a -v parameter in the following command, which mounts the folder containing the cloudflare-clearcache.postman_collection.json on /etc/newman:                      Newman, Docker and Variables                                                                  docker run \\    -v /path/to/scripts:/etc/newman \\    -t postman/newman:alpine run \\    --env-var token=REDACTED_CLOUDFLARE_TOKEN \\    --env-var website=apihandyman.io \\    cloudflare-clearcache.postman_collection.json  Running Newman in Github Action WorkflowNow that we know how to run the cloudflare-clearcache.postman_collection.json with Newman and Docker, let’s add a job doing so to the Github workflow:                      Newman in Github Actions                                                                  jobs:  build_and_publish:    [...]  clear_cdn_cache:    needs: [ build_and_publish ]    env:      POSTMAN_COLLECTION_BRANCH: main      POSTMAN_COLLECTION_FOLDER: scripts      CLOUDFLARE_WEBSITE: apihandyman.io    runs-on: ubuntu-latest    steps:      - name: ⬇️ Download Cloudflare Clear Cache Postman collection        uses: actions/checkout@v2        with:          ref: ${{env.POSTMAN_COLLECTION_BRANCH}}          fetch-depth: 1      - name: 💥 Clear Cloudflare cache        run: |          docker run \\          -v ${{ github.workspace }}/${{env.POSTMAN_COLLECTION_FOLDER}}:/etc/newman \\          -t postman/newman:alpine run \\          --env-var token=${{secrets.CLOUDFLARE_TOKEN}} \\          --env-var website=${{env.CLOUDFLARE_WEBSITE}} \\          cloudflare-clearcache.postman_collection.json  I added clear_cdn_cache job after the build_and_publish one:  The needs property says this job will only start AFTER build_and_publish success (without that both jobs start in parallel)  In env I declare a few variables and especially the CLOUDFLARE_WEBSITE needed by the Postman collection  The first step downloads the collection, it’s in current repo, but it could be elsewhere  The second step runs the collection with newman, note that I obviously didn’t put my Cloudflare token there, instead I’m using a secret ${{secrets.CLOUDFLARE_TOKEN}}. To configure a secret, go to the repository’s Settings tab, then Secrets.And 🎉:            Purging apihandyman.io cache done!Note that, on line 5, the token value (${{secrets.CLOUDFLARE_TOKEN}}) is (hopefully) not printed as it is as secret.Automate all the things!Being able to run Postman collection within Github actions opens endless possibilities but more important, all what I’ve done here can be done because people actually worked hard to bring the best possible user experience at every level:  Regarding APIs DX, the Cloudflare API and its documentation can be taken as a good example (even though I would tweak a thing or 2 in their design), it’s a shame they don’t advertize their wonderful API on their homepage.  Postman and Newman easily help me to avoid writing painful bash/curl scripting.  Github actions being so well documented and simple are a pleasure to use, being able to use others’ actions and the Docker capability are killer features  And so Docker participates greatly in this awesome user experience, making it easy to run absolutely everything wherever you want"
},{
    "id": "23",
    "type": "post",
    "title": "API Design Reviews Series - Part 1 - 3 good reasons to do API Design Reviews",
    "url": "https://apihandyman.io/3-good-reasons-to-do-api-design-reviews/",
    "banner": "https://apihandyman.io/images/3-good-reasons-to-do-api-design-reviews/banner.jpg",
    "description": "More often than not when people hear “let’s do an API design review”, they hear “let’s check that an API design conforms to API design guidelines”. That’s only partially true and reducing API design reviews to that is a terrible mistake. Actually, doing API design reviews only to do that may even not make any sense at all. Let’s see 3 really good reasons to do API design reviews.",
    "body": "More often than not when people hear “let’s do an API design review”, they hear “let’s check that an API design conforms to API design guidelines”.That’s only partially true and reducing API design reviews to that is a terrible mistake.Actually, doing API design reviews only to do that may even not make any sense at all.Let’s see 3 really good reasons to do API design reviews.I’m gonna need a bigger boatPeople following me on Twitter might have expect another post this week.Indeed, I tweeted something like “lately, I slightly changed the way I summarize my API design reviews, that looks promising and I’m going to write about this next week”.But, that would be putting the cart before the horse and I have so many things to say about API design reviews that I think this topic deserves a (probably long) series.So before diving into how I summarize API Design Reviews, we’ll talk about the reviews themselves and especially why you should (even must) do them.And we start with what most people think an API design review is …Check guidelines conformance Ensure consistencySo, more often than not when people hear “API design review”, they hear “checking that an API design conforms to API design guidelines”.That’s only partially true, the aim of an API design review is actually less about checking guidelines conformance (which is the “how doing a review”) and more about ensuring an overall consistency (which is the “why doing a review”).Consistency in API design is important because if all of your APIs and more important all operations, behaviors and data models (and whatever forms an API design) share the same look and feel, that will make your APIs easier to understand and to use.Once people have learned to use one of your APIs, they feel at home when switching to the next one because it looks and behaves like the previous one.That’s why guidelines are important; they are many good (and wrong) ways to design (REST or other) APIs but you need to choose one (preferably a good one). Guidelines define an API design look and feel, and by the way if they are well made, those guidelines are consistent with outside world common practices and so that makes your APIs even more easy to use.But while guidelines may help to achieve a certain level of consistency at high level, there is still much place to introduce inconsistency.Indeed, your guidelines will probably not cover every single and more local design concerns.For instance, it’s up to the API owners (the team, not a single person) to ensure that “a cat is always called a cat” (as we say in french).If it’s randomly called a cat, felisCatus or felidae across same domain APIs or worse inside an API, that will puzzle more than one consumer (and owner by the way). So API designers must take care to use the same vocabulary throughout a single API and across their domain APIs (who said ubiquitous language?).So, ensuring consistency not only requires to observes API design guidelines but also the rest of the API and other related APIs.But reducing API design review to “ensuring API design consistency” is a terrible mistake.Help people shape the right APIsIf an API is 100% consistent with itself, with outside world common practices, with design guidelines and existing APIs, it unfortunately still can be a terrible API.Indeed, it can be as simple as choosing the wrong vocabulary (cat vs felisCatus), making the API hard to understand for non experts.But it can be also less obvious, like exposing purely internal concerns that shouldn’t be exposed to the outside, making the API complex to use (if not dangerous).It can be even worse: choosing a totally wrong purpose, making the API a total failure.And everything in between (and beyond).            The Kitchen Radar 3000 (from my book The Design of Web APIs)Hopefully, it’s not a fatality, a well conducted API design review allows to avoid such dark fates.Put around a table people having functional knowledge, people knowing how the software work (existing) or should work (new), and people knowing nothing about the topic (usually the reviewer, or Jon Snow) and you should be able to decipher what the API should actually do (to solve someone’s problems) and how it should actually looks like.With all these people discussing during the API design review, the resulting API will be the right API, or at least it shouldn’t be that far (do a final check with potential consumers to confirm).Improve API design skillsThe more you do API design reviews, the more people involved improve their API design skills.I have witnessed it myself, after a few months, all people involved (including myself as a reviewer) have improved their API design skills.At the beginning, there can be a lot of basic mistakes (HTTP, guidelines, consistency), but review after review people understand how API design works, how the guidelines works.In the process, reviewers learn also a lot by confronting their views to others, discovering new patterns, new use cases.And in the end, reviews can focus more on doing the right APIs than doing the APIs right.Icing on the cake, API design reviews may have interesting side effects on other areas.One day someone told me that doing API design improved their software design skills, they changed the way they designed class, methods, databases, … and even software architecture.That’s also true on the functional perspective, building APIs that are easy to understand, easy to use, easy to evolve, can trigger new ways of thinking that can be applied when designing business processes too.API design review is a MUST doSo, API design review is a MUST do.It will irremediably lead to consistency across APIs.More important, it will lead to building the right APIs.And even more important, it will help people grow API design skills that, icing on the cake, can be applied to other areas.But, there’s always a but, that will only work if the API designer review is conducted the right way, especially with the right mindset.But that’s another story (if not stories) I’ll keep for one or more later post(s)."
},{
    "id": "24",
    "type": "post",
    "title": "Handling breaking ch-ch-changes",
    "url": "https://apihandyman.io/handling-breaking-ch-ch-changes/",
    "banner": "https://apihandyman.io/images/handling-breaking-ch-ch-changes/banner.jpg",
    "description": "In (Ch-ch-) Changes, David Bowie sang “Every time I thought I’d got it made, it seemed the taste was not so sweet”, that’s a good metaphor for API design. An API will irremediably evolve because it will lack some features or because of mistakes, and so sooner or later, you may have to introduce a “breaking change”. That’s usually when people start to run in circle, scream and shout “Oh! Please no! Please, not a breaking ch-ch-change”. But, what is it actually? How to handle it? And should you always be afraid of it?",
    "body": "In (Ch-ch-) Changes, David Bowie sang “Every time I thought I’d got it made, it seemed the taste was not so sweet”, that’s a good metaphor for API design.An API will irremediably evolve because it will lack some features or because of mistakes, and so sooner or later, you may have to introduce a “breaking change”.That’s usually when people start to run in circle, scream and shout “Oh! Please no! Please, not a breaking ch-ch-change”.But, what is it actually? How to handle it? And should you always be afraid of it?What is a breaking changeA breaking change is non backward-compatible modification that requires consumers to modify their code in order to continue using an API (or at least modify the part of their code using the modified part of the API).There are many different ways to introduce breaking changes in APIs, some are obvious, some are not.The most common obvious way to introduce a breaking change is to rename or remove something in the interface contract.Rename GET /usrs to GET /users or remove the isAdmin property from the User data model and there’s a huge risk that it will break some if not all of the API’s consumers.There are also less obvious interface contract’s breaking changes. Turning an optional parameter into a required one or adding new values to enumerations that consumer is supposed to interpret. And there are even less obvious and far more treacherous breaking changes:    With a sufficient number of users of an API, it does not matter what you promise in the contract: all observable behaviors of your system will be depended on by somebody.        Hyrum Wright, Hyrum's Law                XKCD: WorkflowA breaking change can happen without actually modifying the API’s interface contract.Change a business rule so that given the same conditions a user’s “asshole level” is set to orange instead of green when analyzing their last comments and that may break something. Pushing the concept to the extreme, that also means some consumers could depend on an API’s long response time and optimizing the API’s implementation to make things go faster on provider’s side could put them at risk.That’s probably going a little bit too far, but keep that in mind, just in case.So a breaking change is a change that could literally break something on the consumer side.That does not sound good but is it actually always that bad?Evaluating the cost of breaking changeAs an architect, my favorite answer to any question is “it depends”.And in that case, it applies yet another time.Depending on the context, the cost of a breaking change vary.If the API is in early stage and not even yet consumed, you can break whatever you want without even thinking about it.If the API is consumed only by a single application that you build yourself, you can most probably do it with not much work.On the opposite, if the API is consumed by many consumers that are “far” from you, another team, another business unit or worse partners or customers.The cost will be high.The less consumers and the more you control them, the less will cost a breaking change. The more consumers and the less you control them, the more will cost a breaking change.How to avoid itBefore requiring consumers to update their code, maybe you should think twice and find a way to avoid that.Here are 3 ways to more or less “avoid” introducing breaking changes.Don’t do itFirst, triple check that you actually desperately need to make this breaking change.Evaluate the value it brings versus its cost.You want to fix some mistake (like a typo or a terrible name) to make a perfectly clean API?That’s nice but probably counter-productive, perfection is not of this world, especially in API design.Live with it for the time being, you may be able to fix that when introducing actually awaited new features that your consumers will be totally crazy about.In the meanwhile, you may try to limit problems by improving the documentation if that help.Make it backward-compatibleIf there are good reason to introduce this change, maybe there’s a way to make it in a non-breaking way.The usual strategy to do that is only to “add” in a clever way.Instead of modifying an existing operation, you may simply add a new one.Why not adding a POST /administrators instead of modifying POST /users to introduce the new administrator user type?On the inputs, always add optional properties/parameters with default values.Let’s say you have a “create user” features and want introduce different service level (regular vs gold).Instead of required serviceLevel that will hold regular or gold, set it optional with regular as default value.On the output, it’s simpler, just add, it doesn’t really matter if the new data is always returned or not.There’s more often than not a way to turn a backward-incompatible change into a backward-compatible one, it may not lead to the best design but sometimes you have to make compromises.Use breaking change proof designThe third way to avoid breaking change is a little bit different: it’s about to preemptively ensure that breaking changes have less risk to happen by choosing a breaking change proof design.You can work on data types, avoid using booleans or arrays of atomic (string, number, …) for instance.A isAdmin property is less extensible than a role: \"admin\" one, indeed, there may be more roles than admin and non admin users in the future.Which is less extensible than a roles: [\"admin\"], because a user may have more than one role in the future.Which is less extensible than a roles: [{ type: \"admin\"}], because a role may need more features such as a start and end date for example.You can work building self sufficient features by adding data or new operations.When accessing a user, consumer may need to know what their role mean, at the beginning they can hardcode that an admin user can do everything while a non admin one can only read data for example.But if you provide the role description along with its type, you may seamlessly introduce new user types.When creating a user, consumer need to know the available types of user they can create, they can hardcode that based on an enumeration provided in your documentation or they could call a GET /userTypes and get up to date data.And last but not least, you can also lessen the risk of breaking changes by hiding as much as possible what happens inside your API, inside your domain.The less the outside world know about your internal business rules and way of working, the less coupled with consumers you’ll be.How to handle itWhen the breaking change cost is low or when it is unavoidable even though its cost is high, you have to actually handle it.Here are a few good practices and tips to have in mind in such a situation.Synchronized modificationsThe most simple way to handle breaking change is to synchronize modified API and consumers deployment.This strategy will only work when you have full control on consumers.While it is fairly easy to do that with a web application, it can be more trick for rich clients such as mobile application as end users may not want to update them if they are not forced to do it.My rule of thumb: always implement a “force update” in your mobile application, let it check regularly or at startup if it is still up to date and if not refuse to start and request update to user.That will allow you to synchronize its update with the underlying API.Wait for the right momentA corollary to the “make it backward compatible even that is not totally clean” strategy is to wait for the right moment.I always recommend to the team I work with to let their API live and evolve possibly introducing API design compromises.Then after a while, once they have sufficient experience with the domain of the API and if there’s a killer new feature to introduce, that’s the right moment to clean all this mess and break everything.Create a separated new API and migrate (or not)Breaking everything does not actually mean removing the previous version of the API.You can create a new one and then request consumers migrate to the new version.There are many things to say about that, we’ll talk more about API versioning and its implication in a later post.Include breaking change policy in your terms of servicesAnd last tip, don’t forget to include your breaking change policy in your terms of service: how you define a breaking change, when you’ll warn people about an upcoming one and how long time they’ll have to migrate to a new API version if they have to.Depending on your context, you may not want to let consumers stay on an outdated previous version for too long but think about their context, below a year could be tricky for many consumers as their budget are annualized.Note while that’s a must have for a public/partner API that you sell to people outside of your organization, it that could be interesting to define terms of service including such policy for your private APIs too."
},{
    "id": "25",
    "type": "post",
    "title": "Pink Fluffy Unicorn API? WTF? (or 3 reasons why choosing a not meaningful API name can be a problem)",
    "url": "https://apihandyman.io/pink-fluffy-unicorn-api-wtf-or-3-reasons-why-choosing-a-not-meaningful-API-name-can-be-a-problem/",
    "banner": "https://apihandyman.io/images/pink-fluffy-unicorn-api-wtf-or-3-reasons-why-choosing-a-not-meaningful-API-name-can-be-a-problem/banner.jpg",
    "description": "It is usually considered a terrible practice to name a property or a function with a meaningless name when writing code. But surprisingly, when it comes to choosing application or API name, some people tend to choose names in a more artistic way (says the “API Handyman” who can name some tool “OpenAPI Chainsaw”). So let’s see 3 reasons why choosing a not meaningful API name can be a problem.",
    "body": "It is usually considered a terrible practice to name a property or a function with a meaningless name when writing code.But surprisingly, when it comes to choosing application or API name, some people tend to choose names in a more artistic way (says the “API Handyman” who can name some tool “OpenAPI Chainsaw”).So let’s see 3 reasons why choosing a not meaningful API name can be a problem.This post is a follow up of a tweet I did a few weeks ago: “Pink Fluffy Unicorn” is a cute but totally wrong name for an API unless it actually deals with pink fluffy unicorns. Please choose a meaningful name that tells what the API does.Someone asked some arguments to back this statement because they seem to have to deal with such cute but counter-productive if not dangerous naming strategy.And I realized that I have never formalized my thoughts on this topic, hence this post (thanks so much Twitter people!)Very special thanks to @mrlapingdesign for drawing this post’s banner.It needs explanationsFirst and most obvious reason why choosing a not totally meaningful name is a terrible idea: it needs explanations.When starting a new job in a another company/organization, don’t you ever have grumbled when discovering that all internal tools such as the credential manager or the leave management tool have totally awkward not obvious names?Of course, after someone explained you all that (for the 99th time) and if you use them everyday, you may remember their names.But your new colleague, who arrived a few months later, will also struggle to understand what does what at the beginning.And someone will have to explain all that (again, for the 100th time).And if you don’t use them often, you’ll forget their name and struggle to find them when you desperately need them.And that applies to anything, including APIs.If I’m looking for the API managing users, I will not search for Pink Fluffy Unicorn API.And if I’m looking for the API managing file transfers, I will not search for Blue Fluffy Unicorn API.When I see a Pink Fluffy Unicorn API, I have absolutely no clue about what it does by just reading its name, and that is really annoying.Of course, some may object that I could use our awesome API catalog search engine or read the documentation to see that, so using such a not so meaningful name may not be such a big problem.Maybe, so let’s see the second reason, which is major no-go for me.It does not set boundariesSecond reason why choosing a not totally meaningful name is a terrible idea: it does not set boundaries.And that’s a major concerns.Indeed, a well defined and designed API is supposed to be a independent set of operations covering a meaningful set of related use cases.If this set of operations don’t have a meaningful name such as User but is named Pink Fluffy Unicorn, what stops someone to add new features related to a completely different topic such as file transfers?What stops someone transforming this well defined API into a big ball of mud, a do-it-all API that will make no sense at all and be more complex to maintain?What stops someone to create a dangerous mixtures composed of internal facing and external facing operations.Not its name.Some experienced API designers and developers having working in the team for quite a long time, taking their time to think, actually knowing the purpose of the Pink Fluffly Unicorn, probably won’t do such a mistake but what about beginners or people in a rush?Using a meaningful name creates boundaries that will make most people think twice before adding new features into an API while a meaningless name will open doors to anything.It is possibly a sign of API design smell    Ce que l'on conçoit bien s’énonce clairement, Et les mots pour le dire arrivent aisément (What is well understood is clearly stated, And the words to say it come easily)        Nicolas Boileau-Despréaux, L'art poétique    The third reason why choosing a not totally meaningful name is a terrible idea is a corollary to the second one: it can be a sign of API design smell.Did you choose a meaningless name because you’re actually unable to find a meaningful one?We all know that choosing names is hard, but if you are really struggling to find a meaningful name for your API, your API Designer senses should tell you that there’s something wrong. That could mean your API is not solving the good problem, or solving too much problems or not enough of them.Easily finding a meaningful name can comfort your vision of the use case/problems you’re trying to solve with it.Sometimes you have to deal with itThere are cases where a domain, a team or a tool has a not so meaningful name that you would like to keep for reasons such as not totally changing people habits.Indeed, some people working there for a long time know what means Pink Fluffy Unicorn.So how to satisfy newcomers and seasoned colleagues?In such a case you can use a middle ground approach and name your API(s) “Pink Fluffy Unicorn - Meaningful Name”.That way you ensure seasoned colleagues won’t be surprised.But most important you ensure that your API surface (your APIs) is well defined (not a big ball of mud) and understandable by newcomers.Icing on the cake, you also ensure that people easily connect APIs together which can be interesting in a big organization or when providing public/partner APIs (“Twilio” doesn’t mean anything to me but I can get what the “Twilio Messaging API” does)."
},{
    "id": "26",
    "type": "post",
    "title": "Choosing HTTP status codes Series - Part 4 - Empty list, HTTP status code 200 vs 204 vs 404",
    "url": "https://apihandyman.io/empty-lists-http-status-code-200-vs-204-vs-404/",
    "banner": "https://apihandyman.io/images/empty-lists-http-status-code-200-vs-204-vs-404/banner.png",
    "description": "When designing APIs, choosing HTTP status codes is not always that obvious and prone to errors, I hope this post series will help you to avoid common mistakes and choose an adapted one according to the context. This fourth post answers the following question: given that /users is a collection (a list) and no users are named Spock, what should return GET /users?name=spock? 200 OK, 204 No Content or 404 Not Found",
    "body": "When designing APIs, choosing HTTP status codes is not always that obvious and prone to errors, I hope this post series will help you to avoid common mistakes and choose an adapted one according to the context.This fourth post answers the following question: given that /users is a collection (a list) and no users are named Spock, what should return GET /users?name=spock? 200 OK, 204 No Content or 404 Not Found      Choosing HTTP status codes Series                      When designing APIs, choosing HTTP status codes is not always that obvious and prone to errors, I hope this post series will help you to avoid common mistakes and choose an adapted one according to the context.&lt;div class=\"alert alert-info\"&gt;I never remember in which RFCs HTTP status codes are defined.To get a quick access to their documentation, I use Erik Wilde’s Web Concepts.&lt;/div&gt;Very special thanks to all Twitter people participating to the #choosehttpstatuscode polls and discussions                                                      1 - This is not the HTTP method you're looking for, HTTP status code 404 vs 405 vs 501                                      2 - Hands off that resource, HTTP status code 401 vs 403 vs 404                                      3 - Move along, no resource to see here (truly), HTTP status code 204 vs 403 vs 404 vs 410                                      4 - Empty list, HTTP status code 200 vs 204 vs 404                                      The contextWhen you need to represent lists (aka collection resources) in a REST/RESTful/RESTish API, a usual design pattern is to represented with them a /resources (or /resource, read /resources rules and /resource sucks … or is it the other way around?).More often than not, you’ll need to be able to return a subset of the list’s elements.To do so, a usual (if not standard) design pattern is to add query parameters to provide search filters.If a GET /users is supposed to return a list containing all (actually accessible to the consumer and possibly to the end user) users, a GET /users?name=spock is supposed to return a list containing only the users whose name is spock.The question we will answer today basically is: which HTTP status code respond with when returning an empty list.            According to my Twitter pool, 51% of respondents would return a 200 OK, while 24% would return a 204 No Content and 25% would return a 404 Not Found.Let’s see what could be the correct answers according to RFC(s) and common practice.The obvious 200 OK    The 200 (OK) status code indicates that the request has succeeded.        RFC 7231 Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content, section 6.3.1    Let’s start with the most common and valid response in such a case: 200 OK.When responding to GET /users, the API will respond with that HTTP status code along with a list of all (actually accessible to the consumer and possibly to the end user) users users.When responding to GET /users?name=smith, the API will respond also that with HTTP status code along with a list contains all users named smith.And finally when responding to GET /users?name=spock and if there are no user name spock, the API will respond yet another time with that HTTP status code but this time along with an empty list.That is actually the most common response I have ever seen, probably because most people consider that the /users collection/list resource exists and name query param is used to filter the content of the list.But there is a more specific HTTP status code that could do the trick too.The not so current 204    The 204 (No Content) status code indicates that the server has successfully fulfilled the request and that there is no additional content to send in the response payload body.        RFC 7231 Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content, section 6.3.5    While 200 OK being a valid and the most common answer, returning a 204 No Content could make sense as there is absolutely nothing to return.It is indeed more often used when responding to a PUT (replace) or a PATCH (partial update), when servers don’t want to bother returning the replaced/updated resource or on a DELETE because there is usually nothing to return after a deletion.But it can be used on a GET too.If the request is valid, has been successfully fulfilled and if there is no additional content to send (which is the case as the returned list would be empty),  204 No Content is perfectly understandable and valid answer.It’s a valid response but I personally will not use it and do not recommend to use it in that case in my context.Because it is not that common (based on my experience, it’s not absolute truth) and may imply more work.Actually, I try to avoid using specific/uncommon HTTP status when a more generic/common one works too, that usually simplifies consumer’s job and also designer’s one as there are less possible choices and behaviors (I’ll write a post about that).Though a consumer must be able to interpret any 2xx as as success and fallback to treat it as 200 OK, that means there will be no response body, so no empty list.That could easily lead to to possible “null pointer exception” or any equivalent requiring more controls in code.A 200 OK with an empty list can be treated the same as non empty list without thinking about it.Note that, consumer may obviously have to check il the list is empty or not to possibly show a message to end user, but the exact same code will work without that control.But while simplifying choices, note that using that “simplified HTTP” stance, you’ll loose some “HTTP semantic out of the box”. Indeed tne major argument in favor of 204 No Content is that is allows to check empty search results (especially in logs) vs non empty ones without relying on specific response body’s semantic.That’s quite an interesting feature.Maybe we need more APIs actually fully using HTTP semantic to make this 204 No Content response more common and a no brainer.So choosing between 200 OK and 204 No Content, depends on you and your context.The not recommended 404    The 404 (Not Found) status code indicates that the origin server did not find a current representation for the target resource or is not willing to disclose that one exists.        RFC 7231 Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content, section 6.5.4    I just realized that’s the fourth post in this series and 404 Not Found has been involved in all posts so far.Let’s see what say the HTTP RFCs (with an s) about using it in that use case.If we look at this status code definition in RFC 7231 and if we consider that /users is the resource used even when doing a GET /users?name=spock, returning that HTTP status code makes no sense at all because the resource /users exists, it’s just that the list it contains may be empty.But is this definition of a resource identifier (excluding query parameters) is actually the correct one?Section 2 of RFC 7231 states each resource is identified by a Uniform Resource Identifier (URI), as described in Section 2.7 of RFC 7230.That section 2.7 of RFC 7230 says the “query” (what is between the first ? and #) is a part of the resource identifier.If we follow the link (it’s quite a maze!) conducting to complete description of the query, we eventually arrive at Section 3.4 of RFC 3986 that says the query component contains non-hierarchical data that, along with data in the path component (Section 3.3), serves to identify a resource.That basically means that /users?name=spock is a resource identifier, so returning 404 is valid according to HTTP RFCs if we want to say “sorry no resource match the strict identifier provided in your query” or “there is no such a users list containing users named spock”.But using that HTTP status code being valid from a pure HTTP perspective, is it actually a good idea to use it in that use case?In my humble opinion, based on my experience designing APIs, reading and listening to many API practitioners, analyzing many APIs and doing hundreds of API design reviews, I do not recommend to use it in that case because that would break a common practice.In most REST/RESTful/RESTish APIs, a “resource identifier” is actually the resource path without the query part, that may be wrong when speaking strictly HTTP but that is the current state of common practice.In most APIs, 404 Not Found is strongly attached to “there is nothing for the requested path (excluding query parameters)”.It is returned in case involving /path-that-does-not-exist or /collection/{id that does not exist} (see Choosing HTTP status codes Part 2 - Hands off that resource, HTTP status code 401 vs 403 vs 404 or Choosing HTTP status codes Part 3 - Move along, no resource to see here (truly), HTTP status code 204 vs 403 vs 404 vs 410) but not for empty lists (that’s usually a 2xx Success class).Also, returning a 4xx Client Error Class says that consumer made an error, is that really the case here?I don’t think so, the consumer just provided search filters that don’t match any element in a list.That’s my reasoned opinion of not using 404 Not Found for empty lists, but if you have valid reasons to use this HTTP status code for this use case, don’t forget to be consistent and provide informative error feedback.Indeed, if we take for granted that GET /users?name=spock returns a 404 Not Found if there are no users named spock.What about GET /users if there are no users at all? It should return the same HTTP status code.And differentiating this it from a more common /path-that-does-not-exist will require to add some information in the response body to explain the actual cause of this response.DX above allThe lesson of today is that following the HTTP protocol is one thing but there are sometimes various options with pros and cons and sometimes being overly strict can lead to design that are less easy to understand.The question is not about achieving the most perfect design (regarding HTTP) but just achieve a design that makes sense for most people involved and proposes the best as possible DX.And that D in DX includes developers but also designers.Simple design rules that makes sense for most are a key factor in your APIs success."
},{
    "id": "27",
    "type": "post",
    "title": "Generating OpenAPI Descriptions. When is it a good idea?",
    "url": "https://apihandyman.io/generating-openapi-descriptions-when-is-it-a-good-idea/",
    "banner": "https://apihandyman.io/images/generating-openapi-descriptions-when-is-it-a-good-idea/banner.jpg",
    "description": "As a follow up of my “6 reasons why generating OpenAPI sucks” post, I had the pleasure to talk about “is it a good idea to generate OpenAPI descriptions?” with Erik Wilde. In this discussion, we answer this questions at various stages of the API lifecycle: design time, code time, and runtime.",
    "body": "As a follow up of my “6 reasons why generating OpenAPI sucks” post, I had the pleasure to talk about “is it a good idea to generate OpenAPI descriptions?” with Erik Wilde. In this discussion, we answer this questions at various stages of the API lifecycle: design time, code time, and runtime.Watch on Erik Wilde’s Youtube Channel"
},{
    "id": "28",
    "type": "post",
    "title": "/resources rules and /resource sucks ... or is it the other way around?",
    "url": "https://apihandyman.io/resources-rules-and-resource-sucks-or-is-it-the-other-way-around/",
    "banner": "https://apihandyman.io/images/resources-rules-and-resource-sucks-or-is-it-the-other-way-around/banner.png",
    "description": "Using singular or plural to represent a list of something is an old debate in computer science, especially in the database field. But what about APIs then? It’s still the same, if you look at various APIs, you’ll see that something like “list/search resources” could be either represented by a GET /resources or a GET /resource. Who is right? Who is wrong? I have a preference, you may have another, but should we really give importance to such a debate? Aren’t we missing something? Let’s investigate that topic and discover what’s really important when choosing collection resource path.",
    "body": "Using singular or plural to represent a list of something is an old debate in computer science, especially in the database field.But what about APIs then?It’s still the same, if you look at various APIs, you’ll see that something like “list/search resources” could be either represented by a GET /resources or a GET /resource.Who is right?Who is wrong?I have a preference, you may have another, but should we really give importance to such a debate?Aren’t we missing something?Let’s investigate that topic and discover what’s really important when choosing collection resource path.Is there a “right” REST solution?Regarding choosing between /customer and /customers, I often meet people who ask me “is whatever solution RESTful?” which basically means “what is the right solution?”.When doing a choice, I always try to refer to a RFC, standard or common practice in order to make the “right” choice.So, let’s see what the REST Architectural Style dissertation says about that.In short, REST is an architectural style which has been created by Roy Fielding to explain how distributed applications should interact with each other.He did that to explain how the HTTP protocol work and analyze factually the impact of its possible evolutions.Actually, he chose to describe factually a model and confront others ideas to this model, rather than just saying “my way is the best”, which is something that we all should think about.This architectural style defines a set of constraints (client/server separation, statelessness, cacheability, layered system, uniform interface and code on demand)that a REST system must conforms to.REST APIs (or RESTful) APIs are supposed to embrace the REST Architectural Style and its constraints.Actually, this more often than not means those APIs try to conform more or less to HTTP semantic without thinking too much about all REST constraints.Speaking of constraints, does Mr Fielding dissertation talks about choosing resources paths?Resource paths (or resource identifiers) are not precisely identified as a constraint but there are some guidance provided:    The definition of resource in REST is based on a simple premise: identifiers should change as infrequently as possible. Because the Web uses embedded identifiers rather than link servers, authors need an identifier that closely matches the semantics they intend by a hypermedia reference, allowing the reference to remain static even though the result of accessing that reference may change over time. REST accomplishes this by defining a resource to be the semantics of what the author intends to identify, rather than the value corresponding to those semantics at the time the reference is created. It is then left to the author to ensure that the identifier chosen for a reference does indeed identify the intended semantics.        Roy Fielding, Architectural Styles and the Design of Network-based Software Architectures    For what matters in this post, this could be summarized by saying resource identifiers (or path) should change as infrequently as possible and it is up to the author to choose the most adapted semantics.So as you can see, nothing about singular or plural, according to the REST architectural style, it’s up to us to choose as long as it means something.What is sure: don’t do bothSo according to REST principles, /resources or /resource, you can choose the one you like.But you have to choose one, you can’t use both, for the sake of consistency and predictability.Indeed, it would be quite awkward to do GET /customers to search or list customers and a GET /order to list orders.APIs are supposed to be consistent with themselves and other APIs of the same domain/organization.Choose one format, write it down in your API design guidelines and ensure that everyone designing APIs in your organization stick to this choice.And for those who would come to the idea of using GET /customers to search or list customers and a GET /customer/{customerId} to read a specific customer, because “oh, we are reading a single element so let’s go singular now”.Please don’t do that.If people do a GET /whatever to get a list of whatever they’re used to brainlessly do a GET /whatever/{whateverId} to get a specific element.You’ll disturb many people by breaking habits.But there are more than habits involved here, doing that simply breaks the semantic of paths.In a file system, do folder names change when you target a file inside them?In a database, do you change table name when doing a select * where id=whateverId?No.So, please chose one side or the other, no middle ground here.My reasoned opinion: pluralI use plural names for collections mostly because of semantics: plural means “it contains multiple elements”. Note that I use plural in both path (/customers is a path of collection resource) but also in data models (customers is a property representing a list of customers inside a data model).Using plural name for a collection also avoid surprise when having singleton resources, for instance GET /customers/{customerId}/address, I know by reading this that I’ll manipulate a single address and not a list of address.That’s the main reason why I’m not using singular.Using singular for collection name would make that less obvious, though the data returned by a GET /customer/{customerId}/address would give more than a hints about what is actually returned (list or single element).But that requires to trigger a read operation call to know that (if we don’t rely on documentation at all).But let’s be objective, the plural option is not without drawbacks.Obviously as a machine getting data containing a customerId (singular) and trying to guess how the API work without taking advantage of the documentation, I have some work to do to “know” that the plural of customer is customers in order to try a GET /customers/{customerId} (which is quite simple here but determine singular or plural is not always that simple).But if your API is a true REST API that shouldn’t be a problem because it provides the ready to use links to other resources.Problem solved if that’s actually a problem, which is not the case most of the time.Indeed most people don’t care about hypermedia nor automatic API discovery and rely on the API documentation to write code that actually use the API (even for testing).Regarding the singular option, I also wonder how then would be called a customer list inside a data model?I would probably add a suffix (customerList) but then that introduce inconsistency between path and data, that is another reason why I prefer the plural option.The truth is elsewhereI think the lesson to learn here is not determining which one is “better” between /resources and /resource, I’m sure someone using singular name has plenty of good reason doing so.No, the lesson here is that when there is non refutable standard solution, you have to reason to choose one that makes sense.Avoid “just because” solutions that you can’t explain.Avoid at all costs “wtf” solutions (like GET /customers + GET /customer/{customerId}) introducing complexity or inconsistency.And don’t forget to put it in your guidelines and ensure that everyone in your organization stick to that decision for the sake of consistency."
},{
    "id": "29",
    "type": "post",
    "title": "Choosing HTTP status codes Series - Part 3 - Move along, no resource to see here (truly), HTTP status code 204 vs 403 vs 404 vs 410",
    "url": "https://apihandyman.io/move-along-no-resource-to-see-here-seriously-http-status-code-204-vs-403-vs-404-vs-410/",
    "banner": "https://apihandyman.io/images/move-along-no-resource-to-see-here-seriously-http-status-code-204-vs-403-vs-404-vs-410/banner.png",
    "description": "When designing APIs, choosing HTTP status codes is not always that obvious and prone to errors, I hope this post series will help you to avoid common mistakes and choose an adapted one according to the context. This third post answers the following question: given that resource with id 123 actually doesn’t exist in the underlying database, what should be the response to GET /resources/123 when consumer is allowed to access such ressource? 204 No Content, 403 Forbidden, 404 Not Found or 410 Gone?",
    "body": "When designing APIs, choosing HTTP status codes is not always that obvious and prone to errors, I hope this post series will help you to avoid common mistakes and choose an adapted one according to the context. This third post answers the following question: given that resource with id 123 actually doesn’t exist in the underlying database, what should be the response to GET /resources/123 when consumer is allowed to access such ressource? 204 No Content, 403 Forbidden, 404 Not Found or 410 Gone?      Choosing HTTP status codes Series                      When designing APIs, choosing HTTP status codes is not always that obvious and prone to errors, I hope this post series will help you to avoid common mistakes and choose an adapted one according to the context.&lt;div class=\"alert alert-info\"&gt;I never remember in which RFCs HTTP status codes are defined.To get a quick access to their documentation, I use Erik Wilde’s Web Concepts.&lt;/div&gt;Very special thanks to all Twitter people participating to the #choosehttpstatuscode polls and discussions                                                      1 - This is not the HTTP method you're looking for, HTTP status code 404 vs 405 vs 501                                      2 - Hands off that resource, HTTP status code 401 vs 403 vs 404                                      3 - Move along, no resource to see here (truly), HTTP status code 204 vs 403 vs 404 vs 410                                      4 - Empty list, HTTP status code 200 vs 204 vs 404                                      The contextLet’s say your are creating an API for a library, obviously you’ll design a GET /books to search for books and a GET /books/{isbn} to get detailed information about a book.You did use an International Standard Book Number because such a unique and universally known id is far more convenient than an opaque bookId generated by your implementation.Indeed using standard/well known values for resource identifiers makes an API more interoperable and usable in other contexts than yours.Design digression is over, let’s get back to the true topic of this post: choosing an HTTP status code.A library may not own all books that have been published on earth , end users may also simply mistype an ISBN or books may have been removed from the library.What should be the response to a GET /books/{not known, totally wrong or not present anymore ISBN}?            According to my (vague) Twitter poll (which was not explicitly talking about the removed use case), 94% of respondents would return a 404 Not Found, while 4% would return a 403 Forbidden and 2% would return a 410 Gone.Note also that, in the discussion, some people mentioned returning a 204 No Content.Let’s see what could be the correct answer(s) according to RFCs.No brainer, use 404    The 404 (Not Found) status code indicates that the origin server did not find a current representation for the target resource or is not willing to disclose that one exists.        RFC 7231 Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content, section 6.5.4    Let’s start with what is the most common and valid response in such a case: 404This HTTP status code reason Not Found is both obvious and actually means what everybody thinks it means (which is not always the case).In our case a GET /books/{totally wrong ISBN} must return a 404And that must be your favorite response when consumer is requesting something that doesn’t exist, not only because RFC 7231 says so, but also because people are used to get that response in such a case.Being consistent with the rest of the world is a rule of thumb when building APIs (or whatever).Though people are used to it, there can be some subtleties that requires a more specific HTTP status code when signifying “that doesn’t exist”.Has existed and can do something about it, you may use 410    The 410 (Gone) status code indicates that access to the target resource is no longer available at the origin server and that this condition is likely to be permanent.        RFC 7231 Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content, section 6.5.9    In our case a GET /books/{\"book that once has been in library but is no more\" ISBN} could return such a status code, especially if the end user is a librarian who deleted a book by mistake.Digression: A regular library user may get a 404 Not Found for the same request.That means that your API may return different responses depending on who is the consumer/end/user.Your database state is not your API data state, the data returned by an API may not be exactly how they actually are in the underlying database (we already have seen that in previous post).It’s not unusual to use a soft delete when removing something from a database and so simply flag it as “deleted” but keeping the data.There are many reasons to do that, regulations like GDPR may force you to do so (though you should move such data in another database) or you may want to propose an “undo” possibility.A 410 could also be a good response to a request made on an expired temporary URL (that was valid only for a short period of time, that reminds me to write a post about signed URLs).Whatever the reason of signifying that something actually existed, you may return a 410 Gone if and only if consumers can do something about it (like undoing something or requesting a new temporary URL). But in that case you should provide information about what they can do about it and how (in response body or at least in documentation).No scopes, rights or privilege involved, don’t use 403    The 403 (Forbidden) status code indicates that the server understood the request but refuses to authorize it.  A server that wishes to make public why the request has been forbidden can describe that reason in the response payload (if any).        RFC 7231 Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content, section 6.5.3    In our library use case there are no scopes/privileges/rights involved, a GET /books/{wrong ISBN} will never ever return a 403 Forbidden but a 404 Not Found.A GET /books/{has existed ISBN} may return a 410 Gone as seen in previous section.It’s only after that, when trying to undelete the book, maybe with a PUT /books/{\"book that once has been in library but is no more\" ISBN}, that the response could be a 403 Forbidden if librarian is not allowed to to so.If privileges/rights are involved when accessing resources (either WHATEVER /books/{isbn} in general or a specific WHATEVER /books/{specific isbn}), a 403 may be returned, you should read Choosing HTTP status codes Part 2 - Hands off that resource, HTTP status code 401 vs 403 vs 404 to learn more about that.It’s a consumer error, don’t use 204    The 204 (No Content) status code indicates that the server has successfully fulfilled the request and that there is no additional content to send in the response payload body.        RFC 7231 Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content, section 6.3.5    Obviously, I didn’t include 204 No Content in the poll because Twitter only allows 3 choices … Well to be honest, though I often meet people wanting to use it that way, I totally forget it for that poll 😅 (and would probably had propose it instead of 403 Forbidden).The No Content reason may fool you, but the description is quite clear, it doesn’t mean “there’s nothing for this path” but “these is something for this path but not content to return”.Also that HTTP status is a 2xx Success class, it is not intended to signify that something went wrong which is the case here, consumer did send a non existing/wrong resource id.So you should avoid using it in such a case."
},{
    "id": "30",
    "type": "post",
    "title": "6 reasons why generating OpenAPI from code when designing and documenting APIs sucks",
    "url": "https://apihandyman.io/6-reasons-why-generating-openapi-from-code-when-designing-and-documenting-apis-sucks/",
    "banner": "https://apihandyman.io/images/6-reasons-why-generating-openapi-from-code-when-designing-and-documenting-apis-sucks/banner.png",
    "description": "When working with OpenAPI Specification documents to design and document APIs, there are two approaches: either you write it (directly using a text editor or indirectly using an API design GUI), either you generate it from the implementation’s code (using annotations). Generating OpenAPI Specification documents from code has major drawbacks that you should be aware of in order to choose this approach knowingly.",
    "body": "When working with OpenAPI Specification documents to design and document APIs, there are two approaches: either you write it (directly using a text editor or indirectly using an API design GUI), either you generate it from the implementation’s code (using annotations).Generating OpenAPI Specification documents from code has major drawbacks that you should be aware of in order to choose this approach knowingly.If you know me, have seen me talking at conferences, have read my posts or my book, you know what is my favorite approach (spoiler: the “write it” one).But as an API design reviewer I work with many different teams: some use the first approach and others the second one and some use both.Slowly but surely, the write it approach is gaining ground.I am pleased to see new teams I have never work with before are already convinced that writing OpenAPI (when design and documenting) is a better approach for them.And I am even more pleased to see some who were using the “generate it” approach switching to other other one, convinced by my reasons and the problems their encountered.I thought it could be interesting to share the 6 main reasons why people would stop to use the “generate it” approach and switch to the “write it” one, hence this post.Complicates designThe first reason is that generating OpenAPI from code complicates design.Indeed, you need to write actual implementation’s code to get something.You need a fully functional development environment to code and build a more or less empty API’s implementation’s skeleton.And not everybody who work on the design of an API can write code.That may be strange to your eyes, but there are places where developers of an API’s implementation are not the one who will actually design the API, business analysts may have that role.They work closely with developers but they are the one who actually write the API’s contract.There are places where those people may work more closely together, contributing to the same OpenAPI document, that would be quite complicated to do that with a generated one if one of them don’t code.Some would argue that “writing” OpenAPI is like writing code.Until not so long ago, you would need to know the syntax to actually write it, but that’s not true anymore.There are API design GUI that allows anyone (with basic HTTP knowledge) to describe an API without having to write a single line of YAML (or JSON for the most masochistic).Forces to choose development stackThe second reason is an annoying side effect of having to write actual implementation’s code to get something.To write code, you actually have to choose a development stack.When you are working on a totally new software solution making such decisions too early during the overall solution’s design phase may reveal to be a problem.Indeed, you may realize that the chosen stack was not the more adapted one once you have a full view on what the API is supposed to do and so the written code must be thrown to garbage.Obviously if that’s just “yet another API in familiar environment”, that reason is null and void.Lessens design qualityHaving to write code, especially on an existing application, risks to lessen the API design quality because it may lead to being “inside out” or also less accurate.An inside out API design brutally exposes what is happening under the hood resulting in less easy to understand, less easy to use, less easy to evolve APIs.Seeing existing functions, existing databases, you may be tempted to expose them as is without rethinking them.That will lead to consumers needing to know how your implementation works when they shouldn’t, leading to tight coupling with them crippling the possibility of evolutions on your side.Being polluted by existing implementation or purely development oriented concerns, not only will you expose the engine that should be hidden but you may take shortcuts resulting in less accurate design.Indeed, for instance, you may choose wrong resources, wrong operations, wrong granularity for an operation or data model or you may simply miss that you should have created a totally new API; all that simply because you were too close to the existing code or data.Such design will obviously also be less easy to understand, less easy to use, less easy to evolve APIs.Casts doubt upon implementationThe big argument of the generate it approach is “no need to synchronize spec and code anymore!”.Yes that’s true, but that also means you don’t have an independent source of truth for your API’s contract.Whats was agreed on during the design phase may not be what is actually implemented in the end.Without a source of truth independent from actual code, there’s no way to test that what is implement is actually ok.A long time ago, having working with third party contractors building applications for my company that revealed to be a major problem.And even when working with the family, some errors or modifications may happen inadvertently.Complicates writing documentationDevelopers who love to write documentation raise your hands!Not so many hands risen (that’s a pity, but that’s another story).This reason is similar to the first one “Complicates design”.When working on APIs, people who write the documentation may not be the one who write the code (and note also they may not be the one who do the design).Doc writers may not want to write code and developers may not want to have people mingling with their codebase.Lessens documentation qualityYou may not know it but pushing the OpenAPI Specification to its limits allows to write totally awesome API documentation that everyone will love (writing about that is on my to do list).That’s especially interesting for private APIs, indeed you may not want to do the same level of effort regarding developer portal and producing content.A complete OpenAPI shown in Redoc, Stoplight Elements or even SwaggerUI will do the trick at almost 0 cost.But producing such specification requires to uses all the OpenAPI Specification subtleties and unfortunately not all (if not no) generator allows that (and not all developers are willing to do such effort in their code, because previous reason).You may possibly tweak what the generator does to achieve some interesting modifications but at what cost?Whatever you do, generating code irremediably results in less expressive and less complete OpenAPI documents.So generating OpenAPI sucks?That’s not what I said, what you should retain from this is is that there are concerns to be aware of when generating OpenAPI Specification from code when designing and documenting API.OK, the post’s title says “suck”, that’s a clickbait (for totally honorable reasons 😅).Actually and as always, it’s not a matter of right or wrong, it’s a matter of choosing a solution to a given problem according to a context and living with the consequences.If in your context, people who design, code, and document are the same or are ok to work with code.And if people working on design are sufficiently experimented to not be polluted by existing code and data.And if you’re confident that there will be no variation during implementation.And if you don’t need all OpenAPI subtleties for your API documentation (and frankly, for private APIs, you can live with that).You may generate your OpenAPI documents from code.If not, you may have to rethink your strategy or if it’s too complicated decide knowingly to live with the risks listed in this post.And regarding “generating OpenAPI” in general there are use cases where it’s incredibly interesting to do it.But that’s another story."
},{
    "id": "31",
    "type": "post",
    "title": "Choosing HTTP status codes Series - Part 2 - Hands off that resource, HTTP status code 401 vs 403 vs 404",
    "url": "https://apihandyman.io/hands-off-that-resource-http-status-code-401-vs-403-vs-404/",
    "banner": "https://apihandyman.io/images/hands-off-that-resource-http-status-code-401-vs-403-vs-404/banner.png",
    "description": "When designing APIs, choosing HTTP status codes is not always that obvious and prone to errors, I hope this post series will help you to avoid common mistakes and choose an adapted one according to the context. This second post answers the following question: given that resource with id 123 actually exists in the underlying database, what should be the response to GET /resources/123 when consumer is not allowed to access it? 401 Unauthorized, 403 Forbidden or 404 Not Found?",
    "body": "When designing APIs, choosing HTTP status codes is not always that obvious and prone to errors, I hope this post series will help you to avoid common mistakes and choose an adapted one according to the context. This second post answers the following question: given that resource with id 123 actually exists in the underlying database, what should be the response to GET /resources/123 when consumer is not allowed to access it? 401 Unauthorized, 403 Forbidden or 404 Not Found?      Choosing HTTP status codes Series                      When designing APIs, choosing HTTP status codes is not always that obvious and prone to errors, I hope this post series will help you to avoid common mistakes and choose an adapted one according to the context.&lt;div class=\"alert alert-info\"&gt;I never remember in which RFCs HTTP status codes are defined.To get a quick access to their documentation, I use Erik Wilde’s Web Concepts.&lt;/div&gt;Very special thanks to all Twitter people participating to the #choosehttpstatuscode polls and discussions                                                      1 - This is not the HTTP method you're looking for, HTTP status code 404 vs 405 vs 501                                      2 - Hands off that resource, HTTP status code 401 vs 403 vs 404                                      3 - Move along, no resource to see here (truly), HTTP status code 204 vs 403 vs 404 vs 410                                      4 - Empty list, HTTP status code 200 vs 204 vs 404                                      The contextLet’s say you’re creating an API for a mobile application that allows people to record phone calls.Once calls are recorded, users can list them and listen to each individual recording.Listing a user’s recorded calls could be done with a GET /users/{phoneNumber}/calls, for each phone call listed you get a random and unpredictable id that can be used to retrieve the actual audio recording with a GET /calls/{callId}.Basically it means that when a user whose phone number is 123456789 uses the mobile application, the application sends a GET /users/123456789/calls API request to list available recorded calls.The API responds with a 200 OK along with the recorded calls belonging to user.If user taps on one conversation which id is Bnwgab, the application sends a GET /calls/Bnwgab and the API responds with a 200 OK along with the audio fileBut what happens if some curious and maybe malicious user scan network traffic coming out of the application?This hacker will easily understand how this “not so private” API works.With very little effort, they will succeed to generate phone numbers that actually exist in the underlying system so send GET /users/{phone number of another user}/calls requests.And with more effort, enough patience and adapted tools they may even generate valid random some callId and send GET /calls/{callId that don't belong to their user account} requests.In either case, the API should prevent accessing resources that don’t belong to the caller and signify there’s a problem with caller’s request.Note that if that sounds like a no-brainer for many people, that is actually not always the case and some APIs may return a 200 OK along with the requested data.Regularly, stories such as this one (which inspired the above use case) come out.Never forget that when creating APIs and never refrain from double check that your colleagues are also aware of that.And note also that using PII (Personnally Identifiable Information) or other sensitive data as ids can be very convenient but raises security concerns, especially if they appear in URLs as they can be logged almost everywhere.I should write a post series about API security one day (POST /writing-ideas done!).Let’s get back to what we are talking about today: HTTP status codes.Obviously, when consumer make an API call on resource that actually exists but don’t belong to them, the API must respond with a 4xx Client Error Class, but which one could be the more accurate?            According to my Twitter poll, 54% of people would return a 403 Forbidden, while 24% would return a 404 Not Found and also 24% would return a 401 Unauthorized.Let’s see who is right and who is wrong based on what RFCs say.Use 404 when resource is none of consumer’s business (and never will)    The 404 (Not Found) status code indicates that the origin server did not find a current representation for the target resource or is not willing to disclose that one exists.        RFC 7231 Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content, section 6.5.4    Returning a 404 Not Found means “the requested resource does not exists”.Actually, there’s a subtlety, it could mean “the requested resource actually exists but it’s none of your business, you’re not allowed to access it and never will; actually, it does not exist for you” or “the requested resource does not exist at all” but the consumer will never know what is the true reason behind this HTTP status code.That response is the best one for the introduction’s use case, granted that users want to use this application without sharing anything with others.In that case, given that John and Emma use the application, if Emma “hacks” the API, we will never ever want her to know that /users/{John's phone number}/calls may exists.Because they are not supposed to know it exists and even though can’t do anything about it, so better tell her that it “doesn’t exist” (for her).But if 404 Not Found is usually my first idea when a consumer tries to access to a /resources/1234 they shouldn’t (I admit I’m a little obsess with security and prone to not show what is not needed to be shown), there are cases where it could be interesting to let them know the target resource exists.Use 403 when consumer can do something about it    The 403 (Forbidden) status code indicates that the server understood the request but refuses to authorize it.  A server that wishes to make public why the request has been forbidden can describe that reason in the response payload (if any).        RFC 7231 Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content, section 6.5.3    Returning a 403 Forbidden signifies “the requested resource actually MAY exists but you cannot access it. You MAY access it by requesting adequate rights to someone, maybe an administrator for instance”.Even if that is not very realistic, let’s say that the example application/API described in the introduction allows users to share recorded conversations with others. Given John has shared his conversations with Emma but not with Tara, Emma triggering a GET /users/{John's phone number}/calls API call will get a 200 OK while Tara will get a 403 Forbidden. Tara may request John the rights to access his conversations to fix that.We have talk about 403 Forbidden and 404 Not Found, but what about the poll’s third option?Never ever use 401 (don’t be fooled by its reason)    The 401 (Unauthorized) status code indicates that the request has not been applied because it lacks valid authentication credentials for the target resource.        RFC 7235 Hypertext Transfer Protocol (HTTP/1.1): Authentication, section 3.1    As 24% of respondents to my poll, when a consumers tries to access a resource they shouldn’t access, you may be tempted to return a 401 Unauthorized instead of a 403 Forbidden.Why would you do that?Maybe because its reason phrase says Unauthorized.But that would actually be an error, don’t be fooled by that reason phrase.    There are only two hard things in Computer Science: cache invalidation and naming things.        Phil Karlton    There’s a huge problem with 401 Unauthorized, its reason phrase let think that it is tied to “wrong authorization” while it is actually tied to “lack of authentication”.Actually the RFC that defines it is RFC 7235 - Hypertext Transfer Protocol (HTTP/1.1): Authentication… “Authentication” and not “Authorization”.Even the description states that this status is about “authentication credentials”.A 401 signifies there’s a problem with your credentials which usually are provided in an Authorization header (still wrong name, but at least it’s consistent with the reason).This status is made to signify “you forgot to provide an Authorization header with some credentials” or “your credentials provided in the Authorization header are invalid/expired”.In the API world, it basically says “You can’t use the API at all, come back with a valid access token”.It’s not meant to say “You can use the API but not access that resource”, that is the job of 403 Forbidden.And that is clearly stated in its description in RFC 7231 - Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content:    If authentication credentials were provided in the request, the server considers them insufficient to grant access.  The client SHOULD NOT automatically repeat the request with the same credentials.  The client MAY repeat the request with new or different credentials.  However, a request might be forbidden for reasons unrelated to the credentials.To be even more sure that 403 Forbidden is the right answer, let’s talk about Oauth 2 scopes.Indeed, dealing with resource rights access is not always, let’s say “internal business rule” driven (checking in users table that the identified user has the requested phone number for example).When consumers request an access token using the Oauth 2 framework (the token that goes into the not so well named Authorization header), they may request a token restricted to given elements thanks to scopes.For instance, when using the Github API, you may request access to public repo only or to user data only.What should happen when a consumer requests access to a resource without adapted scopes?Section 3.1 of RFC 6750 The OAuth 2.0 Authorization Framework: Bearer Token Usage is quite clear:    The request requires higher privileges than provided by the access token.  The resource server SHOULD respond with the HTTP 403 (Forbidden) status code and MAY include the \"scope\" attribute with the scope necessary to access the protected resource.        insufficient_scope error    HTTP Status code is not enoughThat means two things.First 401 Unauthorized is definitely not an option in the case we are studying today.Second, HTTP status code is not enough.Indeed, 403 Forbidden could be returned because consumer lacks some scope to GET /resources/{resourceId} in general or does not comply to some business rule and cannot GET /resource/1234 (a specific id).Providing a message and maybe some structured data to explained the why of the error and how it can be solved (request access token with scope X in first case or contact some admin in second case) is mandatory.Note that, this made me realized that 403 Forbidden does not actually disclose that a resource exists, it totally depends on what is said beyond the HTTP status code.Don’t forget DX and contextRespecting HTTP and other RFCs is important to avoid surprising developers with behaviors that are against common practices, but most important, whatever the HTTP status code you’ll choose to return, what matters above all is providing the response the most adapted for the context that will actually help the developer (and the consumer and even the end user) to know what is actually happening and help them solve the problem if they can.So, when consumers want to access a resource they shouldn’t, don’t return a 401 Unauthorized, you would go against the HTTP protocol.Instead, return a 404 Not Found if consumers can’t do anything about it (so from their perspective, it does not exist) and return a 403 Forbidden along with a meaningful message if they can request access."
},{
    "id": "32",
    "type": "post",
    "title": "Adopt and not assess OpenAPI linters and other thoughts reading Thoughtworks Technology Radar 24",
    "url": "https://apihandyman.io/reading-thoughtworks-technology-radar-24/",
    "banner": "https://apihandyman.io/images/reading-thoughtworks-technology-radar-24/banner.png",
    "description": "Thoughtworks Technology Radar 24, an “opinionated guide to technology frontiers”, came out last 15th of April, 2021 and I thought it could be interesting to read it from an API perspective, hence this post sharing my thoughts on it. As always it is really interesting and full of valuable insights, though I nearly fell off my chair while reading the Tools section which talks about OpenAPI linters (if it’s not a click bait, I don’t know what it is).",
    "body": "Thoughtworks Technology Radar 24, an “opinionated guide to technology frontiers”, came out last 15th of April, 2021 and I thought it could be interesting to read it from an API perspective, hence this post sharing my thoughts on it.As always it is really interesting and full of valuable insights, though I nearly fell off my chair while reading the Tools section which talks about OpenAPI linters (if it’s not a click bait, I don’t know what it is).What is Thoughtworks Technology RadarThoughtworks is a quite famous software consultancy company, brilliant minds such as Martin Fowler are working there.Every 6 months, they publish their Technology Radar:  The Radar is a document that sets out the changes that we think are currently interesting in software development - things in motion that we think you should pay attention to and consider using in your projects. It reflects the idiosyncratic opinion of a bunch of senior technologists and is based on our day-to-day work and experiences. While we think this is interesting, it shouldn’t be taken as a deep market analysis.Links:  Radar FAQ  Latest Thoughtworks Technology Radar  Thoughtworks Technology Radar Volume 24 (PDF version)While authors claim it’s not a deep market analysis, it’s still full of highly valuable insights that you, as a developer, architect, CTO or whatever is your title should have in mind for your next tech related decisions or simply to discover new tools, language, trends, …In what follows, I picked up a few topics of the 24th edition of this radar that raise my interest from an API perspective (and if you can’t wait to know why I nearly fell off my chair, you can jump to the last section).Reminder, there are no silver bullets in architectureThe Discerning the Context for Architectural Coupling theme is a gentle reminder of what I called “design in context”.Never choose a solution just because this is “the” solution, because depending on the context it could be totally wrong.That works for anything in general and in the API architecture world, that works for instance for “BFF or not” and “REST ot GraphQL or gRPC”.Smoothly evolve your APIsThe radar authors strongly think that people should be adopting the 1. API expand-contract technique (also called parallel change).The API expand pattern allows to introduce a breaking in 3 steps:  Add element  Deprecate what added element replace  Remove once consumers have switchedWhile it’s a totally valid technique, the last step can be tricky if there are many consumers or if there are far from you.You should read what Sam Newman said about the cost of change at API Days Interface 2020.In my humble opinion, working seriously on design and thinking about how your API may evolve will help you avoid having to use this technique.I will not say more for now, writing one or more posts about API change and versioning is on my to-do list.Share between UI and BFF when owning bothThe radar states that the use of 16. UI/BFF shared types is increasing and that companies should try this technique on a project that can handle the risk (trial).That looks like a very good idea as long as both UI and BFF belong to the same team.So don’t ever think about using this technique between UI and regular API, you should be decoupled as much as you can from elements you don’t own.Compute encrypted data to preserve privacyThe first time I heard about the 20. Homomorphic encryption (technique section) was in 2016 at an API conference: The Česká spořitelna bank was using it experimentally to share data with third party.The idea is that using this technique, the encrypted data are still computable.You can send them to an untrusted third party who will do some calculation with them and return you the results that you will decrypt.According to the radar, it became fairly easy to use it.But while having this technique in mind since 2016 and working in the financial industry, I’m still longing to work an API that will allow me to use it.Unleash the power of APIs (while it’s possible)If you want to build an event-driven architecture, you should take a look at Apache Kafka.While being a widely adopted distributed event streaming platform, actually managing it does not seem quite simple.That’s why some companies launch their Kafka as a service offers, they run it, you use it.But as stated in the radar, some companies have gone a little farther and started to offer “Kafka without Kafka”.How is this possible?Only thanks to APIs.APIs (whatever their nature, web, messaging or whatever) offer amazing possibilities when it comes to replace the engine behind the interface.Thanks to these 45. Kafka API without Kafka describes in the Platforms section, you use a service that looks like Kafka but that is actually not.It allows companies to provide their technology similar to kafka to people who are used to it without any modification.From my perspective, the main to understand point here is not about Kafka (though it is actually interesting) but how anyone can provide a service compatible with an existing solution.What is needed is to simply offer the same interface.And, for now, that’s still “possible but check your lawyers are ready” thanks to the recent legal decision in the Google vs Oracle API Copyright case.Beware that Kafka API without Kafka is in “Assess”, it’s worth exploring to understand how it could affect you.Note also that such solutions may not be fully compatible all Kafka featuresLet’s give a try to Fast API Python frameworkI work with data scientists to help them build APIs and they obviously use Python.So, discovering in the Languages &amp; Frameworks section of the radar, a new Python web API framework such Fast API having Thoughtworks seal of approval (86. FastAPI), made my day.Beware, Fast API is still on “Trial” for Thoughtworks, that means “Enterprises should try this technology on a project that can handle the risk”.As I’m starting to work with Python for a complete overhaul of the API Stylebook, a personal project that perfectly can handle such risk, I may give it a try.Adopt and not assess OpenAPI linting (and why I nearly fell off my chair)And last but not least, the radar mentions 2 OpenAPI linters in the tools section:  77. Spectral  79. ZallyThe OpenAPI Specification (fka. the Swagger Specification) is a format allowing you to describe a web API contract.An OpenAPI linter will help you to ensure that the design of an API conforms to your guidelines (or style guide).I know both of these tools for quite a long time now.Zally was the first industrial/high quality OpenAPI linter I encountered but I find it quite complex to use, there’s a cli, a server, you need to use Kotlin to write your rules.And once I discovered Spectral, I totally forgot Zally.A simple npm install -g @stoplight/spectral and you can start.Writing rules is quite simple, though like any “code”, you definitely need to test them.I use it extensively every day while doing API design reviews, check my Augmented API Design Reviewer talk to learn more about it.Note that I prefer Spectral in my context, I find it simpler, I could simply achieve what I wanted easily, it’s integration with Stoplight Studio is very convenient and it constantly evolves.But remember, there are no silver bullets, so test those 2 and choose the one that suits you.While being quite happy to see those 2 OpenAPI linters in the radar, there are 2 problems regarding how this topic is presented in my humble opinion.First, they are in “assess” (worth exploring to see how it will affect you), while I can understand that classification probably based on “how many companies use them”, I definitely think they should be in “adopt” (industry should adopt these items).Designing API is hard, ensuring consistency is hard and such linters participate in simplifying designers job and ensure a certain level of consistency in your API surface.Note that such tools will never, ever replace a human powered API design review.The second problem in the radar is what is said about “specs” and OpenAPI in the Spectral description, and especially this:  While this tool is a welcome addition to the API development workflow, it does raise the question of whether a non-executable specification should be so complex as to require an error-checking technique designed for programming languages. Perhaps developers should be writing code instead of specs?I nearly fell off my chair.This completely misses the point.It leaves readers totally unaware of API design questions and do not help to grasp how they can take advantage of the OpenAPI specification and such a linter to design consistent APIs.That gives a totally wrong perspective of OpenAPI and OpenAPI linters in general, and Spectral in particular.While I met and still meet people who actually are in such state of mind, even don’t giving a 💩 about API design and everything around, I wouldn’t have expected that from a company such as Thoughtworks.I usually succeed to change people mind about this topic, they realize API design and everything around is a thing, but if Thoughtworks tells something different that will make my work more complicated 😅.I would love to know how the authors came to writing this, did I missed something?Hopefully, I was glad to see the discourse about OpenAPI linters is totally different in the Zally’s description and offers the right perspective on the topic.  As the API specification ecosystem matures, we’re seeing more tools built to automate style checks. Zally is a minimalist OpenAPI linter that helps to ensure an API conforms to the team’s API style guide.Maybe it’s due to these particular pandemic times, but it seems that there’s a lack of alignment between the 2 authors of these advices.That second advice on OpenAPI linters is far much better, consider it applies to Spectral too.And if I can add my opinionated 2 cents about API design, OpenAPI and linters:  You MUST have an API design first approach  You MUST write API design guidelines (or style guide) describe the look and feel of your APIs  You MUST use the OpenAPI (or whatever) specification to describe the result of your work on design  You MUST use an OpenAPI (or whatever) linter to ensure your APIs conform to your style guides (and Spectral is a very good tool to do that)  You MUST do an API design review with human beingsConsider all those items should be “Adopt” according to Thoughtworks classification.If you want to learn more about the OpenAPI Specification, API guidelines, API design reviews and Spectral, you should look at my following talks:  OpenAPI Trek  The Lord of API Designs  The API Design Reviewer’s Starter Set  The Augmented API Design Reviewer"
},{
    "id": "33",
    "type": "post",
    "title": "Choosing HTTP status codes Series - Part 1 - This is not the HTTP method you're looking for, HTTP status code 404 vs 405 vs 501",
    "url": "https://apihandyman.io/this-is-not-the-http-method-you-re-looking-for-http-status-code-404-vs-405-vs-501/",
    "banner": "https://apihandyman.io/images/this-is-not-the-http-method-you-re-looking-for-http-status-code-404-vs-405-vs-501/banner.png",
    "description": "When designing APIs, choosing HTTP status codes is not always that obvious and prone to errors, I hope this post series will help you to avoid common mistakes and choose an adapted one according to the context. This first post answers the following question: given that a GET /resources/123 request returns a 200 OK, what should be the response to DELETE /resources/123 if DELETE method is not implemented? 404 Not Found, 405 Method Not Allowed or 501 Not Implemented?",
    "body": "When designing APIs, choosing HTTP status codes is not always that obvious and prone to errors, I hope this post series will help you to avoid common mistakes and choose an adapted one according to the context.This first post answers the following question: given that a GET /resources/123 request returns a 200 OK, what should be the response to DELETE /resources/123 if DELETE method is not implemented? 404 Not Found, 405 Method Not Allowed or 501 Not Implemented?      Choosing HTTP status codes Series                      When designing APIs, choosing HTTP status codes is not always that obvious and prone to errors, I hope this post series will help you to avoid common mistakes and choose an adapted one according to the context.&lt;div class=\"alert alert-info\"&gt;I never remember in which RFCs HTTP status codes are defined.To get a quick access to their documentation, I use Erik Wilde’s Web Concepts.&lt;/div&gt;Very special thanks to all Twitter people participating to the #choosehttpstatuscode polls and discussions                                                      1 - This is not the HTTP method you're looking for, HTTP status code 404 vs 405 vs 501                                      2 - Hands off that resource, HTTP status code 401 vs 403 vs 404                                      3 - Move along, no resource to see here (truly), HTTP status code 204 vs 403 vs 404 vs 410                                      4 - Empty list, HTTP status code 200 vs 204 vs 404                                      The contextIn my Batch (Github) API calls with CSV and Postman runner and visualizer post, I used the Github REST API and discovered it was impossible to delete an issue on a repository with a DELETE /{user}/{repository}/issues/{issueId} request simply because it was not implemented.Unfortunately, the Github API warned me with a quite awkward 404 Not Found though a GET on the very same issue returned a 200 OK that tells “this issue exists”.That’s quite a contradiction.            According to a Twitter poll I made, a few voters (10%) agreed with Github REST API’s 404 Not Found response, most people (56%) would use a 405 Method Not Allowed, but a significant amount (34%) would use 501 Not Implemented.Let’s see which HTTP status code(s) can be used when a resource actually exists but the method provided in the request is not available.Use 405 Method Not Allowed when method isn’t defined in contract    The 405 (Method Not Allowed) status code indicates that the method received in the request-line is known by the origin server but not supported by the target resource.        RFC 7231 Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content, section 6.5.5    A 405 is a 4xx class status code, which means it’s client’s fault.Receiving such a response means the client sent to the origin server a request with a method that is not allowed/supported by the target resource.Let’s rephrase that definition in the context of an API:a consumer will get a 405 Method Not Allowed response when sending a request with a method which is not explicitly mentioned in in the contract or documentation on the target resource.For instance, that means if the API’s contract or documentation states the only method supported by a resource /resource is GET, a consumer sending a request on this resource using any other method, like DELETE /resource for instance, will get a 405 Method Not Allowed response.Therefore, the 405 status code is the one I would have expected from the Github REST API when I tried to delete an issue.Indeed, the API’s documentation describing the API’s contract of the issue resource (/{user}/{repository}/issues/{issueId}) only mentions GET and I sent DELETE.It’s clearly my fault, though it’s quite surprising to NOT be able to delete an issue (but that’s another story).A 405 Method Not Allowed is the right choice when the method is not defined in contract, but sending a “wrong” method is not always consumer’s fault, that’s where a 501 Not Implemented could be interesting.Use 501 Not Implemented when partially implementing a “standard”    The 501 (Not Implemented) status code indicates that the server does not support the functionality required to fulfill the request. This is the appropriate response when the server does not recognize the request method and is not capable of supporting it for any resource.        RFC 7231 Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content, Section 6.6.2    A 5xx class error means the server is at fault.A 501 Not Implemented basically says “we’re deeply sorry but METHOD has not been implemented on this resource and maybe has not been implemented at all on any resource”.Sending a TOTALLY-UNKNOWN-METHOD /whatever-resource could result in getting a 501 if the method does not match any generally known one, but in that case I would prefer to return a 405 Method Not Allowed as it’s not the server’s fault if the consumer really sent a bullshit method in its request and must send an acceptable one.But, imagine you are implementing a “more or less standard” interface contract.It could be because you work in a regulated industry like banking or an highly inter-connected one like travel or logistics.It could be because you want to implement a protocol such as WebDAV, which is a extended version of HTTP adding new methods.It could also be simply because inside your company several components have to share a common interface in order to facilitate communication.Imagine now that standard contract you need to implement says consumer can use GET and PUT on /resource but you only implement GET in your version 1 for whatever reasonable reason.In that case, returning a 501 Not Implemented would be the perfect answer as the “standard” contract says that PUT /whatever-resource is possible but it has not been implemented by the actual provider.If a 501 Not Implemented is a very good answer in such a context of partially implementing a “more or less standard” API, returning a 404 Not Found is totally out of question in any HTTP method related error.Never use 404 Not Found when receiving wrong or unknown method    The 404 (Not Found) status code indicates that the origin server did not find a current representation for the target resource or is not willing to disclose that one exists.        RFC 7231 Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content, section 6.5.4    The Github REST API responded with a 404 Not Found to my DELETE /issue-resource-path request.According to RFC 7231, that tells the issue identified by the path doesn’t exist (A) or Github is not willing to disclose that issue actually exists (B).Unfortunately, both options were contradicted by the GET /issue-resource-path returning a 200 OK.Indeed, getting this 200 tells the issue actually exists (Not A) and Github is willing to disclose it exists (Not B).And even if for any reason I was actually not able to see this issue (we’ll talk about that in a later post) and so get a 404 on my GET, I still would prefer to get a 405 on my DELETE, that way I could have quickly know that whatever the issue I want to delete, I will never be able to delete it as it’s not possible according to the API’s contract."
},{
    "id": "34",
    "type": "post",
    "title": "When unicorn poop hits the fan (or how APIs can improve how we build software)",
    "url": "https://apihandyman.io/when-unicorn-poop-hits-the-fan-or-how-apis-can-improve-how-we-build-software/",
    "banner": "https://apihandyman.io/images/when-unicorn-poop-hits-the-fan-or-how-apis-can-improve-how-we-build-software/banner.png",
    "description": "Do you know what happens when you throw unicorn poop into a fan? It makes everything better, everyone and everything around looks perfect, covered with joy and happiness. Working seriously on (public or private) APIs can lead to the same kind of effect on how we build software. Why? Because modern web APIs raises the bar of software design and developer experience and so raises awareness and expectations regarding these topics for software in general.",
    "body": "Do you know what happens when you throw unicorn poop into a fan?It makes everything better, everyone and everything around looks perfect, covered with joy and happiness.Working seriously on (public or private) APIs can lead to the same kind of effect on how we build software.Why?Because modern web APIs raises the bar of software design and developer experience and so raises awareness and expectations regarding these topics for software in general.Very special thanks to @mrlapindesign for the unicorn poop hits the fan post’s banner.From API design to software design and architectureI help people to design their web APIs in order to help them achieve the creation of APIs that fulfill actual needs and will be easy to understand, easy to use, reusable and evolvable.But my true aim is actually to help them grow their API design skills so they won’t need my help anymore.I have seen API designers improving their skills, switching their stance from design beginners (if not skeptical) just seeking a “validated API design badge”, having basic questions like “should we use a POST or a GET” or “is it /resources or /resource?”, to fully aware design experts focusing on needs, able to challenge their own designs, to evaluate pros and cons of various design options and to bring interesting solutions to new design challenges not covered by guidelines.This is already great, but there’s more to that.From time to time, I meet someone saying “working on API design improved the way I build software”, and that is a sign of “API unicorn poop” actually hitting the fan.Working seriously on API design not only improves the design of our APIs but it helps to better design object data models, database tables, and also messages (Kafka messages deserves to be designed too you know).And beyond data, you can use your API design skills to write better code, better methods or functions, because API design teaches to question inputs and outputs but also needs and business rules in order to produce something that is useful and simple.At upper scale, it also improves our vision of the domain we are working on, helping us to organize it in pieces of software that make more sense for us and the outside world, and so improving the architecture of the system.Working on API design actually improves the whole software stack behind the interface.But modern web APIs are not only about interface contract designFrom developer experience to everyone experienceModern web APIs comes with the concept of DX, Developer eXperience.It’s basically UX, user experience, focusing on developers who choose to use APIs and write code to actually use them.A good API design is mandatory to provide a good developer experience.And that is important not only for public APIs, but also private ones.Unfortunately, it’s not because an API has one of the best in class design that people will want to use it, will be happy to use it.How many promising APIs have been totally crippled by terrible registration process, terrible documentation or loony non-standard security or simply because people were not aware those APIs actually exists.How you find APIs, how simple is their registration process, how clear is the documentation, how standard is their security, how short is the “time to first call”, all those aspects are what will make a terrible or wonderful developer experience.Hit by the “API unicorn poop”, you’ll think about the people who will come after you to work on what you build, you’ll think about the people who may have to run and monitor what you build (not everyone as turn to “full develops, you build it, you run it”, and even so, you’ll think about your team).You’ll start to work on documentation, automation, … you’ll do whatever is possible to ensure that anyone can start to work in a matter of minute if not seconds.Writing documentation, you’ll work harder on its content, its design in order to ensure it is actually user-friendly and people find what they need instantly.You may even start to wonder if it’s reasonable to use 123 different technologies in your picoservices architecture, that could be a real HR nightmare to find people actually mastering that obscure framework or language you choose to use just because.Basically, working seriously on APIs DX, you’ll start to think about user experience of everyone who will have to work one way or another with what you build, whatever it is.Raising expectations, starting a virtuous circleObviously and hopefully, some people in the software industry did not wait the Web API train to think about design and developer experience, but there was still a lot to do in this area when Web APIs became a thing and there’s still much to do even after that.Now working on design and developer experience became a de facto standard when providing public APIs, then it started to contaminate private APIs and I believe it will irremediably contaminate everything in software beyond interface contracts.If I was pessimistic, I would say that companies creating software for themselves or others should sense they can save or earn much money by creating software that fulfill actual needs, are easy to understand, easy to use and reuse, can evolve easily, and offer a overall descent experience.But I prefer to see that from a more optimistic perspective, having been shown empathy and be very happy with that, people will raise their standard, change their perspective and in return build software along with an experience that are as good as the one they’ve encountered.So, please, next time you create a technology, framework, build an application/system for your company, or simply write code, throw unicorn poop in the fan, think about design and developer experience; if you don’t do it for others, do it at least for you.  You'll thank me later  Adrian Monk"
},{
    "id": "35",
    "type": "post",
    "title": "Batch (Github) API calls with CSV and Postman runner and visualizer",
    "url": "https://apihandyman.io/batch-github-api-call-with-csv-and-postman-runner-and-visualizer/",
    "banner": "https://apihandyman.io/images/batch-github-api-call-with-csv-and-postman-runner-and-visualizer/banner.png",
    "description": "Do you need to make a repetitive task that could be done through an API instead of a UI? Do you need to make many API calls but don’t want to code? This post is made for you: you’ll learn to use Postman and CSV files to batch API calls. You may also learn a thing or two about API design, Github APIs (yes, plural) and other Postman features (variables, security, command line, visualizer, …) in the making. If you never have used Postman or Github APIs, no problem, everything will be explained.",
    "body": "Do you need to make a repetitive task that could be done through an API instead of a UI?Do you need to make many API calls but don’t want to code?This post is made for you: you’ll learn to use Postman and CSV files to batch API calls.You may also learn a thing or two about API design, Github APIs (yes, plural) and other Postman features (variables, security, command line, visualizer, …) in the making.If you never have used Postman or Github APIs, no problem, everything will be explained.About the problem and solutionWhile the problem and solution are quite simple, it’s a great occasion to learn many things.The problem to solveI think it’s Garfield, a famous philosopher, who once said Laziness is the mother of invention.Every time I have a repetitive task to do, I always try to find a way to let machine do it for me.As I’m the API Handyman, it often ends by taking advantage of an API.Recently, I had to create many issues in some random issue tracker based on some data in my emails.Hopefully, that issue tracker comes with an API and I could easily get the input data in a structure way by a simple copy/paste from my email client.So instead of having to laboriously fill N times a form, I had to make N API calls with structured data as input, and Postman can help to do that.What you’ll learn while solving itIn order to keep this demonstration easy to redo by anyone, we’ll use the github API to create issues on a dummy public repository with data coming from a CSV file.In this post, you’ll learn to use Postman (UI) and Newman (command line):  Create Postman workspace, collections and requests  Make REST GET and POST (with body) API calls  Define and use variables  Configure a collection to make secured API call  Run all requests of a collection with data coming from a CSV file with Postman  Export collections and environments  Run all requests of a collection with data coming from a CSV file in a terminal with Newman  Make GraphQL API calls  Setup a visualizer to render API call resultsYou’ll also learn use Github REST and GraphQL APIs:  Get a personal access token to call Github APIs (REST or GraphQL)  Get current user data (REST)  List a repository’s issues (REST)  Add an issue to a repository (REST)  Delete an issue (GraphQL)And we will talk about some principles of API design:  Predictable design  Error design  Be careful when copying others (especially famous companies)Setting up Postman for a first Github API callPostman is a wonderful tool that I have been using for many years to make API calls.It has constantly evolved over the years and now supports many cool features; it is now advertized as “The Collaboration Platform for API Development (note: this post is not sponsored by Postman).Go to https://www.postman.com/downloads/ to download and install Postman, if you don’t already have it.You can also use the browser version (but you’ll have to create an account).Our first Github API call will retrieve current user information.Trying to make a first API callLaunch Postman, we’ll create a “Postman CSV Demo” workspace, a “Github” collection, a “List current user” request calling GET https://api.github.com/user (see Github REST API documentation) and make our first call:        In top menu bar, click on         Click on  button        Set workspace name to “Postman CSV Demo”        Change visibility to “Personal”        Click on “Create Workspace” button        Click on  button next to “Postman CSV Demo” workspace name        Click on “Collection” item in the “Create New” window        Change “New Collection” name to “Github”        Right click on the “Github” collection in the left panel and select “Add request”        Change “New Request” name to “Read current user”        Set request URL to https://api.github.com/user, click on  and hit the  button …        … to get a 401 Unauthorized error telling that authentication is requiredGetting a Github personal access tokenThe easiest way to get access to the Github API, if you have two factor authentication activated (and you MUST have it activated), is to generate a personal access token.For our demonstration we will generate one granting access to public repositories:        Go to your Github account settings by clicking on your profile icon and clicking on “Settings” (at the bottom)        Scroll down and click on Developer setting in the left menu        In developer setting page, click on Personal access tokens        Click on Generate new token (you may have to provide your password)        In the “Note” field, type “postman-csv-demo”        Check the public_repo scope under repo. Note that this scopes obviously gives access to public repositories only, if you want to access private ones, you’ll have to check the repo scope (which is less obvious).        Click on  at the bottom of the page        Copy the generated token by clicking on  (use this token with caution, never, ever, commit this value in any public source code repository!)Configuring Authorization in Postman and make a successful first API callHaving an access token, we’ll configure our collection in order to make all requests that it will contain use it.But we will do that in a secure way using an environment variable, it’s a best practice that allows to share collections without the risk of sharing sensitive data:        Click on  button next to \"Postman CSV Demo\" workspace name        Click on \"Environment\" item in the \"Create New\" window        Change \"New Environment\" name to \"Github\"        Add a github_token variable and paste the Github token in its initial value and click outside the field (That should populate also the current value)        Click on  to save the “Github” environment and its github_token variable        In the upper left corner, click on “No Environment” and select the newly created “Github” environment in order to make its variables accessible        Click on the “Github” collection’s name, in the Authorization tab, change Type from “No Auth” to “Bearer Token”        Set token value to {{github_token}} (If the value is red instead of orange, it means the variable is not found. It’s probably because you didn’t select the “Github” environment)        Click on  (if you don’t you’ll get a 401)        Go to the “Read current user” request and hit  again … now it works! You should get a 200 OK response along with your user’s data.Creating one to many issues with Github REST APINow that everything has been set up, let’s list issues and create one to many.We will work with a dummy repository, its URL on Github website will be something like https://github.com/user/repo.To list issues, we’ll send a GET https://api.github.com/repos/user/repo/issues request and to create an issue we’ll to send a POST request on the same URL.Using GET on a collection resource to list things and POST on the same resource to create a thing that totally makes sense, we’ll discover that unfortunately Github API does not always make sense.Listing issuesLet’s first create our dummy repository with UI and list issues with API:        Go to your Github account and create a new public repository, then go to the issues tab and copy the /user/repo/issues part of the newly created repository’s URL        In Postman, click on the  button on “Github” collection and select “Add request”        Set request’s name to “List issues”, in the URL type https://api.github.com/repos and paste the /user/repo/issues part of the newly created repository’s URLAPI design digressionYou obviously noticed that the UI URLs are similar to the API ones, in the case of Github that’s a really good idea because both UI and API give access to the exact same product and that helps developers to learn how works the API.But note that it is not always a good idea to mimic your UI in your API as it can make it less reusable in other use cases.We could stop here and hit the send button to list issues, but in order to keep our request and project maintainable and reusable, we’ll replace user and repo by variables:        In the URL, select your user (mine is arno-di-loreto), a “Set as variable” menu appears, click on it        Click on “+ Set as new variable”        Set name to github_user, select “Environment: Github” scope and click on “Set Variable”        User has been replaced by the variable /repos/{{github_user}}/repo/issues)        Repeat with your dummy repo name to create a github_repo variable in Github environment        Don’t forget to         Now you can hit  and get an empty list as response because there are no issues in the newly created repository.Create an issueLet’s fill that empty issues list by creating an issue.As the Github REST API follows common practices, we are supposed to do a POST request on the same URL as the one used to list issues:        Right click on the “List issues” request and select “Duplicate”        Select the newly created “List issues in repository Copy” request and change its name to “Create issue” by clicking on the pen that appear next to the request name when hovering over it        Click on “GET” to change method to “POST” and then hit the  button…         … Oops, there’s a 422 error!We actually forgot to provide some data in the body, but the error message is totally unclear about that.                      An error response that don't help as much as it could                                                                  {    &quot;message&quot;: &quot;Invalid request.\\n\\nFor &#39;links/0/schema&#39;, nil is not an object.&quot;,    &quot;documentation_url&quot;: &quot;https://docs.github.com/rest/reference/issues#create-an-issue&quot;}  Such cryptic response is really an example to NOT follow, an error message must clear and help to solve the problem.But at least, there’s a link to the documentation (documentation_url) (which is a very good idea!), if you follow it you’ll see that we need to supply at least a title and there are other data such as the body.Let’s try set this request a body but just with the body property:        Go to the \"Body\" tab        Click on \"raw\" button radio        Click on the \"Text\" menu to select \"JSON\"        Add a JSON object with a “body” property set to some random string (you can copy the following sample)                      Create issue (incomplete) body                                                                  {    &quot;body&quot;: &quot;Body of issue created by Postman&quot;}  Now, if you hit  , it fails again with the following response:                      An error response that actually helps                                                                  {    &quot;message&quot;: &quot;Invalid request.\\n\\n\\&quot;title\\&quot; wasn&#39;t supplied.&quot;,    &quot;documentation_url&quot;: &quot;https://docs.github.com/rest/reference/issues#create-an-issue&quot;}  But the error is clearer this time, we know exactly how to fix the problem: add missing title property.Think about that the next time you design and then code an API.OK, end of API design digression, let’s provide a valid request body with a title and a body:                      Create issue (complete) body                                                                  {    &quot;title&quot;: &quot;Issue created by Postman&quot;,    &quot;body&quot;: &quot;Body of issue created by Postman&quot;}  Click on  and hit  one more time, you’ll get a 201 Created response containing all data of the created issue.If you go back to the “List issues” request to send it again, you should get an non empty list containing the created issue.Obviously, if you also go the dummy repository on Github, you’ll find that issue in the issues tab (I have to admit that I find quite satisfying to see the result of API calls appearing in UI).Creating many github issues with Postman Runner and CSVIf you need to create many issues, you could just modify the “Create issue” request’s body and hit  as many times as needed.But that would be quite cumbersome right? What about trying the lazy way?        Just in case, ensure you actually saved the “Create Issue”        Right click on the “Github” collection and select “Duplicate”        Right click on the “Github Copy” collection and select “Rename” to rename it “Github Batch Issues Create”        Delete all requests EXCEPT the “Create Issue” one by right clicking on their name and selecting Delete        Select the “Create Issue” request, select the body tab and replace title and body values by {{title}} and {{body}} variables as follow                      Create issue request's body with variables                                                                  {    &quot;title&quot;: &quot;{{title}}&quot;,    &quot;body&quot;: &quot;{{body}}&quot;}  But from where will come those variables?From a CSV (Comma Separated Values) file!Open your favorite text editor, and put some issues titles and bodies as follow and save the file somewhere.The first line contains the names of the variables (title and body), the other lines contain actual titles and bodies.                      Issues data in CSV format                                                                  title,bodyA first issue, First issue&#39;s bodyAnother issue, Second issue&#39;s bodyThird issue,Yet another issue&#39;s bodyFourth issue,Too many issuesFive,It doesn&#39;t workSix,It really doesn&#39;t work  Now, we will trigger one API call per CSV file line (excluding the first one which holds the variable names):        Select the “Github Batch Issues Create” collection and click on the “Run” button        Click on “Select File” and open the previously created CSV file        Note that the number of iterations matches the number of line (minus title one) in the CSV file. Click on the “Preview” button        Check that the file is correctly interpreted, then close the preview        And finally, hit “Run Github Batch Issues Create” buttonPostman will do all the work and create all the issues provided in the CSV file.It simply makes and API call for each line, replacing the {{title}} and {{body}} variables by the value provided the CSV file’s line.            You can list issues with an API call of check Github web site to see all the created issues.Note that there are 7 issues, that’s the one created to check our Create Issue API call was actually working plus the six other ones created with the CSV file.            It works also on the command lineIf you need to industrialize doing batch API calls this way, having to use UI is not really convenient.Hopefully, you can run collection on the command line using Postman’s Newman.So, let’s see how to create many Github issues using our “Github Batch Issues Create” collection and Newman.Install NewmanYou’ll need Node.js to install and run Newman.Installing Newman is quite simple, just open a terminal and run a good old npm install -g newman and you’re done.Check Newman documentation for more information.Export collection and environment fileTo run the “Github Batch Issues Create” collection, we obviously need the collection itself but also the “Github” environment variables, let’s export them both:        Click on … near the “Github Batch Issues Create” collection name and select “Export”        Keep default export format, click the “Export” button and save the collection file in the same folder as the CSV file created earlier        Go to the “Environment” tab (in Postman’s window left panel) and select the Github environment by clicking on it        Click on … near the Share button (upper right corner), select “Export” and save the environment file in the same folder as the CSV fileCreating many github issues on command line with NewmanNow, we’re all set to run the “Github Batch Issues Create” collection on the command line:  Open a terminal  Go to the folder containing the csv, collection and environment files  Run newman run collection_filename -e environment_filename -d csv_filename (with your actual collection, environment and csv filenames!)And tada, one “Create Issue” request has been done for each line in the CSV file (again)!            You can optionally check the newly created issued in Postman with the List issues request or go on Github.Note that as we didn’t modify the CSV file between the Postman and Newman run, the 6 new issues are the same as the 6 previous ones.Cleaning the mess with Github GraphQL APIAs an exercise you can try to delete the issues that has been created using Postman (or Newman), a collection and a CSV file containing ids of issues to delete.Do not overlook this exercise that looks quite simple but is actually not, there is a trap and a interesting Postman feature to discover.SpoilerThe rest of this section shows how to do so (with less screenshots as by now you should know how to find your way in Postman UI).Trying to delete an issueAs the Github API is a REST API, I assume that deleting an issue simply means sending a DELETE /issues-resource-path/{issueId} request.To find the actual URL, let’s use the “List issues” request again, it returns something like that:                                                                                        [    {        &quot;url&quot;: &quot;https://api.github.com/repos/arno-di-loreto/postman-csv-demo/issues/13&quot;,        &quot;repository_url&quot;: &quot;https://api.github.com/repos/arno-di-loreto/postman-csv-demo&quot;,        &quot;labels_url&quot;: &quot;https://api.github.com/repos/arno-di-loreto/postman-csv-demo/issues/13/labels{/name}&quot;,        &quot;comments_url&quot;: &quot;https://api.github.com/repos/arno-di-loreto/postman-csv-demo/issues/13/comments&quot;,        &quot;events_url&quot;: &quot;https://api.github.com/repos/arno-di-loreto/postman-csv-demo/issues/13/events&quot;,        &quot;html_url&quot;: &quot;https://github.com/arno-di-loreto/postman-csv-demo/issues/13&quot;,        &quot;id&quot;: 848749267,        &quot;node_id&quot;: &quot;MDU6SXNzdWU4NDg3NDkyNjc=&quot;,        &quot;number&quot;: 13,        ...    },    ...]  A github issue seems to have 3 “ids”: id, node_id and number, which one to choose?No need to actually think about it because the ready to use url is actually provided!That’s pretty handy.And by the way it tells us that the id to use is number (with user and repo name).Let’s try to delete the first issue in the list:  Click on the url property’s value  That opens a new request tab  Hit the Send button to check what happens when doing a GET on that URL  You actually get the issue  Now change method to DELETE and hit send again …That returns a 404 Not Found, does that mean this issue doesn’t exist?!Obviously not, because a GET on it actually returned something.Let’s check what the documentation says (link provided in documentation_url), look for Issues in the left navigation bar.Actually, you can’t delete an issue with Github REST API!Seriously, don’t do that at home, use HTTP protocol correctly, never, ever return a 404 Not Found when a method is not available, return a 405 Method Not Allowed instead.Actually deleting an issueHopefully there are 2 Github APIs: the REST one and the GraphQL one.And you can delete issues with Github GraphQL API using the deleteIssue mutation.And even more hopefully, you can use the same token to access both APIs.I will not go into details about GraphQL.For what we need to do today, you only need to know that to send requests to a GraphQL API you always use a POST request and tell what you want to do in the body using GraphQL query language.In GraphQL, a request can contains many queries (to read data) and mutations (to modify data), actually mutations can be seen as functions.You can read my And GraphQL for all post to learn more about GraphQL.Let’s try to use this deleteIssue mutation:  Select the “Github” collection  Create a new “Delete issue (GraphQL)” request  Set its method to “POST”  Set its URL to https://api.github.com/graphql  Go to the “Body” tab  Select “GraphQL” radio button  Paste the following GraphQL body                      Delete issue GraphQl request body                                                                  mutation {    deleteIssue(input: { issueId: &quot;but which id put here?&quot; }) {         repository {             name        }    }}  The question is, which id should we provide in the issueId property?We have seen in the REST API that an issue has 3 different ids, for example:  id: 848749267  node_id: MDU6SXNzdWU4NDg3NDkyNjc=  number: 13As the request does not provide the repository name, that excludes the number as its value is probably not universally unique across all repositories of all users.The id and node_id could be that unique.Try to set issueId with one of the id of your issues and hit the send button.You’ll get this 200 OK response (sigh… HTTP is only used for transport with GraphQL APIs):                      Error                                                                  {    &quot;data&quot;: {        &quot;deleteIssue&quot;: null    },    &quot;errors&quot;: [        {            &quot;type&quot;: &quot;NOT_FOUND&quot;,            &quot;path&quot;: [                &quot;deleteIssue&quot;            ],            &quot;locations&quot;: [                {                    &quot;line&quot;: 2,                    &quot;column&quot;: 5                }            ],            &quot;message&quot;: &quot;Could not resolve to a node with the global id of &#39;848749267&#39;&quot;        }    ]}  As node_id is the only one left and as the error message talks about “node”, it seems to be the expected value.Try again, and now you’ll get another 200 OK signifying that the issue has been deleted.                      Issue deleted!                                                                  {    &quot;data&quot;: {        &quot;deleteIssue&quot;: {            &quot;repository&quot;: {                &quot;name&quot;: &quot;dummy-repository&quot;            }        }    }}  Note that this response contains the name of the repo that was holding the deleted issue.Now that you know how to delete an issue, it’s quite easy to delete all the issue you have created.I will just give you one last tip.One last tip: “Generating” CSV file with Ids in PostmanTo delete multiple issues using the method we have been using to create them, you need a CSV file containing the ids of the issues you want to delete.You could list issues using Postman and copy/paste them one by one in that file.You could also use the powerful JSON command line processor jq (see my post series about it)But what about “generating” that CSV in Postman?To do so, we’ll use the Visualize feature of Postman.By adding some Javascript code in the Tests tab of a request you can setup a visualizer for the returned data.That can be used to create awesome charts or more simple tables, this is what we’ll do here.Go the the Tests tab of the “List issues” request in “Github” collection and copy/paste the following Javascript code:                      Setup visualizer in Tests tab                                                                  // Handlebar templatevar templateIdsOnly = `    &lt;table bgcolor=&quot;#FFFFFF&quot;&gt;        &lt;tr&gt;            &lt;th&gt;issueId&lt;/th&gt;        &lt;/tr&gt;        {{#each response}}            &lt;tr&gt;                &lt;td&gt;{{node_id}}&lt;/td&gt;            &lt;/tr&gt;        {{/each}}    &lt;/table&gt;`;// Set visualizerpm.visualizer.set(templateIdsOnly, {    // Pass the response body parsed as JSON as `data`    response: pm.response.json()});  This Javascript code creates a templateIdsOnly Handlebar template.This template is pretty basic, it builds a HTML table with a single column title issueId.This table will contain a line line holding the node_id value of each item returned by the API call. After that it configures the Postman visualizer (pm.visualizer) to use the template on the API cal response data (pm.response.json()).Once this is done, hit the Send button and click on Visualize in the response and tada, you get a one column table with its node_id title and all node_id values:            Just select all text and copy/paste it in a file that you’ll use as input to delete all issues.Obviously, in our case as we need a single value for each request, that is not really a CSV file that has been “generated”.If you need to get multiple value, just add a comma and the new value in the template (don’t forget title) as follow                      Actually generating CSV data                                                                  // Handlebar templatevar templateCsv = `    &lt;table bgcolor=&quot;#FFFFFF&quot;&gt;        &lt;tr&gt;            &lt;th&gt;issueId,body&lt;/th&gt;        &lt;/tr&gt;        {{#each response}}            &lt;tr&gt;                &lt;td&gt;{{node_id}},{{body}}&lt;/td&gt;            &lt;/tr&gt;        {{/each}}    &lt;/table&gt;`;// Set visualizerpm.visualizer.set(templateCsv, {    // Pass the response body parsed as JSON as `data`    response: pm.response.json()});  From now on, you have all you need to delete multiple issues with the runner in Postman or with Newman.Delete access tokenOnce you’re done, beware to not commit the environnement file with active access token.I recommend deleting your Github access token if you don’t use it anymore.Go to your Personal Access Token list on Github and click on the “delete” button for the “postman-csv-demo” token.Lessons learnedI hope that the next time you’ll need to batch API calls, you’ll remember what you’ve seen in this post.Doing CSV data based API batch calls is pretty simple once you know that feature exists in Postman (and in its command line counter part Newman).The visualize feature can be really useful too in that case but it can be used to do far more advanced data rendering.And don’t forget to use environment variables to store sensitive data in Postman.I hope that you’ll also remember the few design principles and errors that we have seen:  Being consistent with common practices (and HTTP/REST principles), ease learning to use an API (people can guess how to use APIs)  Including link to documentation is quite useful  Never return unclear error that does not help to solve the problem  Never return 404 Not Found status code when an HTTP method is not available on an actually existing resource, use 405 Method Not Allowed instead  Having consistent URL between UI and API can be a good idea but not always (it may make API less reusable)And last but not least, we’ve seen that even famous companies such as Github can make mistakes with their APIs.That means that you must be careful when taking inspiration from existing APIs.Hopefully, in the case of Github, the problems don’t have much consequences, the API is overall of good quality and usable (and the documentation is quite good), but be careful not to ruin developer experience with more terrible mistakes."
},{
    "id": "36",
    "type": "post",
    "title": "7 ways leading to wrong ownership and killing APIs",
    "url": "https://apihandyman.io/7-ways-leading-to-wrong-ownership-and-killing-apis/",
    "banner": "https://apihandyman.io/images/7-ways-leading-to-wrong-ownership-and-killing-apis/banner.png",
    "description": "After hundreds of API design reviews, I can tell that the most neglected aspect of API governance is ownership. Unfortunately, that’s probably the most important one. Without true ownership, your APIs will probably be totally wrong. Without true ownership, your employees will be terribly sad or leave. Without true ownership, your company may even die. As an API design reviewer, I believe that my role is also to warn the teams I’m working with about this topic and help them to fix the problem.",
    "body": "After hundreds of API design reviews, I can tell that the most neglected aspect of API governance is ownership.Unfortunately, that’s probably the most important one.Without true ownership, your APIs will probably be totally wrong.Without true ownership, your employees will be terribly sad or leave.Without true ownership, your company may even die.As an API design reviewer, I believe that my role is also to warn the teams I’m working with about this topic and help them to fix the problem.Ownership done wrongIn this post, I’ll share with you 7 ways leading to wrong ownership that I have actually witnessed.Letting consumers dictate their willThat’s a very classic one.After decades of building point to point web services that serve for highly specific needs and highly specific consumers, teams may be tempted to go on as before and just say yes to every single request of any consumer resulting in non reusable and totally bloated APIs.In such cases, it’s often hard at the beginning to switch to a true API provider stance and be the actual owner of the APIs.You’ll have to make consumers understand that as an API provider you can’t just make an API only for them exactly as they wish.Reversing roles, and so becoming the true owner, is often a simple matter of explaining that who can do more, can do less and that your more generic API design is actually able to fullfil many specific needs.Mapping API to micro-organizationIt’s not unusual to have a business domain split across different small teams, each one working on a specific part because of process or technology.The problem is that some may be tempted to build an API per team resulting in many micro-APIs.By doing so you may needlessly expose your internal organization (who said Conway’s law?) and build micro-APIs that are worthless without each others.For example, if a team works on the “Customer Creation API” and the other one on “Customer modification and read API”, it will be cumbersome to use those 2 APIs if that separation does not make any sense from a business perspective and even more if most consumers actually need both set of operations.In that case, you’ll have to find organizational and technical ways to expose and maintain a unified API façade that will be meaningful for consumers.That especially means that ownership encompass the 2 subsets of operations.And by the way, that could be a signal that your human organization is not the good one.Not being the golden sourceIn big companies replicating data is unfortunately very common, not all companies are aware of Jeff Bezos mandate (which basically says do APIs for between team communication or you’re fired).That means that more often than not, data is replicated and sometimes enhanced the same ways dozens of times.At some extent, some team may be tempted to expose APIs providing data they don’t actually own.Depending on whom these APIs are exposed to that could be a real problem.If it’s just a quick win used inside a team while waiting the true owner build they’re own APIs that could be OK.If not, data officers and even actual provider may not really happy with that.But most important, not being the actual owner, the team building the API may not work enough on design and just build an ugly technical connector because they don’t really care about it.Outsourcing implementationI have never seen a successful API resulting from owner delegating implementation to someone else.In best cases, there’s so much delegation that owner don’t actually own the API, it’s designed in a totally independent and usually bad way.In worst cases, the owner may have strong views on how the API should look like (and that’s totally normal) but these views are not shared by the people who will actually build the API resulting in conflicts and the API is not released before the owner actually find a way to be able to build the API themselves.Delegating design to developers without business knowledgeI can’t count how many times I had to work on API design reviews with developers without business knowledge.That’s terrible for API design because they are unable to answer my business oriented questions and make decisions.API design is not really a matter of POST /this and which database is used underneath, it’s first and foremost a matter of needs and business rules.An API must be owned by both business AND developers, they must work together on design.Delegating API stuff to center of expertiseThis one is quite close to previous case.As APIs become more and more important for companies, especially big ones, they’re tempted to build an API center of excellence or any other type of structure concentrating all API related expertise.If that leads to teams fully delegating APIs building to these experts, that will only lead to terrible APIs as if those experts actually know how to build and design APIs, they probably know nothing of the business domain.A center of expertise should only exist to help, empower and train non-experts in order to make them self-sufficient on a new topic.Suffering from dictatorial API governanceAnd last, but not least, a dictatorial or even just a little bit too strong governance has a subtle but terrible effect: it inevitably disempowers people, takes API ownership from them.Why?Simply because, having extremist API design reviewers that actually don’t help people design their API but just yell at them and actually constrain them so much that they can’t design anything themselves lead to only one thing: “OK, Mr Inquisitor, design it for me, so I can move on and deliver my stuff”.Not only people loose ownership but they also loose the will to learn and improve, the consequences at scale for the company will be terrible.People who actually build APIs will not grow their expertise (and be sad or leave).And the resulting API will be of low quality, probably less usable, reusable, evolvable.In the 21st century, I believe that it that could kill a company in the long run.What ownership actually requiresSo how to be sure that an “organization” actually is the true owner of an API?It must:  Be the actual owner of data, services, domain, components  Represent a meaningful business domain leading to meaningful and self sufficient API(s)  Know domain from business perspective  Know domain from technical perspective  Be able to design (maybe with some help but without over delegating)  Be able to make decisions  Be able to actually implementAn “organization” can be a team or a group of teams but be warned that making different teams working together may not be that easy, maybe you should rethink your human organization to solve that problem."
},{
    "id": "37",
    "type": "post",
    "title": "The Augmented API Design Reviewer",
    "url": "https://apihandyman.io/the-augmented-api-design-reviewer/",
    "banner": "https://apihandyman.io/images/the-augmented-api-design-reviewer/banner.png",
    "description": "API Design Reviews can be a total nightmare when it comes to check API Design Guidelines conformance. Hopefully, this can be automated using the OpenAPI Specification and Spectral, helping you to focus on real API design matters.",
    "body": "My 2020 talk, The Augmented API Design Reviewer is about (partial) API Design review automation with the OpenAPI Specification and Spectral.AbstractAPI Design Reviews can be a total nightmare when it comes to check API Design Guidelines conformance. Hopefully, this can be automated using the OpenAPI Specification and Spectral, a JSON/YAML linter. Using these tools, you’ll be able to focus on other more interesting tasks such as investigating if the API fullfils the identified needs. But that will only work if you know how to build and use Spectral rulesets. During this session you’ll discover the basics of Spectral and how to actually use it at scale by discovering how to design rules and rulesets, how to ensure they actually work, and also by learning the differents ways of using Spectral.Video                                                This content is hosted on youtube.com.                By showing this third party content you accept YouTube (Google)'s                     privacy policy.                                                    Show third party content                                                                    Remember my choice                        (can be changed in privacy settings)                                                                                      SlidesDownload PDFOpen PDF    "
},{
    "id": "38",
    "type": "post",
    "title": "API Days Interface 2020 Series - Part 2 - Doing APIs right and doing right APIs",
    "url": "https://apihandyman.io/apidays-interface-doing-apis-right-and-doing-right-apis/",
    "banner": "https://apihandyman.io/images/apidays-interface-doing-apis-right-and-doing-right-apis/banner.png",
    "description": "API Days Interface being online made the experience a bit different but after 3 days, I felt almost as usual; exhausted and my brain boiling. In previous post, I shared my feelings about my first online conference. Now let’s talk about the content; Sam Newman doing a facepalm, API design, architecture, governance and my new favorite quote “Doing APIs right, doing right APIs”.",
    "body": "API Days Interface being online made the experience a bit different but after 3 days, I felt almost as usual; exhausted and my brain boiling. In previous post, I shared my feelings about my first online conference. Now let’s talk about the content; Sam Newman doing a facepalm, API design, architecture, governance and my new favorite quote “Doing APIs right, doing right APIs”.       API Days Interface 2020 Series                      INTERFACE, by API Days gathered best past 7 years speakers, entire global community, and the API landscape leaders around our most popular topics. In this 2 part series, I share my feeling attending an online conference and what I learned.                                                      1 - Speaking into the void                                      2 - Doing APIs right and doing right APIs                                      DesignAs usual, API design is a center piece of any API conference. Again we had brilliant demonstration of why the API design first approach prevail and I was pleased to see some long awaited features added to the OpenAPI Specification.            Speaker      Session                  Mike Amundsen, Author of “Designing and Building Web APIs” and “Restful API Design”      Building great web APIs              Alianna Inzana, Senior Director, Product Management @SmartBear      /Contract/{Collaboration}/DrivenDevelopment              Darrell Miller, Board Member of Open API Initiative      The State of Open API Specification      Design firstBoth Alianna Inzana and Mike Amundsen did a wonderful job describing the API design and build lifecycle and both especially said that design forst approach is key.An API must be created to solve business problems for people. In order to be sure that you build the right API and so identified the real needs, you must use a design first approach and request feedback early. Using a standardized API description like the OpenAPI specification and creating mocks will make it easier to check if you’re doing the right API. By working on a design and not an implementation, you can do modification easily and quickly.OpenAPI Specification improvementsAt a more ground level regarding API design, Darrell Miller made my day by announcing two major improvements coming with version 3.1 of the Open Specification (among other modifications):OpenAPI 3.1 supports original and standard JSON Schema in its latest version, no more fancy OpenAPI/Swagger variationAnd at last we’ll be able to have a description (and all other possible properties) along with a $ref. Any property set beside the $ref will override what comes from the $ref.            Copyright Darrel MillerArchitectureAPIs and their implementation are nothing without good architecture reliying on clearly identified and understood principles. And they are nothing without organization around them. This conference proposed some sessions that were really good at talking about this.            Speaker      Session                  Mary Poppendieck, Author of “Lean Software Development: An Agile Toolkit      Where do great architecture come from              Sam Newman, Author of “Building Microservices and Monolith to Microservices”      Microservices, APIs, and the Cost Of Change              Mark Cheshire, Director Product Management for API Management @Red Hat      When to manage Microservices as a Mesh or as APIs?              Ronnie Mitra, Author of “Microservice Architecture”      The Next API Strategy: Going Borderless              Matthew Reinbold, Director, Platform Services Center of Excellence @Capital One      APIs are Arrangements of Power. Now what?      Principles and responsabilityMary Poppendieck gave an amazing talk about evolution of architectures from the 60s to our time with her Where do great architecture come from session. It’s a pity she didn’t have more time, hopefully she may come back at another API Days with a longer slot. I will not retrace here in details all what she said (if you watch only one video of this conference, this is the one).In order to build better systems we can rely on principles discovered throughout the years thanks to past failures:  Redundancy: instead or running one instance, run many  Fault isolation: when a component fails, others can still run  Local contral: gives each component the capability of running on its own even when it relies on others (caching results for example)And we are still discovering new principles even when relying on old ones. For example in 2000, Google solved a major crisis (indexing software stopped working due to faulty hardware). By combining redundancy and fault isolation principles, they build an architecture composed of cheap machines that tolerates such failure. In 2010 Amazon make a ground breaking evolution by getting rid of the sacrosanct central database and building a distributing database.Another interesting aspects is that some architecture principles are not only related to software or hardware. They can be related to organization and people too. And actually, with systems being more and more complex, archicture decisions are mostly people related.In 2000, Jeff Bezos, Amazon’s CEO, believed that his company (and the underlying system) couldn’t become huge without encouraing team autonomy, hence the famous memo.Teams must be autonomous but do be efficient they need to understand that they are part of a bigger system. Their mission is part of an overall mission.            Copyright Mary PoppendieckMicroservice vs APISam Newman gave a definition of a microservice and how it relates to API; this is important to remind because the “microservice” name tend to be used for things that are actually not “microservices” and also because APIs and microservices are too often confused:  A microservice is independently deployable  A microservice runs as a separate process  A microservice’s data are hidden inside its boudaries  A microservice can be called via some form of network call: for example via an API which becomes a mean to hide internal implementation.So the microservice is not an API and reverse. The API is only an interface to a microservice.Also, if your “microservices” share a database with others or are wars or ears running inside a Jboss server for example, those are not microservices.Versioning Handling changesSam Newman gave a deep dive into versioning during his session. He especially explained that versioning is not the real problem. It’s not about version 1 and version 2. The real problem is how to handle change, how to handle backward compatibility and incompatibility. And this is even more true when doing microservices which are supposed to be independently deployable: maintaining backward compabitibility is key.He gave 4 concrete tips to do so.I have to admit that I was quite proud of myself because I realized that I always say what he told us during my API Design reviews!Tip #1: Hiding information is key.If an upstream consumer can reach into your internal implementation then you can’t change the implementation without breaking the consumer. Consumer and provided are tightly coupled, making any change risky and even impossible.            Copyright Sam NewmanModularization is not a new concept that appeared with APIs and microservices. In 1971, D.L. Parnas published On the criteria to be used tin decomposing systems into modules. He looked at how best to define module boundaries and found that “information hiding” worked best.Your interface (API) shows what is shared, the rest data and implementation details is your own business. That’s why it is really important do have separate models for data, objects and exposed interfaces (as also always say Mike Admundsen).            Copyright Sam NewmanIf the whole becomes to big, you can split your internal implementation in various sub modules, while keeping the shared interface unique and unmodified. But be warned that only works if the whole set of microservices/modules is handled by the same team.            Copyright Sam NewmanTip #2: Cost of change variesNot all changes have the same cost. Some changes have critical consequences and some others have very limited impacts.A modification inside a team, on the set of microservices of the Accounts domain above for example has a very low cost because it only has internal impacts. If the change, like a modification of the shared interface, impacts an other team inside the company the cost is higher. If this shared interface is used by multiple teams inside the company, the cost increases again. And lastly, if this change impacts people outside the company, the cost is even more high.That means the cost of change increases with the “distance” between the provided and consumer (inside the team, inside the company, outside the company) and the number of consumers.            Copyright Sam NewmanThe cost of change leads to different ways of taking the decision to actually do this change or not. According to Jeff Bezos, Amazon’s CEO, there are 2 types of decisions. Type 1 are irreversible decisions, it’s impossible to go back, you have to think carefully before taking them. On the opposite type 2 ones are reversible, they don’t cost 0 but you can change your mind very easily and you take no risk doing them.If the change has impacts only inside a team, that’s a reversible decision make can be taken locally inside the team. On the opposite, a decision impacting a public facing API provided to people outside the company is an irreversible decision which requires more discussion and a formal approval.Getting the balance right regarding those decisions is key to having an organization that thrives from team autonomy.Tip #3: Catch accidental breakagesEven when having found the right balance for decision making, people can still do mistakes like replacing a property by another in an API response (that’s actually removing the original property). Such modification breaks the consumers.That’s why it is important to have separate models (as already said in tip #1). Doing such modification requires more work and requires explicit changes that requires you to think about it and so you’ll notice it.But you can’t rely only on people actually noticing that, you need testing. And to do tests, you need schema (JSON schema, Protobuf, OpenAPI, …) to actually check the difference between old and new version (that’s also why design first is important).Tip #4: Expose multiple endpointsOnce you know you are doing a change impacting others, avoid lock step release. Requireing coordination between consumer and provider is the enemy, the anti-thesis of independen deployability. That means, you must give to to consumer to upgrade/To do so you can expose multiple separates ervice versions. But there are a few challenges doing so:  Service discovery  Doubling infrastructure costs money  Keeping data consistency between the 2 versions can be hard  And also bug fixing can be botheringTo solve that you can expose 2 endpoints, one for each version inside the same component. That way, you shift from complex infrastructure issue to a more simpler design/implementation issue.Switching from one version to another can be as simple as using path, the accept header or a domain.Microservices IndieservicesDuring Q&amp;A, Mehdi Medjaoui asked Newman how he felt about miniservices, macroservices, nanoservices and other {whatever size}services. His reaction made me burst out laughing (jump at 31:45 to see it), he looked totally desperate and did a long facepalm.            Sam Newman's reaction (reenactment by Jean-Luc Picard)More seriously, he stated that the name microservice which imply “size” is actually a problem. He want to go back in time and choose another name focusing on the real important aspect: independent deployability.Medjaoui proposed indieservices and after 2 second Newman said that would be probably better than microservices.BoundariesThe Next API Strategy: Going Borderless by Ronnie Mitra and Choosing between API gateway and service mesh by Mark Cheshire sessions gave really good insights about how to define and manage the internal and external boundaries or your system and they resonate with what Sam Newman said about microservices.Boundaries as a providerMark Cheshire said that at first making the decision between API Management and Service Mesh looks quite simple.API Management is used for North-South traffic. North being outside the organization and south being inside. With API Management, there’s an API Gateway (a proxy) that sits between the provider and its consumers. Consumers can access to APIs exposed on that gateway by registering to a developer portal. Those APIs are considered as products.Service Mesh is used for East-West traffic, both sides being inside the organization. Service mesh comes as a side car proxy on microservices which handles the communication with other microservices (dealing with discovery, logs/observability, retry, …).So it looks like the decision should be made on does the communication take place inside or outide my company. But that’s not the case. A company/organization can be split in various domains (however you call them). And these domain boundaries must be treated the same way as enterprise boundary (API Management). Inside the domains you may use service meshes.            Copyright Mark Cheshire/RedhatWhat distingues inter and intra-domain traficc is the relation between provider and consumers. Are they in the same team? How many consumers? Explicit contract needed?            Copyright Mark Cheshire/RedhatBoundaries as a consumerRonnie Mitra explained that a system is usually complex and difficult to understand and use. Hiding complexity of microservices, APIs, data and third party providers will ease the use of this complex system.You can’t change someone else’s API (I add: you can’t change someone else’s API even if they are in the same company as yours, but that’s another story I’ll tell another day). In order to avoid building a brittle and tightly couple relation with API providers, you must proxy others APIs with a sub-domain having its own (anti-corruption) model. Reminder: That’s basically what you would do for your own API, separating data/object/API model as sais Sam Newman and Mike Amundsen.Capabilities don’t interoperate. You may need to build an layer of orchestration to weave microservices capabilities together. There’s a big centralization/decentralization trade-off decision to do here.Data is all over the place (especially when splitted across dozens if not hundreds of microservices). Data need to be collected and catalgues to be useful.So many APIs and so many components lead to a system that is difficult to understand and manage. You need to build access and management components that represent this system as a monolith.            Copyright Ronnie MitraBy building all these layers, creating new boundaries, you can create a system so simple that it looks totally borderless.OrganizationAs you may have noticed, architecture is more about principles and choosing the right organization than technology. Actually technology questions are not the main ones. In his session “APIs are Arrangements of Power. Now what?”, Matthew Reinbold gave really good insights about how organization matters for architecture and strategy.The most important one is that you can take advantage of architecture to change your organization. This strategy is called the inverse Conway maneuver in reference to Conway’s law that tells “Organizations design systems that mirrors their own communication structure”.Why doing that? Because in order to succeed, an organization must realigned itself around capabilities and the architecture must be aligned on this too. Changing organization is always hard and sometimes it may be easier to start with architecture, so the inverse Conway maneuver makes sense. And if you don’t think this works, just take a look at what Amazon became after the Jeff Bezos mandates.GovernanceYou may want to skip that section because you think governance sucks, but please read it. Indeed, for many people, governance is a dirty word, synonym of pointless, useless and terrible processes and constraints dictated by some crazy people from the top of their ivory towers. And they are right because unfortunately such totally wrong governance exists. Hopefully it’s not always the case, there are some people and company who do governance in a totally different way.Without proper governance at every level from design to API strategy, your company’s employees will be very sad and your company may even fail. Most sessions were tied in a way or another to governance (even the one I talked about in previous section about architecture). The following ones were explicitely talking about this topic and may give you some ideas to create or improve your existing governance.            Speaker      Session                  Alan Glickenhouse, API Strategist @IBM      Recommendations for API Governance and an API Economy Center of Excellence              Phil Sturgeon, Architect @Stoplight      Automating style guides for REST, gRPC, or GraphQL              Erik Wilde, Co-Author of “Continuous API Management”      How to Guide your API Program and Platform              John Phenix, Chief API Architect @HSBC      Automating API Governance              Arnaud Lauret, Author of “The Design of Web APIs”      The Augmented API Design Reviewer      What follows is a summary of all ideas coming from all sessions around governance.The right level of governanceGovernance is not doing the police. Governance is doing all that can be done to make people do the right thing the right way easily. Whatever this thing is, creating an API product, design an API, securing an API, … A very good governance is the one you don’t actually see.You don’t need to govern everything just because you need it, governance must have a reason, an objective. You must govern as little as possible, you must govern the minimum need to deliver value and manage risk (the consequences of not doing right).GuidelinesYou cannot govern based of personal preferences that will change from one day to another, from one person to another. You need clearly written rules, you need guidelines. Often reduced to API Design Guidelines, you can (even must) create guidelines for every level: API Strategy, API Program, API Platform, API Product, API Design, architecture, domain definition, …The first step will be to make people share their practices, then you’ll be able to create your guidelines based on those practices.Guidelines describe (Erik Wilde):  Why they exist, which issue they are solving  What can be done to address this issue  How to implement the solutionOne of the major benefits of having guidelines is ensuring a certain level of consistency. Consistency matters because inconcistency wastes times, especially inconsistent API design which means that ALL consumers will have a lot of work to do (Phil Sturgeon).Automating API Design ReviewsAPI Design Guidelines are important, but let’s be honest: most APIs developers will not read the organization’s API manifesto. If they do they won’t remember it. If they do they won’t reread it looking for changes (Phil Sturgeon). So you must automate guidelines controls as much as possible to make their (and reviewer’s) life easier.Phil Sturgeon, John Phenix and myself talked about API Design review automation using Spectral.We all agreed on the fact that API design review cannot be completely replace by automation. An API linter will not tell you if the design is actually accurate, if this resource’s name is the good one or if the API is actually the one that is needed. But it simplifies the process massively, removing 80% or rejections before reviewers even look.Scaling and Shifting API Design GovernanceThe mosy visible aspect of governance is API design governance. Without it, your API landscape will be a totally inconsistent nightmare that will make loose time to all of your consumers. Therefore you must ensure that API are design properly with API design reviews.Depending on your context (locations, size, number of APIs), you may use different organization model to do so (John Phenix):  Centralized: A core expert team do all reviews. This is a consistent but not scalable approach  Federated: API champions enforce standard locally. This is a scalable but not consistent approach.  Automated: Designs are automatically reviewed by some magic programs. This is scalable and consistent but is far from comprehensive. Indedd, such program will not tell you if the API is the right one.  Hybrid: Focus human-power on what cannot be checked automatically.Whatever approach you have, you’ll notice that in the long run the discussions will shift from “Are we doing APIs right” (meaning conforming to our design guidelines) to “Are we doing the right APIs” (API product vision).Doing APIs right and doing right APIsIt’s time to conclude. What do I retain in the end? Well, besides Sam Newman doing a facepalm, I will remember that “it’s the people that matter, the people that last, not machines, not technology. Change is not Kubernetes or Service Mesh, change is people” (Matthew Reinbold). And also a clever way to say that they are two sides of doing APIs:  “Doing APIs right and doing right APIs” (Alianna Inzana and John Phenix). Based on my experience, I can tell you that helping people doing the APIs right with appropriate governance will help them making right APIs by themselves in the long run."
},{
    "id": "39",
    "type": "post",
    "title": "APIs You Won't Hate Podcast - The API Handyman Cometh",
    "url": "https://apihandyman.io/apis-you-wont-hate-podcast-the-api-handyman-cometh/",
    "banner": "https://apihandyman.io/images/apis-you-wont-hate-podcast-the-api-handyman-cometh/banner.png",
    "description": "It was great to chat with Phil Sturgeon and Matt Trask on the APIs You Won’t Hate Podcast. We talked about API Design and Reviews, and we also talk about life in quarantine, as France completely shut down and how Phil made it back in time to England before the lock downs took place.",
    "body": "It was great to chat with Phil Sturgeon and Matt Trask on the APIs You Won’t Hate Podcast. We talked about API Design and Reviews, and we also talk about life in quarantine, as France completely shut down and how Phil made it back in time to England before the lock downs took place.Listen on APIs You Won’t Hate"
},{
    "id": "40",
    "type": "post",
    "title": "API Days Interface 2020 Series - Part 1 - Speaking into the void",
    "url": "https://apihandyman.io/apidays-interface-speaking-into-the-void/",
    "banner": "https://apihandyman.io/images/apidays-interface-speaking-into-the-void/banner.png",
    "description": "I’ve attended and spoke at API Days Interface online conference on June 20, July 1 &amp;amp; 2, 2020. Being online made the experience a bit different but after almost 3 days, I felt almost as usual; exhausted and my brain boiling with all what I’ve heard and seen. In this first post I share my feelings about attending and speaking at an online conference.",
    "body": "I’ve attended and spoke at API Days Interface online conference on June 20, July 1 &amp; 2, 2020. Being online made the experience a bit different but after almost 3 days, I felt almost as usual; exhausted and my brain boiling with all what I’ve heard and seen. In this first post I share my feelings about attending and speaking at an online conference.      API Days Interface 2020 Series                      INTERFACE, by API Days gathered best past 7 years speakers, entire global community, and the API landscape leaders around our most popular topics. In this 2 part series, I share my feeling attending an online conference and what I learned.                                                      1 - Speaking into the void                                      2 - Doing APIs right and doing right APIs                                      API Days Interface Online conferenceAPI Days Interface was my first online conference. It was a 2 days long conference with 3 to 4 parallel tracks, workshops and booths, just like a regular conference. All usual API conference topics were discussed; design, governance, security, documentation, architecture, developer experience, … The line up of speakers and topics was as always quite impressive. So many great speakers (especially Mary Poppendiek and Sam Newman who gave awesome talks) coming from a wide range of domains from culture to government agencies and finance to travel and many others.All this looks like the usual API conference.But this time, no travel abroad, only my bedroom. No sponsored snacks and beers but my own food and ice cream (yes, I actually ate an ice cream during the API specifications panel discussion). No IRL meetings, only me, my laptop and my webcam and the Hopin platform chosen by the conference. And most terrible, no gifts to bring back to my wife and daughter.Speaking at an online conferenceMy session was titled “The Augmented API Design Reviewer”, it was about my journey to (partial) API design review automation using the OpenAPI specification and Spectral.Preparation as usual: write, deck, rehearseI prepared my session as usual. I wrote my speech, did a few rehearsal to ensure my story telling makes sense and ensure that it fits withing the allowed 25 minutes time range. Unfortunately, I had to cut out many elements to keep only what was the most important to fit in this time range. I would have need more than 1 hours to tell the whole story (I’ll tell all that in a blog post series). Then I chose a theme for my slide deck, after digging on the idea of the 6 Million Dollar Man (the 70s TV show), I finally choose Blade Runner (the original movie, the sequel does not exist). I watched the movie to get a few screenshots and build my deck.New concerns: stage, sound and the platformWhile I was doing the last rehearsal using the final slidedeck, a few questions were turning and turning in mind: the “stage”, the sound recording and how the Hopin platform work.The stage was my bedroom, my desk is there, but unfortunately the wall behind me is just a boring white wall and a corner of my TV would also have been seen. We’re still working on decorating our appartment after a year living there. Even if people would mostly look at my slides and only see mee in a small window beside them, the boring background was bothering me. So I pull some wires and put my laptop and a small table facing my desktop which is less boring, there are some photos, Nintendo NES posters, He-Man and Saint Seiya dolls. (I’m supposed to say “adult collectible action figures”. Indeed, because I’m a grown up adult, they must be collectible and not toys. Also I’m a guy and guys have “action figures” instead of dolls. Watch “The toys that made us” to learn the story behind this ridiculous naming). Bonus: my secondary display screen fixed on the wall could even show my slides. Great, boring background problem solved.The sound now. I’m used to use a basic bluetooth headset when using teams/skype/slack/hangout but I would like to avoid having something on my head. Hopefully I got a brand new computer which advertize a “studio quality microphone” (you know the one pricy laptop sold by some fruit cooperative which was having some keyboards problems for the last few years, that was finally fixed last november by putting a good old scissor keyboard back). I did a few tests recording myself with Quicktime whi rehearsing and the result was quite impressive. The sound was crystal clear without interference noise. Sound problem solved.Last problem, actually giving the talk and especially sharing my slides while seeing my speakers note AND the Hopin tab in my browser. I usually use Google Slides for my slide decks. If I had used it, I wouldn’t had any problem. But I needed to use very specific fonts that do not exist on Slides. In such case I usually put the text using such font in a image with Gimp and then put the image in my slides. But this time I had a lot of text using specific fonts, especially code samples and hadn’t the time to do all that in Gimp (I would have probably gone crazy doing so). So I gave a try to Keynote (the MacOS equivalent of PowerPoint). I did my deck and was quite happy with the “Blade Runner Style” result. While rehearsing I realized that when starting the slide show, Keynote goes in full screen on ALL of your screens; slides on screen 1, speaker’s notes on screen 2. Even when disabling speaker’s notes, the second screen goes black. Then how to keep an eye on the Hopin tab during my session?I thought that if I could import my Keynote slides in Google Slides that would solve my problem. Slides works inside the browser and you can keep many different apps on your second screen while having youur slides in fullscreen on first screen. I tried to export my slides as a PowerPoint file and then import in Google Sheets… That did not work because the PowerPoint export was ugly (missing elements and fonts). I export my slides as images and thought that I could import all of them in one shot in slides …. nope. I gave up thinking: well, let’s go without a net and hope that everything will go smoothly. But that was still too worrying and eventually had the idea of opening the Hopin website on my phone next to my laptop. Last problem solve!I was ready 2 hours before my session. Perfect, I had time to cool down and take some rest.The session: speaking into the voidI did my Augmented API Design Reviewer session on tuesday morning (which actually was the evening for me in Paris). All session were done live on Pacific timezone and replayed 2 times on Asia and Europe time zones.I connected to API Interface/Hopin website go to my track and listened to the great Mike Admundsen. Then my turm came. I shared my web cam and microphone and while the MC was introducing me, I was seeking the sharing screen button …Sharing your screen is the online version of connecting to the projector (cable incompatibility …). Here, no cable problem but I had to find the share screen button which was had not an obvious design to say the least. And then, bad luck, as I never had shared my screen with my browser before (brand new laptop), I had to tweak some security configuration and restart chrome. Imagine the speaker leaving the stage to do some stuff while letting the MC filling the blank. Quite awkward. But hopefully, that took less than a minute and at last everything was set (including the brower opened on my phone).I spoke and wave my hands almost as usual but not having the usual feedback from the audience is quite annoying. During a live session, I’m used to make eye contact with people in the audience. I’m used to seek people violently shaking their head in agreement or disagreement. And sometimes I have the chance to see and hear people laughing to my terrible jokes or funny slides. Online you see no one, you hear no one. It’s like speaking into the void. You do not wonder if people like what you say or not. You wonder if people actually see and hear you. At the beginning I gave a few glance to the chat window opened on my phone, everything was seeming OK until I saw “I’m not seeing the feed” … My heart rate briefly sky rocketed to 553.43 bpm … and hopefully other people said “working on my side” … after one or two minutes I was confident and did my stuff without worrying about technical issue. I was trying to keep my eyes looking at the camera as much as possible, but I always need to check my notes and the timer. I did not checked the chat until I finished the session. There was no time for live Q/A, but I anwsered to a few questions using the chat. Attendees seem quite happy and so was I. And as always I was totally exhausted after speaking.The day after, I was on the chat during the replay of my session on the Europe time zone and discussed with the audience, put links to the tools and posts I was talking about. I did a one to one session with an attendee after my session, we had discussed about Spectral.Attending at an online conferenceI prepared the conference as I always did. Checking the whole agenda, tracks and session in order to choose the track I would attend too. I selected the tracks and here I go watching sessions one after another. I realized that I choose the sessions just like for a regular conference, thinking that I couldn’t easily go from one room to another during a track. Obviously at an online conference, you can switch very easily between sessions.I realized that some conversations could take place between attendees in the chat windows during the session, that was interesting. I didn’t took advantage of the networking and webcam feature because for totally nonsensical reasons I couldn’t start conversation that way. As I had to work on myself when I started to go to conferences to speak to total strangers, I think I’ll have to go through my mental barriers to talk to people using this “new” way of communicating.Also, I didn’t do my usual conference tweet notes storm, I only tweeted a few selected quotes. That has nothing to do with the conference being online, I was just too tired.ConclusionRegarding the content, it was, as always, great (I’ll talk more about it in my next post). The overall experience offered by the platform when attending sessions was good. But, I clearly had far less interactions than during a live conference where attendees can come to me right after the talk or later and where I can talk to people during breaks. The platform offers features allowing to do so though, I think it’s just a matter of time and changing my habits.So, am I 100% convinced by online conference? No. Because I will never have as much fun as I have when hanging out with my friends and attendees in the alleys and in the city where the conference takes place. But in these times, online conferences are far better than no conference at all. Thanks to them, we can still share our experiences and learn from others, even if we have less or different interactions with people."
},{
    "id": "41",
    "type": "post",
    "title": "I'd Rather Be Writing Podcast - API Design and Usability",
    "url": "https://apihandyman.io/i-d-rather-be-writing-podcast-api-design-and-usability/",
    "banner": "https://apihandyman.io/images/i-d-rather-be-writing-podcast-api-design-and-usability/banner.png",
    "description": "I had the pleasure to chat with Tom Johnson for his I’d Rather Be Writing Podcast. We talked about my book, The Design of Web APIs, and specifically best practices for designing web APIs and focus on the roles technical writers can play.",
    "body": "I had the pleasure to chat with Tom Johnson for his I’d Rather Be Writing Podcast. We talked about my book, The Design of Web APIs, and specifically best practices for designing web APIs and focus on the roles technical writers can play.Listen on idratherbewriting.com"
},{
    "id": "42",
    "type": "post",
    "title": "JQ and OpenAPI Series - Part 4 - Bonus: Coloring JQ's raw output",
    "url": "https://apihandyman.io/api-toolbox-jq-and-openapi-part-4-bonus-coloring-jqs-raw-output/",
    "banner": "https://apihandyman.io/images/api-toolbox-jq-and-openapi-part-4-bonus-coloring-jqs-raw-output/banner.png",
    "description": "Ever wanted to quickly find, extract or modify data coming from some JSON documents on the command line? JQ is the tool you’re looking for. The three previous parts of this JQ and OpenAPI Series, taught us to extract data from JSON (OpenAPI) files and modify them using many filters, creating modules and using command line arguments. To finish this series, we’ll learn to color JQ’s raw terminal output and do a colored version of part 2’s search operations.",
    "body": "Ever wanted to quickly find, extract or modify data coming from some JSON documents on the command line? JQ is the tool you’re looking for. The three previous parts of this JQ and OpenAPI Series, taught us to extract data from JSON (OpenAPI) files and modify them using many filters, creating modules and using command line arguments. To finish this series, we’ll learn to color JQ’s raw terminal output and do a colored version of part 2’s search operations. The screen capture below shows what we already have seen in part 1, JQ “colors its output” by default, but what it actually does is JSON syntax highlighting. What we want to do now is coloring raw terminal output, the one you get when using the -r flag and outputing text instead of JSON. After reading this post, you’ll be able to create JQ module doing output such as the colored version of search operations you see below.                                                      JQ and OpenAPI Series                      JQ’s documentation is quite complete and there are many tutorials and Stackoverflow answers, so why bother writing this series? First reason, I regularly meet people working with APIs and/or JSON files who actually don’t know JQ exists and how it could save their life (or at least their time). Second reason, I often use it with OpenAPI specification files and I found that showing how JQ can be used on such a widely adopted and familiar JSON based format could help to learn how to use it (and also writing this post actually helped me to improve my JQ skills!).                                                      1 - Using JQ to extract data from OpenAPI files                                      2 - Using JQ command line arguments, functions and modules                                      3 - Modifying OpenAPI files with JQ                                      4 - Bonus: Coloring JQ's raw output                                                                                                                  Get post’s contentAll examples shown in this post are based on JQ 1.6 and OpenAPI 3. All examples can be copied using the  button and downloaded using the  one on code snippets. All source code can be retrieved from the JQ and OpenAPI post series’ github repository.  git clone https://github.com/arno-di-loreto/jq-and-openapi/cd jq-and-openapigit checkout part-4                                                                                      [apihandyman.io]$ git clone https://github.com/arno-di-loreto/jq-and-openapi/[apihandyman.io]$ cd jq-and-openapi[apihandyman.io]$ git checkout part-4  Coloring JQ’s raw terminal outputBefore working on the colored version of the search operation jq module, we need to learn how to ouput basic raw colored text. As in previous posts, the content of this section is available as an Asciinema session.                    Coloring JQ's output                                                          Printing colored text in terminalWhen I got this idea of coloring jq’s raw output, I was not familiar with colored printing in terminal, so I started to tinker with the echo command as shown below. Line 1 simply prints Hello World without colors (in white). Line 2’s purpose is only to show what happens if you don’t provide the -e flag to echo: no colors. Line 3 prints Hello World in red. And eventually, line 4 prints Hello in red and World in white.                                                                      Colored echo                                                                  echo Hello Worldecho &#39;\\e[31mHello World&#39;echo -e &#39;\\e[31mHello World&#39;echo -e &#39;\\e[31mHello\\e[0m World&#39;  As you can see, printing in color requires to use cryptic character sequences. Basically, to print some text in color you need to concatenate:  The escape character \\e  A color code like [31m (red)  The text to color  The escape character \\e  The “reset” color code [0m which remove any style modification previously setIf you want to learn more about coloring text in terminal, I highly recommend reading bash:tip_colors_and_formatting, I learned everything I know about this topic reading this post.Coloring JQ raw outputLet’s try to replicate this colored echo example with jq. Line 1 is equivalent to our first non-colored echo \"Hello World\". We provide a JSON object with greeeting and who properties and concatenate them. On line 2 we add the escape charaecters and color codes to print the greeting value in red. But jq returns two “Invalid espace” errors (one for each \\e escape character. It seems jq does not like it. Hopefully there are multiple variant of this escape character. And replacing \\e by its unicode equivalent \\u001b do the trick: jq is able to concatenate all values (line 3). But the text is printed as a JSON string; simply because I did not put the -r flag. Line 4 shows jq -r printing colored raw text.                                                                      Colored jq                                                                  echo &#39;{ &quot;greeting&quot;: &quot;Hello&quot;, &quot;who&quot;:&quot;World&quot; }&#39; | jq &#39;.greeting + &quot; &quot; + .who&#39;echo &#39;{ &quot;greeting&quot;: &quot;Hello&quot;, &quot;who&quot;:&quot;World&quot; }&#39; | jq &#39;&quot;\\e[31m&quot; + .greeting + &quot;\\e[0m &quot; + .who&#39;echo &#39;{ &quot;greeting&quot;: &quot;Hello&quot;, &quot;who&quot;:&quot;World&quot; }&#39; | jq &#39;&quot;\\u001b[31m&quot; + .greeting + &quot;\\u001b[0m &quot; + .who&#39;echo &#39;{ &quot;greeting&quot;: &quot;Hello&quot;, &quot;who&quot;:&quot;World&quot; }&#39; | jq -r &#39;&quot;\\u001b[31m&quot; + .greeting + &quot;\\u001b[0m &quot; + .who&#39;  Defining a colored_text functionPrinting colored text with jq is is working almost like with echo. We just need to use the unicode escape character instead of \\e. But to be honest it’s quite complicated to write this escape character and color codes are not user friendly at all. So, let’s write some jq function in a module-color.jq file to make colored printing easier. The idea is to have a colored_text(\"some text\"; \"red\") function that prints “some text” in “red” (or “blue”).First, let’s define a variable holding the not-easy-to-type-and-remember unicode escape character. To use it, just include the jq file (see part 2) in which its defined and use its name.                    Escape character variable (module-color.jq)                                                                            def escape: \"\\u001b\";    jq -n &#39;include &quot;module-color&quot;;escape&#39;                    Using escape variable                                                                  [apihandyman.io] $ jq -n &#39;include &quot;module-color&quot;;escape&#39;&quot;\\u001b&quot;  Then, we define a map with user-friendly color names as keys and ugly color codes as values. Each value of a map can be accessed with map.key or map[\"key\"] syntax as shown in the bash snippet below.                    User friendly colors map (module-color.jq)                                                                            def colors: {  \"red\": \"[31m\",  \"green\": \"[32m\",  \"yellow\": \"[33m\",  \"blue\": \"[34m\",  \"darkgray\": \"[90m\",  \"disabled\": \"[30;100m\", # Black on darkgray  \"reset\": \"[0m\"};    jq -n &#39;include &quot;module-color&quot;;colors.red&#39;jq -n &#39;include &quot;module-color&quot;;colors[&quot;blue&quot;]&#39;                    Using escape variable                                                                  [apihandyman.io] $ jq -n &#39;include &quot;module-color&quot;;colors.red&#39;&quot;[31m&quot;[apihandyman.io] $ jq -n &#39;include &quot;module-color&quot;;colors[&quot;blue&quot;]&#39;&quot;[34m&quot;  Now that the variables are defined, we need to define a function that do all the needed concatenation to generate a string containing some text in color color:                    What the function does (module-color.jq)                                                                            def colored_text(text; color):  escape + colors[color] + text + escape + colors.reset;                                                                        Using colored_text function                                                                  jq -n &#39;include &quot;module-color&quot;;colored_text(&quot;some text&quot;; &quot;red&quot;)&#39;jq -r -n &#39;include &quot;module-color&quot;;colored_text(&quot;some text&quot;; &quot;red&quot;)&#39;jq -n &#39;include &quot;module-color&quot;;colored_text(&quot;some text&quot;; &quot;blue&quot;)&#39;jq -r -n &#39;include &quot;module-color&quot;;colored_text(&quot;some text&quot;; &quot;blue&quot;)&#39;  Here’s the complete module:                    Complete module-color.jq module                                                                            # To learn more about colors in terminal, see https://misc.flogisoft.com/bash/tip_colors_and_formatting# use with -r flag on jq command# Unicode escape character# \\e, \\033 and \\x1b cause \"Invalid escape\" errordef escape: \"\\u001b\";# Terminal color codesdef colors: {  \"red\": \"[31m\",  \"green\": \"[32m\",  \"yellow\": \"[33m\",  \"blue\": \"[34m\",  \"darkgray\": \"[90m\",  \"disabled\": \"[30;100m\", # Black on darkgray  \"reset\": \"[0m\"};# Colors text with the given color# colored_text(\"some text\"; \"red\")# will output # \\u001b[31msome text\\u001b[0m# WARNING parameters are separated by ; not ,def colored_text(text; color):  escape + colors[color] + text + escape + colors.reset;  Coloring OpenAPI search operations outputNow that we know how to output colored raw text, creating a colored version of search operation should be quite easy.                                                This section’s content is available as an Asciinema session:                    Colored search operations                                                          Analyzing original search operationsThe original non-colored search-operaions module shown below is quite simple thanks to what we have learned in part 2 of this series. It consists in three steps:  Retrieving operations data by reorganizing the data coming from an OpenAPI JSON file with oas_operation  Filters returned operation based on optionnal –arg parameters with filter_oas_operations  Print the result in JSON or text with print_oas_operations                    search-operations.jq                                                                            include \"module-openapi\";include \"module-args\";include \"module-openapi-search\";# Gets operations dataoas_operations# Filters operations| filter_oas_operations(init_parameters(default_filters))# Prints operations| print_oas_operations(init_parameters(default_print_parameters).format)  What we actually need to do to created a colored version of this module is copying it and modifythe last step to call a new function that will output text with some cryptic color codes.Creating a new print colored oas functionAs we have created a useful function that prints colored text, let’s include its module to be able to use it:                    Including colored_text function (module-openapi-operations-color.jq)                                                                            include \"module-color\";  The colored version of the print_oas_operations function, will print HTTP method in colors. In order to avoir having a complex if then elif else end statement, we proceeed like for color codes; we create a map but now each key is an HTTP method and its value is its user friendly color. So delete value is red for example.                    Defining HTTP colors (module-openapi-operations-color.jq)                                                                            def http_method_colors: { \"delete\": \"red\", \"post\": \"green\", \"patch\": \"yellow\", \"put\": \"yellow\", \"get\": \"blue\"};  And then in the print_colored_oas_operations to generate a string for each operation we colored_text on the various elements. Note on line 22 how the HTTP method color is easily chosen. Note also that deprecated operations are printined in black on dark gray using the disabled color.                    Generating string for each operation (module-openapi-operations-color.jq)                                                                                if .original.deprecated then      colored_text(        .method + \"\\t\" + .path + \"\\t\" + .summary + \" (deprecated)\";         \"disabled\"      )    else      colored_text(.method;http_method_colors[.method]) + \"\\t\" +       .path + \"\\t\" +       colored_text(.summary; \"darkgray\")    end  Here’s the complete module:                    Complete module-openapi-operations-color.jq module                                                                            include \"module-color\";# Colors to apply for each HTTP methoddef http_method_colors: { \"delete\": \"red\", \"post\": \"green\", \"patch\": \"yellow\", \"put\": \"yellow\", \"get\": \"blue\"};# Prints operations in SwaggerUI like styledef print_colored_oas_operations:  map( # Applies a transformation to each element    if .original.deprecated then      colored_text(        .method + \"\\t\" + .path + \"\\t\" + .summary + \" (deprecated)\";         \"disabled\"      )    else      colored_text(.method;http_method_colors[.method]) + \"\\t\" +       .path + \"\\t\" +       colored_text(.summary; \"darkgray\")    end  )  [] # Flattens array for raw output;  Creating a new search operations in color moduleAnd lastly, we create a new module that will be used with the -f parameter. The only difference with its uncolored counterpart is on line 4 (including the jq file containing the print_colored_oas_operation) and line 11 (actually calling the new function instead of print_oas_operation). Reminder, here’s the command line to use it jq -r -f search-operations-color.jq demo-api-openapi.json.                    search-operations-color.jq                                                                            include \"module-openapi\";include \"module-args\";include \"module-openapi-search\";include \"module-openapi-operations-color\";# Gets operations dataoas_operations# Filters operations| filter_oas_operations(init_parameters(default_filters))# Prints operations| print_colored_oas_operations  Obviously, it is quite possible to merge the colored and uncolored search operations to have a single module taking format parameters to print how you want. I let you work on that to apply everything you have learned so far.ConclusionThat concludes for now this JQ and OpenAPI series, I may add some other posts if I create interesting JQ+OpenAPI modules. Thanks to what you have learned about JQ, you should be able to do whatever you want on any OpenAPI file and even on any JSON document, especially the one you may retrieve with curl; that may be a good topic for another series by the way …"
},{
    "id": "43",
    "type": "post",
    "title": "API Design Reviewer's Starter Set",
    "url": "https://apihandyman.io/api-design-reviewers-starter-set/",
    "banner": "https://apihandyman.io/images/api-design-reviewers-starter-set/banner.png",
    "description": "Explore subterranean needs! Plunder hoards of inconsistency! Battle legendary design flaws! The API Design Reviewer’s Starter Set is your gateway to exhaustive and constructive API design reviews. It contains the essential rules of design reviews plus a few tips and trick that will be of great help on your perilous adventures in the API world.",
    "body": "My 2019 talk, The API Design Reviewer’s Starter Set, is about API design reviews and Dungeons and Dragons.You’ll find here its abstract, slides and video recorded at API Days London 2019.AbstractWhat could go possibly wrong when designing APIs? Everything.Among many other things, API Design may be inconsistent with pre-existing elements, may be bugged, may not fulfill needs, may be hard to understand or use, may be too specific and impossible to reuse, …Whatever the organization’s size, the type of APIs and the designers skills and experience, something will go wrong. That is why, any API design must be reviewed.During this session, I uncover everything you need to start reviewing the designs of your organization’s APIs.Explore subterranean needs! Plunder hoards of inconsistency! Battle legendary design flaws!The API Design Reviewer’s Starter Set is your gateway to exhaustive and constructive API design reviews. This session contains the essential rules of design reviews plus a few tips and trick that will be of great help on your perilous adventures in the API world.Video                                                This content is hosted on youtube.com.                By showing this third party content you accept YouTube (Google)'s                     privacy policy.                                                    Show third party content                                                                    Remember my choice                        (can be changed in privacy settings)                                                                                      SlidesDownload PDFOpen PDF    "
},{
    "id": "44",
    "type": "post",
    "title": "The Design of Everyday APIs",
    "url": "https://apihandyman.io/the-design-of-everyday-apis/",
    "banner": "https://apihandyman.io/images/the-design-of-everyday-apis/banner.png",
    "description": "Well-designed APIs are a joy to use; poorly-designed APIs are cumbersome, confusing and frustrating, just like everyday things. During this session, I make a parallel between everyday things design and API design to expose simple but fundamentals design principles.",
    "body": "I totally forgot to put my 2018 talk on the blog. It’s called The Design of Everyday APIs which was the working title of my book before it was renamed The Design of Web APIs. It’s about fundamental design principles and use famous swedish furniture instruction manual theme. The principles discussed in this session are deeply covered (with more others) in my book The Design of Web APIs.You’ll find here the talk’s abstract, slides and video which was recorded at Nordic API Platform Summit 2018.You can also read a write up on the Nordic API blog: The Three Principles of Excellent API Design.AbstractWell-designed APIs are a joy to use; poorly-designed APIs are cumbersome, confusing and frustrating, just like everyday things. During this session, I make a parallel between everyday things design and API design to expose simple but fundamentals design principles.Is using knobs better than using buttons? API design is more than REST vs GraphQL vs gRPC vs whatever existing or yet to come API style. Great design can be achieved using any type of API. Would you buy a Kitchen Radar 3000? Are you able to use any washing machine instantly without reading user manual? Why QWERTY layout was invented? Like everyday things, APIs must have a clear purpose, must be used easily by anyone and are constrained by their environment.Video                                                This content is hosted on youtube.com.                By showing this third party content you accept YouTube (Google)'s                     privacy policy.                                                    Show third party content                                                                    Remember my choice                        (can be changed in privacy settings)                                                                                      SlidesDownload PDFOpen PDF    "
},{
    "id": "45",
    "type": "post",
    "title": "JQ and OpenAPI Series - Part 3 - Modifying OpenAPI files with JQ",
    "url": "https://apihandyman.io/api-toolbox-jq-and-openapi-part-3-modifying-openapi-files-with-jq/",
    "banner": "https://apihandyman.io/images/api-toolbox-jq-and-openapi-part-3-modifying-openapi-files-with-jq/banner.png",
    "description": "Ever wanted to quickly find, extract or modify data coming from some JSON documents on the command line? JQ is the tool you’re looking for. Thanks to the two previous parts of this JQ and OpenAPI Series, we learned how to extract data from JSON (OpenAPI) files by discovering many filters, creating modules and using command line arguments. Now we will discover how to modify them; how to replace, add or delete elements in processed documents.",
    "body": "Ever wanted to quickly find, extract or modify data coming from some JSON documents on the command line? JQ is the tool you’re looking for. Thanks to the two previous parts of this JQ and OpenAPI Series, we learned how to extract data from JSON (OpenAPI) files by discovering many filters, creating modules and using command line arguments. Now we will discover how to modify them; how to replace, add or delete elements in processed documents.       JQ and OpenAPI Series                      JQ’s documentation is quite complete and there are many tutorials and Stackoverflow answers, so why bother writing this series? First reason, I regularly meet people working with APIs and/or JSON files who actually don’t know JQ exists and how it could save their life (or at least their time). Second reason, I often use it with OpenAPI specification files and I found that showing how JQ can be used on such a widely adopted and familiar JSON based format could help to learn how to use it (and also writing this post actually helped me to improve my JQ skills!).                                                      1 - Using JQ to extract data from OpenAPI files                                      2 - Using JQ command line arguments, functions and modules                                      3 - Modifying OpenAPI files with JQ                                      4 - Bonus: Coloring JQ's raw output                                                                                                                  Get post’s contentAll examples shown in this post are based on JQ 1.6 and OpenAPI 3. All examples can be copied using the  button and downloaded using the  one on code snippets. All source code can be retrieved from the JQ and OpenAPI post series’ github repository.  git clone https://github.com/arno-di-loreto/jq-and-openapi/cd jq-and-openapigit checkout part-3                                                                                      [apihandyman.io]$ git clone https://github.com/arno-di-loreto/jq-and-openapi/[apihandyman.io]$ cd jq-and-openapi[apihandyman.io]$ git checkout part-3  We will go on using the demo-api-openapi.json OpenAPI file in this post:                    demo-api-openapi.json                                                                            {\"openapi\":\"3.0.0\",\"info\":{\"title\":\"Banking API\",\"version\":\"1.0.0-snapshot\",\"description\":\"The Banking API provides access to the [Banking Company](http://www.bankingcompany.com) services, which include bank account information, beneficiaries, and money transfer management.&#60;!--more--&#62;\\n\\n# Authentication\\n\\n## How to \\n- Register\\n- Create an APP\\n- Request credentials\\n\\n# Use cases\\n\\n## Transferring money to an account or preexisting beneficiary\\n\\nThe _transfer money_ operation allows one to transfer an `amount` of money from a `source` account to a `destination` account or beneficiary.\\nIn order to use an appropriate `source` and `destination`, we recommend to use _list sources_ and _list source's destinations_ as shown in the figure below (instead of using _list accounts_ and _list beneficiaries_).\\n\\n![Diagram](http://localhost:9090/12.2-operation-manual-diagram.svg)\\n\\n## Cancelling a delayed or recurring money transfer\\n\\n- List money transfers: To list existing money transfers and select the one to delete\\n- Cancel a money transfer: To cancel the selected money transfer\\n\",\"contact\":{\"name\":\"The Banking API team\",\"email\":\"api@bankingcompany.com\",\"url\":\"developer.bankingcompany.com\"}},\"tags\":[{\"name\":\"Transfers\",\"description\":\"Everything you need to manage money transfers. A money transfer consists in transferring money from a source account to a destination account.\"},{\"name\":\"Beneficiaries\",\"description\":\"Everything you need to manage money transfer beneficiaries. Beneficiaries are pre-registred external accounts that can be used as destinations for money transfers.\"}],\"paths\":{\"/accounts\":{\"get\":{\"tags\":[\"Accounts\"],\"summary\":\"List accounts\",\"responses\":{\"200\":{\"description\":\"User's accounts\",\"content\":{\"application/json\":{\"schema\":{\"required\":[\"properties\"],\"properties\":{\"items\":{\"type\":\"array\",\"items\":{\"$ref\":\"#/components/schemas/Account\"}}}}}}}}}},\"/accounts/{id}\":{\"get\":{\"tags\":[\"Accounts\"],\"summary\":\"Get an account\",\"parameters\":[{\"name\":\"id\",\"in\":\"path\",\"description\":\"Account's id\",\"required\":true,\"schema\":{\"type\":\"string\"}}],\"responses\":{\"200\":{\"description\":\"The account\",\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/Account\"}}}},\"401\":{\"description\":\"Unauthorized\"}},\"x-implementation\":{\"security\":{\"description\":\"Only accounts belonging to user referenced in security data;\\nreturn a 404 if this is not the case\\n\",\"source\":{\"system\":\"security\",\"location\":\"jwt.sub\"},\"fail\":404}}}},\"/beneficiaries\":{\"post\":{\"tags\":[\"Beneficiaries\"],\"summary\":\"Register a beneficiary\",\"security\":[{\"BankingAPIScopes\":[\"beneficiary:create\",\"beneficiary:admin\"]}],\"responses\":{\"201\":{\"description\":\"Beneficiary added\"},\"401\":{\"description\":\"Unauthorized\"},\"403\":{\"description\":\"Forbidden\"}}},\"get\":{\"tags\":[\"Beneficiaries\"],\"summary\":\"List beneficiaries\",\"security\":[{\"BankingAPIScopes\":[\"beneficiary:read\",\"beneficiary:admin\"]}],\"responses\":{\"200\":{\"description\":\"The beneficiaries list\"}}}},\"/beneficiaries/{id}\":{\"parameters\":[{\"name\":\"id\",\"in\":\"path\",\"description\":\"Beneficiary's id\",\"required\":true,\"schema\":{\"type\":\"string\"}}],\"delete\":{\"deprecated\":true,\"tags\":[\"Beneficiaries\"],\"summary\":\"Delete a beneficiary\",\"security\":[{\"BankingAPIScopes\":[\"beneficiary:delete\",\"beneficiary:admin\"]}],\"responses\":{\"204\":{\"description\":\"Beneficiary deleted\"},\"401\":{\"description\":\"Unauthorized\"}}},\"patch\":{\"deprecated\":true,\"tags\":[\"Beneficiaries\"],\"summary\":\"Updates a beneficiary\",\"security\":[{\"BankingAPIScopes\":[\"beneficiary:admin\"]}],\"requestBody\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/BeneficiaryUpdate\"}}}},\"responses\":{\"200\":{\"description\":\"The updated beneficiary\"},\"401\":{\"description\":\"Unauthorized\"}}},\"get\":{\"tags\":[\"Beneficiaries\"],\"summary\":\"Get a beneficiary\",\"security\":[{\"BankingAPIScopes\":[\"beneficiary:read\",\"beneficiary:admin\"]}],\"responses\":{\"200\":{\"description\":\"The beneficiary\"}}}},\"/sources\":{\"get\":{\"summary\":\"List transfer sources\",\"tags\":[\"Transfers\"],\"description\":\"Not all bank accounts can be used as a source\\nfor a money transfers. This operation returns\\nonly the accounts elligible as a money transfer\\nsource.\\n\",\"responses\":{\"200\":{\"description\":\"The transfer sources\"}}}},\"/sources/{id}/destinations\":{\"parameters\":[{\"name\":\"id\",\"in\":\"path\",\"description\":\"Source's id\",\"required\":true,\"schema\":{\"type\":\"string\"}}],\"get\":{\"summary\":\"List transfer source's destinations\",\"tags\":[\"Transfers\"],\"description\":\"Depending on the source account, only specific\\nbeneficiaries or accounts can be used as a money\\ntransfer destination.\\nThis operation returns them.\\n\",\"responses\":{\"200\":{\"description\":\"The transfer destination\"}}}},\"/transfers\":{\"post\":{\"summary\":\"Transfer money\",\"security\":[{\"BankingAPIScopes\":[\"transfer:create\",\"transfer:admin\"]}],\"tags\":[\"Transfers\"],\"description\":\"This operation allows one to transfer an `amount` of money from a `source` account to a `destination` account.\\nThere are three different types of money transfer:\\n  - Immediate -- these are executed as soon as the request is received \\n  - Delayed -- these are executed upon a given future `date`\\n  - Recurring -- these are executed a given `occurrences` number of times at a given `frequency` -- the first occurrence being executed immediately or at a given `date`\\n\",\"requestBody\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/TransferRequest\"},\"examples\":{\"immediate\":{\"summary\":\"Immediate transfer\",\"description\":\"The money transfer is executed immediately\",\"value\":{\"source\":\"000534115776675\",\"destination\":\"000567689879878\",\"amount\":456.2}},\"delayed\":{\"summary\":\"Delayed transfer\",\"description\":\"The money transfer is executed at a given date\",\"value\":{\"source\":\"000534115776675\",\"destination\":\"000567689879878\",\"amount\":456.2,\"date\":\"2019-03-19\"}},\"recurring\":{\"summary\":\"Recurring transfer\",\"description\":\"The money transfer is executed at a given date reurringly\",\"value\":{\"source\":\"000534115776675\",\"destination\":\"000567689879878\",\"amount\":456.2,\"date\":\"2019-03-19\",\"occurrences\":1,\"frequency\":\"MONTHLY\"}}}}}},\"responses\":{\"201\":{\"description\":\"Immediate or recurring transfer executed\",\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/TransferResponse\"},\"examples\":{\"immediate\":{\"summary\":\"Immediate transfer\",\"description\":\"The money transfer is executed immediately\",\"value\":{\"source\":\"000534115776675\",\"destination\":\"000567689879878\",\"amount\":456.2}},\"recurring\":{\"summary\":\"Recurring transfer\",\"description\":\"The first occurence is executed immediately\",\"value\":{\"source\":\"000534115776675\",\"destination\":\"000567689879878\",\"amount\":456.2,\"date\":\"2019-03-19\",\"occurrences\":1,\"frequency\":\"MONTHLY\"}}}}}},\"202\":{\"description\":\"Delayed or recurring delayed transfer accepted\",\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/TransferResponse\"},\"examples\":{\"delayed\":{\"summary\":\"Delayed transfer\",\"description\":\"The money transfer is executed at a given date\",\"value\":{\"source\":\"000534115776675\",\"destination\":\"000567689879878\",\"amount\":456.2,\"date\":\"2019-03-19\"}},\"recurring\":{\"summary\":\"Recurring transfer\",\"description\":\"The money transfer is executed at a given date reurringly\",\"value\":{\"source\":\"000534115776675\",\"destination\":\"000567689879878\",\"amount\":456.2,\"date\":\"2019-03-19\",\"occurrences\":1,\"frequency\":\"MONTHLY\"}}}}}},\"400\":{\"description\":\"The transfer is rejected due to an error in the request properties or an insufficient balance.\\nEach error provides the property `source` of the error along with a human-readable `message` and its `type`:\\n\\n- MANDATORY_PROPERTY: The property indicated in `source` is missing\\n- INVALID_FORMAT: The format of the property indicated in `source` is invalid\\n- INVALID_VALUE: The value of the property indicated in `source` is invalid\\n- INSUFFICIENT_BALANCE: The `amount` property is higher than the `source` account balance\\n\",\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/ConsumerError\"}}}}}},\"get\":{\"summary\":\"List money transfers\",\"tags\":[\"Transfers\"],\"security\":[{\"BankingAPIScopes\":[\"transfer:read\",\"transfer:admin\"]}],\"responses\":{\"200\":{\"description\":\"Transfers list\",\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/TransferList\"}}}}}}},\"/transfers/{id}\":{\"parameters\":[{\"name\":\"id\",\"in\":\"path\",\"description\":\"Transfer's id\",\"required\":true,\"schema\":{\"type\":\"string\"}}],\"get\":{\"summary\":\"Get a money transfer\",\"tags\":[\"Transfers\"],\"security\":[{\"BankingAPIScopes\":[\"transfer:read\",\"transfer:admin\"]}],\"responses\":{\"200\":{\"description\":\"The money transfer\"},\"404\":{\"description\":\"The money transfer does not exist\"}}},\"x-tension-example\":{\"some\":\"value\"},\"patch\":{\"tags\":[\"Transfers\"],\"responses\":{\"200\":{\"description\":\"The money transfer has been update\"}}},\"delete\":{\"summary\":\"Cancel a money transfer\",\"tags\":[\"Transfers\"],\"security\":[{\"BankingAPIScopes\":[\"transfer:delete\",\"transfer:admin\"]}],\"description\":\"Only delayed or recurring money transfer can be canceled\",\"responses\":{\"204\":{\"description\":\"The money transfer has been deleted\"},\"404\":{\"description\":\"The money transfer does not exist\"}}}}},\"components\":{\"securitySchemes\":{\"BankingAPIScopes\":{\"type\":\"oauth2\",\"flows\":{\"implicit\":{\"authorizationUrl\":\"https://auth.bankingcompany.com/authorize\",\"scopes\":{\"transfer:create\":\"Create transfers\",\"transfer:read\":\"Read transfers\",\"transfer:delete\":\"Delete transfers\",\"transfer:admin\":\"Create, read, and delete transfers\",\"beneficiary:create\":\"Create beneficiaries\",\"beneficiary:read\":\"List beneficiaries\",\"beneficiary:delete\":\"delete beneficiaries\",\"beneficiary:admin\":\"Create, read, and delete beneficiaries\",\"account:read\":\"Read accounts\",\"account:admin\":\"Read accounts\"}}}}},\"schemas\":{\"BeneficiaryUpdate\":{\"description\":\"A beneficiary update parameter\",\"properties\":{\"name\":{\"type\":\"string\"}}},\"UselessSchema\":{\"description\":\"An unused useless schema\",\"type\":\"string\"},\"TransferRequest\":{\"description\":\"A money transfer request\",\"required\":[\"source\",\"destination\",\"amount\"],\"properties\":{\"deprecatedPropertyExample\":{\"deprecated\":true,\"type\":\"string\",\"description\":\"An example of a deprecated property\"},\"source\":{\"type\":\"string\",\"description\":\"Source account number\",\"minLength\":15,\"maxLength\":15,\"pattern\":\"^\\\\d{15}$\",\"example\":\"000534115776675\"},\"destination\":{\"type\":\"string\",\"description\":\"Destination account number\",\"minLength\":15,\"maxLength\":15,\"pattern\":\"^\\\\d{15}$\",\"example\":\"000567689879878\"},\"amount\":{\"type\":\"number\",\"example\":456.2,\"minimum\":0,\"exclusiveMinimum\":true},\"date\":{\"type\":\"string\",\"format\":\"date\",\"description\":\"Execution date for a delayed transfer\\nor first execution date for a recurring one\\n\",\"example\":\"2019-03-19\"},\"occurrences\":{\"type\":\"integer\",\"description\":\"Number of times a recurring transfer will be executed\\n\",\"example\":2,\"minimum\":2,\"maximum\":100},\"frequency\":{\"type\":\"string\",\"description\":\"Frequency of recurring transfer's execution\",\"example\":\"MONTHLY\",\"enum\":[\"WEEKLY\",\"MONTHLY\",\"QUARTERLY\",\"YEARLY\"]}}},\"TransferResponse\":{\"allOf\":[{\"required\":[\"id\",\"type\",\"status\"],\"properties\":{\"id\":{\"type\":\"string\",\"example\":\"1611e71f-1bb2-412f-8c43-92b275a5c321\"},\"type\":{\"type\":\"string\",\"enum\":[\"IMMEDIATE\",\"DELAYED\",\"RECURRING\"],\"example\":\"RECURRING\"},\"status\":{\"type\":\"string\",\"description\":\"An immediate transfer is always `EXECUTED`, a delayed transfer can be `EXECUTED` or `PENDING` and a recurring one is always `PENDING`\\n\",\"enum\":[\"EXECUTED\",\"PENDING\"],\"example\":\"PENDING\"},\"requestDate\":{\"type\":\"string\",\"example\":\"2019-09-19\"}}},{\"$ref\":\"#/components/schemas/TransferRequest\"}]},\"TransferList\":{\"properties\":{\"items\":{\"type\":\"array\",\"items\":{\"$ref\":\"#/components/schemas/TransferResponse\"}}}},\"ConsumerError\":{\"required\":[\"errors\"],\"properties\":{\"errors\":{\"description\":\"A list of errors providing detailed information about the problem\",\"type\":\"array\",\"minItems\":1,\"items\":{\"required\":[\"source\",\"type\",\"message\"],\"properties\":{\"source\":{\"description\":\"the property source of the error\",\"type\":\"string\",\"example\":\"amount\",\"enum\":[\"source\",\"destination\",\"amount\",\"date\",\"occurrences\",\"frequency\"]},\"type\":{\"type\":\"string\",\"example\":\"MANDATORY_PROPERTY\",\"enum\":[\"MANDATORY_PROPERTY\",\"INVALID_FORMAT\",\"INVALID_VALUE\",\"INSUFFICIENT_BALANCE\"]},\"message\":{\"description\":\"a human-readable error message\",\"type\":\"string\",\"example\":\"The money transfer's amount must be provided\"}}}}}},\"ProviderError\":{\"properties\":{\"errors\":{\"type\":\"array\",\"minItems\":1,\"maxItems\":1,\"items\":{\"properties\":{\"message\":{\"type\":\"string\"}}}}}},\"Account\":{\"properties\":{\"balance\":{\"description\":\"The balance in the account's default currency\",\"type\":\"object\",\"title\":\"Amount\",\"required\":[\"value\",\"currency\"],\"properties\":{\"value\":{\"description\":\"Balance's value using the number of decimal places defined by ISO 4217\",\"externalDocs\":{\"description\":\"Decimal places table\",\"url\":\"https://www.currency-iso.org/en/home/tables/table-a1.html\"},\"type\":\"number\",\"x-implementation\":{\"description\":\"The real time balance (not the daily one!)\",\"source\":{\"system\":\"Core Banking\",\"data\":\"ZBAL0.RTBAL\"}}},\"currency\":{\"description\":\"An ISO 4217 code\",\"externalDocs\":{\"url\":\"https://www.iso.org/iso-4217-currency-codes.html\"},\"type\":\"string\",\"example\":\"USD\",\"x-implementation\":{\"source\":{\"system\":\"Core Banking\",\"data\":\"ZBAL0.RTCUR\"}}}}}}}}}}  Replacing elementsIt’s fairly common to tweak OpenAPI files, especially before putting them in an API portal. You may have to replace some server URLs, update version number and replace some descriptions. That can be easily done with JQ. To learn how to replace values, we’ll work on the info section of demo-api-openapi.json with = and |= operators . And we will also see how to save the modified file because it wouldn’t make any sense to not be able to save our modifications.              JQ Operators                    .info.description = \"New description.\".info.description = .info.contact.name      Replaces a value, the input to the right-hand-side (rhs) is the same as the input to the left-hand-side (lhs) rather than the value at the lhs path                    .info.contact |= .name.info.version |= sub(\"-snapshot\";\"\")      Replaces a value, it takes a filter on the right-hand side and works out the new value for the property of `.` being assigned to by running the old value through this expression            This section’s content is also available as an asciinema bash session:                    Replacing elements                                                          Replacing a value with =The following command line shows how to print the .info.description property of demo-api-openapi.json file (as we have learned to do so in part 1 of this post series):  jq &#39;.info.description&#39; demo-api-openapi.json                    Printing .info.description original value                                                                  [apihandyman.io] $jq &#39;.info.description&#39; demo-api-openapi.json &quot;The Banking API provides access to the [Banking Company](http://www.bankingcompany.com) services, which include bank account information, beneficiaries, and money transfer management.&lt;!--more--&gt;\\n\\n# Authentication\\n\\n## How to \\n- Register\\n- Create an APP\\n- Request credentials\\n\\n# Use cases\\n\\n## Transferring money to an account or preexisting beneficiary\\n\\nThe _transfer money_ operation allows one to transfer an `amount` of money from a `source` account to a `destination` account or beneficiary.\\nIn order to use an appropriate `source` and `destination`, we recommend to use _list sources_ and _list source&#39;s destinations_ as shown in the figure below (instead of using _list accounts_ and _list beneficiaries_).\\n\\n![Diagram](http://localhost:9090/12.2-operation-manual-diagram.svg)\\n\\n## Cancelling a delayed or recurring money transfer\\n\\n- List money transfers: To list existing money transfers and select the one to delete\\n- Cancel a money transfer: To cancel the selected money transfer\\n&quot;  The next listing shows how modifying this value is as simple, thanks to = operator. By adding =\"New description\" after the property’s path, its content is modified like in any programming language. And now instead of returning the .info.description value, jq returns the whole document in which this property’s value has been replaced by “New description”.The listing shows also 2 different ways to only show what we need to see. The first one is to use head (which show only the nth first line) and the second one consists in piping the result of jq in another jq command to show only the value of .info.description.  jq &#39;.info.description=&quot;New description&quot;&#39; demo-api-openapi.jsonjq &#39;.info.description=&quot;New description&quot;&#39; demo-api-openapi.json | head -n6jq &#39;.info.description=&quot;New description&quot;&#39; demo-api-openapi.json | jq &#39;.info.description&#39;                    Modifying .info.description                                                                  [apihandyman.io] $jq &#39;.info.description=&quot;New description&quot;&#39; demo-api-openapi.json{...full modified document ...}[apihandyman.io] $jq &#39;.info.description=&quot;New description&quot;&#39; demo-api-openapi.json | head -n6 {  &quot;openapi&quot;: &quot;3.0.0&quot;,  &quot;info&quot;: {    &quot;title&quot;: &quot;Banking API&quot;,    &quot;version&quot;: &quot;1.0.0-snapshot&quot;,    &quot;description&quot;: &quot;New description&quot;,[apihandyman.io] $jq &#39;.info.description=&quot;New description&quot;&#39; demo-api-openapi.json | jq &#39;.info.description&#39;&quot;New description&quot;  Anything can be put on the right side of the = operator as shown in the following listing. The command line allows to replace the value of .info.contact by another JSON object.  jq &#39;.info.contact&#39; demo-api-openapi.jsonjq &#39;.info.contact = { name: &quot;The Awesome Banking API Team&quot;, url: &quot;www.bankingcompany.com&quot; }&#39; demo-api-openapi.json | jq &#39;.info.contact&#39;                    Modifying an entire object value                                                                  [apihandyman.io] $jq &#39;.info.contact&#39; demo-api-openapi.json{  &quot;name&quot;: &quot;The Banking API team&quot;,  &quot;email&quot;: &quot;api@bankingcompany.com&quot;,  &quot;url&quot;: &quot;developer.bankingcompany.com&quot;}[apihandyman.io] $jq &#39;.info.contact = { name: &quot;The Awesome Banking API Team&quot;, url: &quot;www.bankingcompany.com&quot; }&#39; demo-api-openapi.json | jq &#39;.info.contact&#39;{  &quot;name&quot;: &quot;The Awesome Banking API Team&quot;,  &quot;url&quot;: &quot;www.bankingcompany.com&quot;}  Saving (a copy of) modified fileBut those command lines did not actually saved the modified files; indeed the modified content is just printed in the terminal. Unfortunately jq does not come with in-place modification like sed. But that’s not really a problem, we can use a good old &gt; to save result in another file as shown below (and once really sure of what we have done, we can replace the original one).  jq &#39;.info.description=&quot;New description&quot;&#39; demo-api-openapi.json &gt; demo-api-openapi-mod.jsonjq &#39;.info.description&#39; demo-api-openapi-mod.json                    Saving modified file                                                                  [apihandyman.io] $jq &#39;.info.description=&quot;New description&quot;&#39; demo-api-openapi.json &gt; demo-api-openapi-mod.json [apihandyman.io] $jq &#39;.info.description&#39; demo-api-openapi-mod.json&quot;New description&quot;  Using filters when replacing a valueWhen I said that anything can be put on the right side, it’s virtually anything; including complex filters chains like the one we have learned to create previously in part 1 and 2. Let’s see that with a very simple example. The following listing shows how to delete the “-snapshot” suffix from the .info.version property using the sub filter (which replaces a string by another one inside a string) on the .info.version property.  jq &#39;.info.version&#39; demo-api-openapi.json jq &#39;.info.version = (.info.version | sub(&quot;-snapshot&quot;;&quot;&quot;))&#39; demo-api-openapi.jsonjq &#39;.info.version = (.info.version | sub(&quot;-snapshot&quot;;&quot;&quot;))&#39; demo-api-openapi.json | jq &#39;.info.version&#39;                     Using filters                                                                  [apihandyman.io]$ jq &#39;.info.version&#39; demo-api-openapi.json&quot;1.0.0-snapshot&quot;[apihandyman.io]$ jq &#39;.info.version = (.info.version | sub(&quot;-snapshot&quot;;&quot;&quot;))&#39; demo-api-openapi.json{  ...full modified document}[apihandyman.io]$ jq &#39;.info.version = (.info.version | sub(&quot;-snapshot&quot;;&quot;&quot;))&#39; demo-api-openapi.json | jq &#39;.info.version&#39;&quot;1.0.0&quot;  Did you noticed the parenthesis around the right side of the = operator? They are very important. If you forget them, be ready to face more or less unexpected consequences depending on what you do. Here it hopefully break swith an error without silently doing nasty stuff. Indeed, here, without (), the result of .info.version = .info.version, which is the whole document (a JSON object), is piped into the sub filter which expects a string. So always put parenthesis around the right side if there are some piped filters.  jq &#39;.info.version = (.info.version | sub(&quot;-snapshot&quot;;&quot;&quot;))&#39; demo-api-openapi.jsonjq &#39;.info.version = .info.version | sub(&quot;-snapshot&quot;;&quot;&quot;)&#39;  demo-api-openapi.json                    Do not forget parenthesis                                                                  [apihandyman.io]$ jq &#39;.info.version = (.info.version | sub(&quot;-snapshot&quot;;&quot;&quot;))&#39; demo-api-openapi.json | jq &#39;.info.version&#39;&quot;1.0.0&quot;[apihandyman.io]$ jq &#39;.info.version = .info.version | sub(&quot;-snapshot&quot;;&quot;&quot;)&#39;  demo-api-openapi.jsonjq: error (at demo-api-openapi.json:0): object ({&quot;openapi&quot;:...) cannot be matched, as it is not a string  And again, when I said that anything could be put on the right side, it’s really anything. Even anything from from anywhere. For example, the following command line put the modified version number into the description.  jq &#39;.info.description&#39; demo-api-openapi.jsonjq &#39;.info.description = (.info.version | sub(&quot;-snapshot&quot;;&quot;&quot;))&#39; demo-api-openapi.json | jq &#39;.info.description&#39;                    Using anything from anywhere                                                                  [apihandyman.io]$ jq &#39;.info.description&#39; demo-api-openapi.json&quot;The Banking API provides access to the [Banking Company](http://www.bankingcompany.com) services, which include bank account information, beneficiaries, and money transfer management.&lt;!--more--&gt;\\n\\n# Authentication\\n\\n## How to \\n- Register\\n- Create an APP\\n- Request credentials\\n\\n# Use cases\\n\\n## Transferring money to an account or preexisting beneficiary\\n\\nThe _transfer money_ operation allows one to transfer an `amount` of money from a `source` account to a `destination` account or beneficiary.\\nIn order to use an appropriate `source` and `destination`, we recommend to use _list sources_ and _list source&#39;s destinations_ as shown in the figure below (instead of using _list accounts_ and _list beneficiaries_).\\n\\n![Diagram](http://localhost:9090/12.2-operation-manual-diagram.svg)\\n\\n## Cancelling a delayed or recurring money transfer\\n\\n- List money transfers: To list existing money transfers and select the one to delete\\n- Cancel a money transfer: To cancel the selected money transfer\\n&quot;[apihandyman.io]$ jq &#39;.info.description = (.info.version | sub(&quot;-snapshot&quot;;&quot;&quot;))&#39; demo-api-openapi.json | jq &#39;.info.description&#39;&quot;1.0.0&quot;  Replacing a value with |=deleting “-snapshot” from the version number can be done in a more elegant way using the |= operator, as shown in the following listing. Thanks to this operator, when using . on the right side, you only get what was passed on the left side and so you may not need to use | (reminder . | some_filter is equivalent to some_filter).  jq &#39;.info.version&#39; demo-api-openapi.json jq &#39;.info.version |= sub(&quot;-snapshot&quot;;&quot;&quot;)&#39; demo-api-openapi.jsonjq &#39;.info.version |= sub(&quot;-snapshot&quot;;&quot;&quot;)&#39; demo-api-openapi.json | jq &#39;.info.version&#39;                     Using |= instead of =                                                                  [apihandyman.io]$ jq &#39;.info.version&#39; demo-api-openapi.json&quot;1.0.0-snapshot&quot;[apihandyman.io]$ jq &#39;.info.version |= sub(&quot;-snapshot&quot;;&quot;&quot;)&#39; demo-api-openapi.json{  ...full modified document}[apihandyman.io]$ jq &#39;.info.version |= sub(&quot;-snapshot&quot;;&quot;&quot;)&#39; demo-api-openapi.json | jq &#39;.info.version&#39;&quot;1.0.0&quot;  That works with objects, let’s invert email and url values in the contact object. As you can see, url value is accessed with .url as only the contact object value is available on the right side (same for email); if we had used = we should have used .info.contact.url. Note also how name is kept unmodified by just using name.  jq &#39;.info.contact&#39; demo-api-openapi.json jq &#39;.info.contact |= { name, url: .email, email: .url }&#39; demo-api-openapi.jsonjq &#39;.info.contact |= { name, url: .email, email: .url }&#39; demo-api-openapi.json | jq &#39;.info.contact&#39;                    |= operator works on object too                                                                  [apihandyman.io]$ jq &#39;.info.contact&#39; demo-api-openapi.json{  &quot;name&quot;: &quot;The Banking API team&quot;,  &quot;email&quot;: &quot;api@bankingcompany.com&quot;,  &quot;url&quot;: &quot;developer.bankingcompany.com&quot;}[apihandyman.io]$ jq &#39;.info.contact |= { name, url: .email, email: .url }&#39; demo-api-openapi.json{  ...full modified document}[apihandyman.io]$ jq &#39;.info.contact |= { name, url: .email, email: .url }&#39; demo-api-openapi.json | jq &#39;.info.contact&#39;&quot;1.0.0&quot;  Chaining modificationsObviously, jq allows to do more than one modification at a time. You probably already guessed how to do so, you just need to pipe all modifications one after another as shown below on line 12 and 16. Here, we replace .info.description value by “New description.” using = and then | the result to another modification consisting in deleting “-snapshot” from .info.version using |= and sub. The final result shows both modifications.  jq &#39;.info&#39; demo-api-openapi.jsonjq &#39;(.info.description = &quot;New description.&quot;) | (.info.version |= sub(&quot;-snapshot&quot;;&quot;&quot;))&#39; demo-api-openapi.jsonjq &#39;(.info.description = &quot;New description.&quot;) | (.info.version |= sub(&quot;-snapshot&quot;;&quot;&quot;))&#39; demo-api-openapi.json | jq &#39;.info&#39;                                                                                      [apihandyman.io]$ jq &#39;.info&#39; demo-api-openapi.json{  &quot;title&quot;: &quot;Banking API&quot;,  &quot;version&quot;: &quot;1.0.0-snapshot&quot;,  &quot;description&quot;: &quot;The Banking API provides access to the [Banking Company](http://www.bankingcompany.com) services, which include bank account information, beneficiaries, and money transfer management.&lt;!--more--&gt;\\n\\n# Authentication\\n\\n## How to \\n- Register\\n- Create an APP\\n- Request credentials\\n\\n# Use cases\\n\\n## Transferring money to an account or preexisting beneficiary\\n\\nThe _transfer money_ operation allows one to transfer an `amount` of money from a `source` account to a `destination` account or beneficiary.\\nIn order to use an appropriate `source` and `destination`, we recommend to use _list sources_ and _list source&#39;s destinations_ as shown in the figure below (instead of using _list accounts_ and _list beneficiaries_).\\n\\n![Diagram](http://localhost:9090/12.2-operation-manual-diagram.svg)\\n\\n## Cancelling a delayed or recurring money transfer\\n\\n- List money transfers: To list existing money transfers and select the one to delete\\n- Cancel a money transfer: To cancel the selected money transfer\\n&quot;,  &quot;contact&quot;: {    &quot;name&quot;: &quot;The Banking API team&quot;,    &quot;email&quot;: &quot;api@bankingcompany.com&quot;,    &quot;url&quot;: &quot;developer.bankingcompany.com&quot;  }}[apihandyman.io]$ jq &#39;(.info.description = &quot;New description.&quot;) | (.info.version |= sub(&quot;-snapshot&quot;;&quot;&quot;))&#39; demo-api-openapi.json{  ...full modified document...}[apihandyman.io]$ jq &#39;(.info.description = &quot;New description.&quot;) | (.info.version |= sub(&quot;-snapshot&quot;;&quot;&quot;))&#39; demo-api-openapi.json | jq &#39;.info&#39;{  &quot;title&quot;: &quot;Banking API&quot;,  &quot;version&quot;: &quot;1.0.0&quot;,  &quot;description&quot;: &quot;New description.&quot;,  &quot;contact&quot;: {    &quot;name&quot;: &quot;The Banking API team&quot;,    &quot;email&quot;: &quot;api@bankingcompany.com&quot;,    &quot;url&quot;: &quot;developer.bankingcompany.com&quot;  }}  JQ moduleHere’s a JQ module demonstrating the various use of = and |= we have seen (use jq -r replace.jq demo-api-openapi.json to see it in action).                    replace.jq                                                                            # Basic value replacement using =(.info.description = \"New description.\") | # modified document                                           # goes to next step# Using processing when setting value(.info.version = (.info.version | sub(\"-snapshot\";\"-no-snapshot\"))) |# Any type of value can be provided on right side of =(  .info.contact = {                     name: \"The Awesome Banking API Team\",                     email: \"www.bankingcompany.com\"                  }) |# |= can also be used to only work on what is provided on left side(.info.version |= sub(\"-no-snapshot\";\"\")) |# It works on objects too(  .info.contact |= {                     name, # unmodified                     url: .email, # path of value inside .info.contact                    email: \"api@bankingcompany.com\"                  })  Adding elementsJQ does not only allow to replace existing values, it allows also to add elements thanks to the += operator which can be used on many kind of value and |= which can be used on objects.              JQ Operators                    .info.description += \"More description\".info.description += .info.contact.name      Increments a number value, concatenates string or add properties to object                                      This section’s content is also available as an asciinema bash session:                    Adding elements                                                          Appending to a string with +=The += operator is used in various programming language; a+=x usually means a=a+x and jq is no exception. But if such operator is usually to be used with numbers, jq allows to use it with other types such as string as shown in the listing below. As comparison, line 3 and 5 shows how to add the “ is awesome” string to .info.contact.name using = and |=. And line 5 shows how to do the same modification using +=.  jq &#39;.info.contact.name&#39; demo-api-openapi.json jq &#39;.info.contact.name = .info.contact.name + &quot; is awesome&quot;&#39; demo-api-openapi.json | jq &#39;.info.contact.name&#39;jq &#39;.info.contact.name |= . + &quot; is awesome&quot;&#39; demo-api-openapi.json | jq &#39;.info.contact.name&#39;jq &#39;.info.contact.name += &quot; is awesome&quot;&#39; demo-api-openapi.json | jq &#39;.info.contact.name&#39;                    Appending to a string                                                                  [apihandyman.io]$ jq &#39;.info.contact.name&#39; demo-api-openapi.json &quot;The Banking API team&quot;[apihandyman.io]$ jq &#39;.info.contact.name = .info.contact.name + &quot; is awesome&quot;&#39; demo-api-openapi.json | jq &#39;.info.contact.name&#39;&quot;The Banking API team is awesome&quot;[apihandyman.io]$ jq &#39;.info.contact.name |= . + &quot; is awesome&quot;&#39; demo-api-openapi.json | jq &#39;.info.contact.name&#39;&quot;The Banking API team is awesome&quot;[apihandyman.io]$ jq &#39;.info.contact.name += &quot; is awesome&quot;&#39; demo-api-openapi.json | jq &#39;.info.contact.name&#39;&quot;The Banking API team is awesome&quot;  Adding properties to object with +=More interesting, += can be used on objects; that means it can be used to add properties to existing objects. The following listing shows how a Slack channel name can be added to .info.contact. All that is needed is to put an object with the desired properties on the right side of +=.Note that this new property name is prefixed with x-; indeed the standard OpenAPI Contact object does not have such property but the OpenAPI specification allows to add custom ones. They must be prefixed by x- so parsers can detect them and do not consider them as errors. Note also that as this name contains a - is must b quoted.  jq &#39;.info.contact&#39; demo-api-openapi.jsonjq &#39;.info.contact += {&quot;x-slack&quot;: &quot;apiteam&quot; }&#39; demo-api-openapi.json | jq &#39;.info.contact&#39;                    Adding properties                                                                  [apihandyman.io]$ jq &#39;.info.contact&#39; demo-api-openapi.json{  &quot;name&quot;: &quot;The Banking API team&quot;,  &quot;email&quot;: &quot;api@bankingcompany.com&quot;,  &quot;url&quot;: &quot;developer.bankingcompany.com&quot;}[apihandyman.io]$ jq &#39;.info.contact += {&quot;x-slack&quot;: &quot;api-team&quot; }&#39; demo-api-openapi.json | jq &#39;.info.contact&#39;{  &quot;name&quot;: &quot;The Banking API team&quot;,  &quot;email&quot;: &quot;api@bankingcompany.com&quot;,  &quot;url&quot;: &quot;developer.bankingcompany.com&quot;,  &quot;x-slack&quot;: &quot;apiteam&quot;}  Adding and updating properties with +=Another interesting aspect of += is that it can be used to replace values inside an object as shown below. The jq command on line 7 still adds a x-slack property to .info.contact but it also updates the existing name to “The Awesome Banking API team”.  jq &#39;.info.contact&#39; demo-api-openapi.jsonjq &#39;.info.contact += { name: &quot;The Awesome Banking API team&quot;, &quot;x-slack&quot;: &quot;apiteam&quot; }&#39; demo-api-openapi.json | jq &#39;.info.contact&#39;                    Adding and updating properties                                                                  [apihandyman.io]$ jq &#39;.info.contact&#39; demo-api-openapi.json{  &quot;name&quot;: &quot;The Banking API team&quot;,  &quot;email&quot;: &quot;api@bankingcompany.com&quot;,  &quot;url&quot;: &quot;developer.bankingcompany.com&quot;}[apihandyman.io]$ jq &#39;.info.contact += { name: &quot;updated name&quot;, &quot;x-slack&quot;: &quot;apiteam&quot; }&#39; demo-api-openapi.json | jq &#39;.info.contact&#39;{  &quot;name&quot;: &quot;The Awesome Banking API team&quot;,  &quot;email&quot;: &quot;api@bankingcompany.com&quot;,  &quot;url&quot;: &quot;developer.bankingcompany.com&quot;,  &quot;x-slack&quot;: &quot;apiteam&quot;}  JQ moduleBefore going further and to add real stuff on an OpenAPI file, here’s a jq module summarizing what we have learned about +=.                    add.jq                                                                            # += adds anything to an existing value# String concatenation# Equivalent to #   .info.contact.name = .info.contact.name + \" is awesome\"#   .info.contact.name |= . + \" is awesome\"(.info.contact.name += \" is awesome\") | # Equivalent to .info.contact.name = .info.contact.name + \" is awesome\"# Adding a property(.info.contact += {\"x-slack\": \"api-team\" }) |# Adding a property and updating existing name(.info.contact += {\"x-fax\": \"555-06-777\", name: \"The Awesome Banking API team\"})  Adding missing 500 response when needed with +=So far, we have replaced/add to known elements (.info.version) inside the demo OpenAPI file. Whatever the operator used (=, |= or +=,), we only provided them a static reference to update. But jq is more clever than that, we already have seen that we can but anything on the right side of an operator, it’s the same on the left side.Let’s say we have an OpenAPI file in which some operations lack the definition of 500 (unexpected server error) responses. We could use += on their responses list to add the missing 500 response.                                                The path to each operations responses list is .paths.&lt;some path&gt;.&lt;some http method&gt;.responses, unfortunately, path and http method will never be the same and some operations may have a 500 response defined. We could manually and painfully list all the response without 500 and then write a jq file to update them all… Hopefully we won’t. We can let jq search and update the responses lists when needed.First we need to identify the operation missing a 500 reponse. This is done with the following jq filters.                      Selecting responses list without 500                                                                  .paths[][] |select(type == &quot;object&quot;) |select(has(&quot;responses&quot;)) | .responses |select(has(&quot;500&quot;) | not)  Note that we cannot simply use paths[][].responses because of path parameters list and some x-tension not containing a responses property, hence the two select. Without select(type == \"object\"), we have have a Cannot index array with string “responses” error because the path parameters list. And without select(has(\"responses\"))we would have some null elements in out final list.Once we get, at last, to the responses we keep only the one not having already a 500 property using select, has and not.The following listing shows the result of this filters combination:  jq &#39;.paths[][] | select(type==&quot;object&quot;) | select(has(&quot;responses&quot;)) | .responses | select(has(&quot;500&quot;) | not) &#39; demo-api-openapi.json                    Selecting responses list without 500 command line                                                                  [apihandyman.io]$ jq &#39;.paths[][] | select(type==&quot;object&quot;) | select(has(&quot;responses&quot;)) | .responses | select(has(&quot;500&quot;) | not) &#39; demo-api-openapi.json ...{  &quot;200&quot;: {    &quot;description&quot;: &quot;The money transfer has been update&quot;  }}{  &quot;204&quot;: {    &quot;description&quot;: &quot;The money transfer has been deleted&quot;  },  &quot;404&quot;: {    &quot;description&quot;: &quot;The money transfer does not exist&quot;  }}  Now that we are able to list the elements to fix, let’s put these filters on the left side of += and put the missing data on the right as we have just learned :                    add-missing-500.jq                                                                            # First we select the elements to modify(  .paths[][] |  select(type == \"object\") |  select(has(\"responses\")) |   .responses |  select(has(\"500\") | not))# Then each of them is modified += {  \"500\":{    description: \"Unexpected error\",    content: {      \"application/json\": {        schema: {          \"$ref\": \"#components/schemas/ProviderError\"        }      }    }  }}# The fully modified document is returned  As shown in the two following listings, the get /accounts operation does not have a 500 but it is hopefully easily fixed by applying add-missing-500.jq on the file. Note that all other operations lacking a 500 are also fixed as the new 500 property is added to each element identified by the filters on the left side of +=.  jq &#39;.paths[&quot;/accounts&quot;].get.responses&#39; demo-api-openapi.json                     Before                                                                  [apihandyman.io]$ jq &#39;.paths[&quot;/accounts&quot;].get.responses&#39; demo-api-openapi.json {  &quot;200&quot;: {    &quot;description&quot;: &quot;User&#39;s accounts&quot;,    &quot;content&quot;: {      &quot;application/json&quot;: {        &quot;schema&quot;: {          &quot;required&quot;: [            &quot;properties&quot;          ],          &quot;properties&quot;: {            &quot;items&quot;: {              &quot;type&quot;: &quot;array&quot;,              &quot;items&quot;: {                &quot;$ref&quot;: &quot;#/components/schemas/Account&quot;              }            }          }        }      }    }  }}    jq -f add-missing-500.jq demo-api-openapi.json | jq &#39;.paths[&quot;/accounts&quot;].get.responses&#39;                    After                                                                  [apihandyman.io]$ jq -f add-missing-500.jq demo-api-openapi.json | jq &#39;.paths[&quot;/accounts&quot;].get.responses&#39;{  &quot;200&quot;: {    &quot;description&quot;: &quot;User&#39;s accounts&quot;,    &quot;content&quot;: {      &quot;application/json&quot;: {        &quot;schema&quot;: {          &quot;required&quot;: [            &quot;properties&quot;          ],          &quot;properties&quot;: {            &quot;items&quot;: {              &quot;type&quot;: &quot;array&quot;,              &quot;items&quot;: {                &quot;$ref&quot;: &quot;#/components/schemas/Account&quot;              }            }          }        }      }    }  },  &quot;500&quot;: {    &quot;description&quot;: &quot;Unexpected error&quot;,    &quot;content&quot;: {      &quot;application/json&quot;: {        &quot;schema&quot;: {          &quot;$ref&quot;: &quot;#components/schemas/ProviderError&quot;        }      }    }  }}  Adding missing response content when needed with |= and complex update filterIn the demo-api-openapi.json file some operations may have basic 401 and 403 responses but without any schema (missing content property). Let’s fix that with a jq module inpired by previous one but using |= with a more complex filters on the left and accepting a regex HTTP status code and a schema model name.                                                The following jq module is composed of a |= main statement. On its left side, it selects all responses list. On its right side, it works on each key/value of all responses list using with_entry. If the key (HTTP status code) matches the regex ($coderegex) provided as a command line argument and does not already contain a content property, it add a content to the value. If not, it leaves the value as is is by returning ..                    add-missing-response-content.jq                                                                            # Selecting all responses list(   .paths[][] |  select(type == \"object\") |  select(has(\"responses\")) |   .responses) |= # Updating selected values  with_entries( # transforms key: value into { key: key, value: value}  # $coderegex is provided with --arg coderegex 40.  if (.key | test($coderegex)) and (.value | has(\"content\") | not) then    .value += { # Actually updating the value      content: {        \"application/json\": {          schema: { # $schema is provided with --arg schema ConsumerError             \"$ref\": (\"#/components/schemas/\" + $schema)          }        }      }  }  else    . # unmodified element  end)  Here’s the responses list of post /beneficiaries before modification:  jq &#39;.paths[&quot;/beneficiaries&quot;].post.responses&#39; demo-api-openapi.json                     Before                                                                  [apihandyman.io]$ jq &#39;.paths[&quot;/beneficiaries&quot;].post.responses&#39; demo-api-openapi.json {  &quot;201&quot;: {    &quot;description&quot;: &quot;Beneficiary added&quot;  },  &quot;401&quot;: {    &quot;description&quot;: &quot;Unauthorized&quot;  },  &quot;403&quot;: {    &quot;description&quot;: &quot;Forbidden&quot;  }}  Once add-missing-response-content.jq is applied on the OpenAPI file, the responses matching the 40. regex (coderegex command line argument) have been modified to add a content with application/json media type referencing the schema provided with schema command line argument. And as seen previously that has been done to all operations responses.  jq --arg coderegex 40. --arg schema ConsumerError -f add-missing-response-content.jq demo-api-openapi.json | jq &#39;.paths[&quot;/beneficiaries&quot;].post.responses&#39;                    Before                                                                  [apihandyman.io]$ jq --arg coderegex 40. --arg schema ConsumerError -f add-missing-response-content.jq demo-api-openapi.json | jq &#39;.paths[&quot;/beneficiaries&quot;].post.responses&#39;{  &quot;201&quot;: {    &quot;description&quot;: &quot;Beneficiary added&quot;  },  &quot;401&quot;: {    &quot;description&quot;: &quot;Unauthorized&quot;,    &quot;content&quot;: {      &quot;application/json&quot;: {        &quot;schema&quot;: {          &quot;$ref&quot;: &quot;#/components/schemas/ConsumerError&quot;        }      }    }  },  &quot;403&quot;: {    &quot;description&quot;: &quot;Forbidden&quot;,    &quot;content&quot;: {      &quot;application/json&quot;: {        &quot;schema&quot;: {          &quot;$ref&quot;: &quot;#/components/schemas/ConsumerError&quot;        }      }    }  }}  Note that the selection of elements to modify with $coderegex could be fully made on right side (you could try to modify the module to do so).Deleting elementsLast but not least, deleting elements. We’ll learn to use the following jq operators and function:              JQ Operators and Functions                    .info.description = \"New description.\".info.description = .info.contact.name      Replaces a value, the input to the right-hand-side (rhs) is the same as the input to the left-hand-side (lhs) rather than the value at the lhs path                    .info.contact |= .name.info.version |= sub(\"-snapshot\";\"\")      Replaces a value, it takes a filter on the right-hand side and works out the new value for the property of `.` being assigned to by running the old value through this expression                    .info.contact |= del(.contact)del(.info.contact)      Removes a key and its corresponding value from an object                    walk(f)      Applies a filter recursively to every component of the input entity                    delpaths(PATHS)      Deletes an array of paths. each path is an array of string and numbers.            This section’s content is also available as an asciinema bash session:                    Deleting elements                                                          Dumbly deleting contact with = or |=If we want to get rid of the contact property in info, we can do a replacement using = or a more clever |= as we have seen before. The idea is to keep all other properties (title, version, and description). Note how the |= syntax is simpler.  jq &#39;.info&#39; demo-api-openapi.jsonjq &#39;.info = { info: .info.title, version: .info.version, description: .info.description }&#39; demo-api-openapi.json | jq &#39;.info&#39;jq &#39;.info |= { title, version, description }&#39; demo-api-openapi.json | jq &#39;.info&#39;                    Keeping title, version and description to delete contact                                                                  [apihandyman.io]$ jq &#39;.info&#39; demo-api-openapi.json{  &quot;title&quot;: &quot;Banking API&quot;,  &quot;version&quot;: &quot;1.0.0-snapshot&quot;,  &quot;description&quot;: &quot;The Banking API provides access ...&quot;,  &quot;contact&quot;: {    &quot;name&quot;: &quot;The Banking API team&quot;,    &quot;email&quot;: &quot;api@bankingcompany.com&quot;,    &quot;url&quot;: &quot;developer.bankingcompany.com&quot;  }}[apihandyman.io]$ jq &#39;.info = { info: .info.title, version: .info.version, description: .info.description }&#39; demo-api-openapi.json | jq &#39;.info&#39;{  &quot;info&quot;: &quot;Banking API&quot;,  &quot;version&quot;: &quot;1.0.0-snapshot&quot;,  &quot;description&quot;: &quot;The Banking API provides access ...&quot;}[apihandyman.io]$ jq &#39;.info |= { title, version, description }&#39; demo-api-openapi.json | jq &#39;.info&#39;{  &quot;info&quot;: &quot;Banking API&quot;,  &quot;version&quot;: &quot;1.0.0-snapshot&quot;,  &quot;description&quot;: &quot;The Banking API provides access ...&quot;}  Efficiently deleting contact with delThat works because there’s not too many properties to keep inside info. But if you work on a more complex object this could become quite boring to delete an element. Hopefully, there is a del function that can be used to actually delete an element. It can be used with |= but also alone. The del function takes a path expressions so it can be directly used on .info.contact to delete this property.  jq &#39;.info |= del(.contact)&#39; demo-api-openapi.json | jq &#39;.info&#39;jq &#39;del(.info.contact)&#39; demo-api-openapi.json | jq &#39;.info&#39;                    Actually deleting contact                                                                  [apihandyman.io]$ jq &#39;.info |= del(.contact)&#39; demo-api-openapi.json | jq &#39;.info&#39;{  &quot;title&quot;: &quot;Banking API&quot;,  &quot;version&quot;: &quot;1.0.0-snapshot&quot;,  &quot;description&quot;: &quot;The Banking API provides access ...&quot;}[apihandyman.io]$ jq &#39;del(.info.contact)&#39; demo-api-openapi.json | jq &#39;.info&#39;{  &quot;title&quot;: &quot;Banking API&quot;,  &quot;version&quot;: &quot;1.0.0-snapshot&quot;,  &quot;description&quot;: &quot;The Banking API provides access ...&quot;}  deleting deprecated operations or properties with walk and delThe OpenAPI 3 specification allows to tell that some operations ans even properties are deprecated by adding a deprecated: true. It can be useful to be able to delete all those deprecated elements.That can be done quite easily with walk and del functions.              JQ Functions                    .info.contact |= del(.contact)del(.info.contact)      Removes a key and its corresponding value from an object                    walk(f)      Applies a filter recursively to every component of the input entity            The walk function is very useful, it will basically walk through all nodes inside the provided document and apply the filters provided as parameter. The following jq module is split in 3 steps and uses walk on each of them:  First we delete all object values having a deprecated property set to true  Then we delete the keys having a null value created by first step  And eventually, we delete all keys whose value became an empty object because of second step                    delete-deprecated.jq                                                                            # Removes all object having a deprecated property set to true# Before: \"objectProperty\": { \"deprecated\": true }# After: \"objectProperty\": nullwalk(  if type==\"object\" and .deprecated == true then     del(.)   else     .   end) | # Removes all property set to null (\"nullProperty\": null) created # when deleted objects containing deprecated set to truewalk(  if type==\"object\" then     with_entries(       select( .value != null)    )   else  # Not an object, just keep it    .  end) |# Removes all empty property (\"emptyProperty\": {}) that may have# been created when removing the null oneswalk(  if type==\"object\" then     with_entries(      select(.value != {} )    )  else # Not an object, just keep it    .   end)  Here’s the module in action (note for this demonstration we focus only on deprecated operations and reuse the  search operations module from part 2):  jq -r --arg deprecated true -f search-operations.jq demo-api-openapi.jsonjq -f delete-deprecated.jq demo-api-openapi.json | jq -r -f search-operations.jq --arg deprecated true                    Deleting deprecated elements                                                                  [apihandyman.io]$ jq -r --arg deprecated true -f search-operations.jq demo-api-openapi.json[demo-api-openapi.jso]  delete  /beneficiaries/{id}     Delete a beneficiary (deprecated)[demo-api-openapi.jso]  patch   /beneficiaries/{id}     Updates a beneficiary (deprecated)[apihandyman.io]$ jq -f delete-deprecated.jq demo-api-openapi.json | jq -r -f search-operations.jq --arg deprecated true  Deleting x-tensions with paths and delpathsAnother simple way of deleting elements is to use paths and delpaths, we can use them to remove all x-tensions (custom properties starting whose names start with x-) from an OpenAPI file.              JQ Functions                    paths      Lists all possible paths in documents, each path is represented as an array                    delpaths(PATHS)      Deletes an array of paths. each path is an array of string and numbers.            First we list all paths to those x-tensions. The paths function returns an array of all paths to all elements inside a document. Each path is an array, for example the path to contact is [\"info\",\"contact\"] (hence paths returns an array of array). As we only want x-tensions, we filter this lists of paths to keep only the ones having their leafs prefixed by x-. Once we have this array of paths, we can use it as a parameter for delpaths and we’re done!                    delete-xtensions.jq                                                                            # Lists all available x-tensions' paths[(  paths | # Lists ALL possible paths in documents           # (each path is represented as an array)  select( # Keeps only the values for which what follows return true    .[-1] | # Gets the path leaf (last item in array)            # Equivalent to .[.|length-1]    tostring | # Converts to string for next step    test(\"^x-\") # Matches \"^x-\" regex (starts with x-)  ))] as $xtensions |# Delete all found x-tensions using their pathsdelpaths($xtensions)    jq -r -f list-xtension-paths.jq demo-api-openapi.jsonjq -f delete-xtensions.jq demo-api-openapi.json | jq -r -f list-xtension-paths.jq                    Deleting x-tensions                                                                  [apihandyman.io]$ jq -r -f list-xtension-paths.jq demo-api-openapi.json [  [    &quot;paths&quot;,    &quot;/accounts/{id}&quot;,    &quot;get&quot;,    &quot;x-implementation&quot;  ],  ...][apihandyman.io]$ jq -f delete-xtensions.jq demo-api-openapi.json | jq -r -f list-xtension-paths.jq []  Deleting unsused schemas with delpathsWe’re under no obligation to use paths when using delpaths, we can build the paths ourselves.              JQ Filters and Functions                    ..      Returns every value recursively                    delpaths(PATHS)      Deletes an array of paths. each path is an array of string and numbers.            The following module removes unused schemas from an OpenAPI file. Unused schemas are defined in components.schemas but never referenced in a $ref property.To build the paths list, we first create a list of all possible $ref values using the keys of components.schemas. Then we substract all actually used $ref. Note the use of ..to get all document’s nodes and unique to keep only one occurrence of each used $ref. Once we have a list of #/components/schemas/name strings, we transform them in paths by splitting on / and removing #. And eventually we use delpaths on the resulting array of paths. Note that delpaths accept a parameter which is not strictly an array of array, indeed the unsused schema paths list is only a succession of individual arrays not enclosed inside an array.                    delete-unused-schemas.jq                                                                            (  # Defined schemas  (    .components.schemas | # select reusable schemas structure    keys | # keeps only the schema names    map(\"#/components/schemas/\" + .) # return an array with schema refs  )  # Minus operator to substract used schemas from defined schemas  -  # Actually used schemas  ([ # Creating an array    .. | # selects all nodes    select(type==\"object\") | # keeps only object    select(has(\"$ref\")) | # keeps only object having $ref property    .[\"$ref\"] # the $ref property (.$ref connot be used because of $)   ] | unique) # Keeps only one occurence  |  map(split(\"/\") - [\"#\"])) as $unused |delpaths($unused)    jq -r -f list-unused-schemas.jq demo-api-openapi.jsonjq -f delete-unused-schemas.jq demo-api-openapi.json | jq -r -f list-unused-schemas.jq                    Deleting unused schemas                                                                  [apihandyman.io]$ jq -r -f list-unused-schemas.jq demo-api-openapi.json [  &quot;components&quot;,  &quot;schemas&quot;,  &quot;ProviderError&quot;][  &quot;components&quot;,  &quot;schemas&quot;,  &quot;UselessSchema&quot;][apihandyman.io]$ jq -f delete-unused-schemas.jq demo-api-openapi.json | jq -r -f list-unused-schemas.jq  SummaryAnd we’re done with part 3, you should now be able to modify any OpenAPI or any JSON file as you like using the following operators and functions:              JQ Filters, Operators and Functions                    .info.description = \"New description.\".info.description = .info.contact.name      Replaces a value, the input to the right-hand-side (rhs) is the same as the input to the left-hand-side (lhs) rather than the value at the lhs path                    .info.contact |= .name.info.version |= sub(\"-snapshot\";\"\")      Replaces a value, it takes a filter on the right-hand side and works out the new value for the property of `.` being assigned to by running the old value through this expression                    .info.description += \"More description\".info.description += .info.contact.name      Increments a number value, concatenates string or add properties to object                    .info.contact |= del(.contact)del(.info.contact)      Removes a key and its corresponding value from an object                    walk(f)      Applies a filter recursively to every component of the input entity                    paths      Lists all possible paths in documents, each path is represented as an array                    ..      Returns every value recursively                    delpaths(PATHS)      Deletes an array of paths. each path is an array of string and numbers.            What’s nextWith what you have learned in the first 3 parts, you should be able to achieve anything you want with jq. And known that we only scratched the surface, check jq’s documentation to discover all of its features. The next and final part is a little bonus in which you’ll learn to colorize jq terminal output just for fun."
},{
    "id": "46",
    "type": "post",
    "title": "JQ and OpenAPI Series - Part 2 - Using JQ command line arguments, functions and modules",
    "url": "https://apihandyman.io/api-toolbox-jq-and-openapi-part-2-using-jq-command-line-arguments-functions-and-modules/",
    "banner": "https://apihandyman.io/images/api-toolbox-jq-and-openapi-part-2-using-jq-command-line-arguments-functions-and-modules/banner.png",
    "description": "Ever wanted to quickly find, extract or modify data coming from some JSON documents on the command line? JQ is the tool you’re looking for. In the previous part of this JQ and OpenAPI Series, we learned to invoke JQ and how to extract data from JSON documents using some of its many filters. Now we will discover how to build flexible and easily reusable JQ filters by creating functions and modules and also using command line arguments.",
    "body": "Ever wanted to quickly find, extract or modify data coming from some JSON documents on the command line? JQ is the tool you’re looking for. In the previous part of this JQ and OpenAPI Series, we learned to invoke JQ and how to extract data from JSON documents using some of its many filters. Now we will discover how to build flexible and easily reusable JQ filters by creating functions and modules and also using command line arguments. We will continue working on OpenAPI files, at the end of this second part, we’ll have built a multi-criteria OpenAPI search and some reusable filters, especially one that you’ll be able to reuse anytime you’ll have to deal with JQ command line parameters.      JQ and OpenAPI Series                      JQ’s documentation is quite complete and there are many tutorials and Stackoverflow answers, so why bother writing this series? First reason, I regularly meet people working with APIs and/or JSON files who actually don’t know JQ exists and how it could save their life (or at least their time). Second reason, I often use it with OpenAPI specification files and I found that showing how JQ can be used on such a widely adopted and familiar JSON based format could help to learn how to use it (and also writing this post actually helped me to improve my JQ skills!).                                                      1 - Using JQ to extract data from OpenAPI files                                      2 - Using JQ command line arguments, functions and modules                                      3 - Modifying OpenAPI files with JQ                                      4 - Bonus: Coloring JQ's raw output                                                                                                                  Get post’s contentAll examples shown in this post are based on JQ 1.6 and OpenAPI 3. All examples can be copied using the  button and downloaded using the  one on code snippets. All source code can be retrieved from the JQ and OpenAPI post series’ github repository.  git clone https://github.com/arno-di-loreto/jq-and-openapi/cd jq-and-openapigit checkout part-2                                                                                      [apihandyman.io]$ git clone https://github.com/arno-di-loreto/jq-and-openapi/[apihandyman.io]$ cd jq-and-openapi[apihandyman.io]$ git checkout part-2  Listing operations using functions and modulesIn previous post, we built a filter that lists the operations available in an OpenAPI file. In this first section, we will just refactor the JQ code to make it more readable and reusable using functions and modules. The following listing shows what happens when using the new version of list-operations.jq on the demo OpenAPI file.  jq -r -f list-operations.jq demo-api-openapi.json                    Same result as in part 1 but list-operations.jq has changed under the hood                                                                  [apihandyman.io]$ jq -r -f list-operations.jq demo-api-openapi.jsonget     /accounts       List accountsget     /accounts/{id}  Get an accountpost    /beneficiaries  Register a beneficiaryget     /beneficiaries  List beneficiariesdelete  /beneficiaries/{id}     Delete a beneficiary (deprecated)patch   /beneficiaries/{id}     Updates a beneficiary (deprecated)get     /beneficiaries/{id}     Get a beneficiaryget     /sources        List transfer sourcesget     /sources/{id}/destinations      List transfer source&#39;s destinationspost    /transfers      Transfer moneyget     /transfers      List money transfersget     /transfers/{id} Get a money transferpatch   /transfers/{id}delete  /transfers/{id} Cancel a money transfer  It seems nothing has changed, it still outputs operations HTTP methods, paths and summaries, but under the hood, the JQ file used has changed as shown in the following listing.                    list-operations.jq                                                                            include \"module-openapi\"; # Imports module-openapi.jq fileoas_operations | # Function coming from module-openapi.jq fileoas_operations_to_text  # Function coming from module-openapi.jq file  Let’s see how it was created, we’ll discover functions and then modules.Creating functionsAs a reminder, here’ the previous version of the list-operations.jq file we created in previous part. It is composed of three steps. Steps 1 and 2 build an array of operation object containing a (HTTP) method, path, summary and deprecated indicator. Step 3 aims to print this array as tab separated text.                    list-operations-original.jq                                                                            # 1 - Selects paths objects#--------------------------# returns [{key: path, value: path value}].paths # Selects the paths property content| to_entries # Transforms             # { \"/resources\": { \"get\": {operation data}}}              # to              # [ { \"key\": \"/resources\",              #     \"value\": { \"get\": {operation data}} ]| map(select(.key | test(\"^x-\") | not)) # Gets rid of x-tensions# 2 - Creates an array of operations#-----------------------------------# returns [{path, method, summary, deprecated}]| map ( # Applies a transformation to each element  .key as $path # Stores the path value (.key)                   # in a variable ($path) for later use  | .value # Keeps only the path's content            # { \"get\": {operation data}}  | to_entries # Transforms                # { \"get\": {operation data}}               # to               # [ { \"key\": \"get\",                #     \"value\": {operation data}} ]  | map( # Applies a transformation to each element    select( # Keeps only elements for which the following is true      # With IN, which returns true if the value is one of its      # parameters, we can get rid of x- , parameters      # description and summary properties      .key | IN(\"get\", \"put\", \"post\", \"delete\",          \"options\", \"head\", \"patch\", \"trace\")    )    | # Creates a new JSON object    {      method: .key,      path: $path, # Using the variable defined on line 4      summary: .value.summary?,      deprecated: .value.deprecated?    }  )[] # Flattens array to avoid having an array       # of array of {path, method, summary, deprecated}) # Now we have an array of {path, method, summary, deprecated}# 3 - Outputs tab separated raw text#-----------------------------------| map( # Applies a transformation to each element  .method + \"\\t\" +   .path + \"\\t\" +   .summary +   (if .deprecated then \" (deprecated)\" else \"\" end))[] # Flattens array for raw output  Let’s focus on step 3, which is shown below, and build a function that does the same job.                    We will create a function for step 3                                                                            # 3 - Outputs tab separated raw text#-----------------------------------| map( # Applies a transformation to each element  .method + \"\\t\" +   .path + \"\\t\" +   .summary +   (if .deprecated then \" (deprecated)\" else \"\" end))[] # Flattens array for raw output  Defining a function in JQ is quite simple: at the beginning of the file, add a def function_name: put some filters and end by ; and you’re done. The oas_operation_to_text which basically contains step 3’s filters is shown below.                    Defining the oas_operation_to_text function                                                                            def oas_operations_to_text: # Defining a function that                            # Prints operations as raw text  map( # Applies a transformation to each element    .method + \"\\t\" +     .path + \"\\t\" +     .summary +     (if .deprecated then \" (deprecated)\" else \"\" end)  )  [] # Flattens array for raw output; # oas_operations_to_text function's end  If defining a function in JQ is quite simple, using it is even more simple. Just call it like any regular JQ filter. The following listing shows how step 3’s code has been replaced by the new oas_operation_to_text custom filter which is on top of the file.                    Using the oas_operation_to_text function                                                                            # 3 - Outputs tab separated raw text#-----------------------------------| oas_operations_to_text  Here’s the full modified list-operations.jq file including the oas_operation_to_text definition at the beginning and its calling on the last line.                    list-operations-with-to-text-function.jq                                                                            def oas_operations_to_text: # Defining a function that                            # Prints operations as raw text  map( # Applies a transformation to each element    .method + \"\\t\" +     .path + \"\\t\" +     .summary +     (if .deprecated then \" (deprecated)\" else \"\" end)  )  [] # Flattens array for raw output; # oas_operations_to_text function's end# 1 - Selects paths objects#--------------------------# returns [{key: path, value: path value}].paths # Selects the paths property content| to_entries # Transforms             # { \"/resources\": { \"get\": {operation data}}}              # to              # [ { \"key\": \"/resources\",              #     \"value\": { \"get\": {operation data}} ]| map(select(.key | test(\"^x-\") | not)) # Gets rid of x-tensions# 2 - Creates an array of operations#-----------------------------------# returns [{path, method, summary, deprecated}]| map ( # Applies a transformation to each element  .key as $path # Stores the path value (.key)                   # in a variable ($path) for later use  | .value # Keeps only the path's content            # { \"get\": {operation data}}  | to_entries # Transforms                # { \"get\": {operation data}}               # to               # [ { \"key\": \"get\",                #     \"value\": {operation data}} ]  | map( # Applies a transformation to each element    select( # Keeps only elements for which the following is true      # With IN, which returns true if the value is one of its      # parameters, we can get rid of x- , parameters      # description and summary properties      .key | IN(\"get\", \"put\", \"post\", \"delete\",          \"options\", \"head\", \"patch\", \"trace\")    )    | # Creates a new JSON object    {      method: .key,      path: $path, # Using the variable defined on line 4      summary: .value.summary?,      deprecated: .value.deprecated?    }  )[] # Flattens array to avoid having an array       # of array of {path, method, summary, deprecated}) # Now we have an array of {path, method, summary, deprecated}# 3 - Outputs tab separated raw text#-----------------------------------| oas_operations_to_text  That’s great, using functions big JQ filters are far more readable. But what about being able to reuse these functions?Creating a module with reusable functionsCreating JQ modules that define reusable functions is, again, quite simple. Just put some functions in a JQ file and you’re done. The following listing shows a module-openapi.jq module file defining two functions. There’s the oas_operation_to_text we have just created and also an oas_operations which do the same as steps 1 and 2 of the list-operations.jq file (returning an array of operations). Note that there’s a light modification (line 43/44), this function returns also the input_filename and the original value of each operations (for a later use) besides its HTTP method, path, summary and deprecated flag.                    module-openapi.jq                                                                            # This is a reusable JQ module defining useful# OpenAPI specification (OAS) processing functionsdef oas_operations: # Defining a listoperations function                    # returning {path, method, summary, original}  # 1 - Selects paths objects  #--------------------------  # returns [{key: path, value: path value}]  .paths # Selects the paths property content  | to_entries # Transforms              # { \"/resources\": { \"get\": {operation data}}}               # to               # [ { \"key\": \"/resources\",               #     \"value\": { \"get\": {operation data}} ]  | map(select(.key | test(\"^x-\") | not)) # Gets rid of x-tensions  # 2 - Creates an array of operations  #-----------------------------------  # returns [{path, method, summary, deprecated}]  | map ( # Applies a transformation to each element    .key as $path # Stores the path value (.key)                     # in a variable ($path) for later use    | .value # Keeps only the path's content             # { \"get\": {operation data}}    | to_entries # Transforms                 # { \"get\": {operation data}}                # to                # [ { \"key\": \"get\",                 #     \"value\": {operation data}} ]    | map( # Applies a transformation to each element      select( # Keeps only elements for which the following is true        # With IN, which returns true if the value is one of its        # parameters, we can get rid of x- , parameters        # description and summary properties        .key | IN(\"get\", \"put\", \"post\", \"delete\",           \"options\", \"head\", \"patch\", \"trace\")      )      | # Creates a new JSON object      {        method: .key,        path: $path, # Using the variable defined on line 4        summary: .value.summary?,        deprecated: .value.deprecated?,        original: .value, # Keeping original value, just in case 😉        source: input_filename # Adding source file, also just in case 😉      }    )[] # Flattens array to avoid having an array         # of array of {path, method, summary, deprecated}  ) # Now we have an array of {path, method, summary, deprecated}; # oas_operations function's enddef oas_operations_to_text: # Defining a function that                            # Prints operations as raw text  map( # Applies a transformation to each element    .method + \"\\t\" +     .path + \"\\t\" +     .summary +     (if .deprecated then \" (deprecated)\" else \"\" end)  )  [] # Flattens array for raw output; # oas_operations_to_text function's end  Let’s get back to the new version of list-operations.jq (shown below) to see how this module is actually used. The module is include with the include &lt;module name without extension&gt;; line. Then any functions defined in it can be used like any other regular JQ filter as shown on line 3 and 4 where oas_operations and oas_operations_to_text are used.                    list-operations.jq                                                                            include \"module-openapi\"; # Imports module-openapi.jq fileoas_operations | # Function coming from module-openapi.jq fileoas_operations_to_text  # Function coming from module-openapi.jq file  Managing modules locations                    Managing JQ modules location                                                          The following listings shows different ways of managing reusable modules location with JQ (see modules in the JQ’s documentation for a complete description of what can be done).It starts by a a first command done inside the jq-and-openapi folder.It simply returns the first operation’s summary of the demo-api-openapi.json file using the oas_operations[0] filter composed of the oas_operations function and the [] array filter.As you can see, there’s no need to create a JQ file to use a module, just use the include directive in the '&lt;filter&gt;' argument on the command line.Then we go a level up, and obviously redoing the same exact command does not work anymore: the module-openapi.jq cannot be found in the current folder as it is in the jq-and-openapi one.Hopefully, you can use the -L &lt;path list&gt; argument to tell JQ where to look for modules.  jq -r &#39;include &quot;module-openapi&quot;; oas_operations[0].summary&#39; demo-api-openapi.jsoncd ..jq -r &#39;include &quot;module-openapi&quot;; oas_operations[0].summary&#39; jq-and-openapi/demo-api-openapi.jsonjq -r -L jq-and-openapi &#39;include &quot;module-openapi&quot;; oas_operations[0].summary&#39; jq-and-openapi/demo-api-openapi.json                    Indicating where to find modules with -L argument                                                                  [apihandyman.io]$ jq -r &#39;include &quot;module-openapi&quot;; oas_operations[0].summary&#39; demo-api-openapi.jsonList accounts[apihandyman.io]$ cd ..[apihandyman.io]$ jq -r &#39;include &quot;module-openapi&quot;; oas_operations[0].summary&#39; jq-and-openapi/demo-api-openapi.jsonjq: error: module not found: module-openapijq: 1 compile error[apihandyman.io]$ jq -r -L jq-and-openapi &#39;include &quot;module-openapi&quot;; oas_operations[0].summary&#39; jq-and-openapi/demo-api-openapi.jsonList accounts  If there are modules that you use extensively, it would be interesting to put them in a ~/.jq folder. Therefore, no longer need for the -L argument as shown below. JQ looks for the modules mentioned in include directives in this folder automatically.  mkdir ~/.jqcp jq-and-openapi/module-openapi.jq ~/.jqjq -r &#39;include &quot;module-openapi&quot;; oas_operations[0].summary&#39; jq-and-openapi/demo-api-openapi.json                    Using ~/.jq default folder to store modules                                                                  [apihandyman.io]$ mkdir ~/.jq[apihandyman.io]$ cp jq-and-openapi/module-openapi.jq ~/.jq[apihandyman.io]$ jq -r &#39;include &quot;module-openapi&quot;; oas_operations[0].summary&#39; jq-and-openapi/demo-api-openapi.jsonList accounts  Note that ~/.jq can also be a file. In that case, you don’t even need to include anything, as shown below. Any function defined in this file is usable inside any of your filters. I personally do not recommend to do this because that makes your filters dependencies invisible (and can also result in a quite huge unmaintainable .jq file).  rm -rf ~/.jqcp jq-and-openapi/module-openapi.jq ~/.jqjq -r &#39;oas_operations[0].summary&#39; jq-and-openapi/demo-api-openapi.json                    Using ~/.jq default file to store functions                                                                  [apihandyman.io]$ rm -rf ~/.jq[apihandyman.io]$ cp jq-and-openapi/module-openapi.jq ~/.jq[apihandyman.io]$ jq -r &#39;oas_operations[0].summary&#39; jq-and-openapi/demo-api-openapi.jsonList accounts  Searching operations using command line argumentsNow that we have a reusable module that provides functions to list operations of an OpenAPI specification file and print them as tab separated text, let’s work on a multiple-criteria and multiple-file search.Passing an argument to JQ filtersIn order to make this search flexible, we’ll need to be able to accept search arguments coming from outside our filter in order to avoid having to modify it on each different search. Passing arguments to JQ is done with --arg &lt;name&gt; &lt;value&gt; as shown below. Inside the filter, you can access a --arg with $&lt;name&gt;. In this case $foo returns bar. Note also in this example the -n flag which is used to tell JQ to not expect any JSON input. That’s pretty useful to make demos of some JQ’s features but also to generate JSON from scratched based on some arguments values.  jq -n --arg foo bar &#39;{foo: $foo}&#39;                    Passing an argument with --arg (and discovering -n flag)                                                                  [apihandyman.io]$ jq -n --arg foo bar &#39;{foo: $foo}&#39;{  &quot;foo&quot;: &quot;bar&quot;}  Searching operations accessible for a scopeThe following listing shows which operations are accessible to a consumer when it is given the transfer:admin security scope. The scope value is provided to the filter using --arg &lt;name&gt; &lt;value&gt;.  jq -r --arg scope transfer:admin -f search-operations-using-scope.jq demo-api-openapi.json                     Searching operations using a given scope                                                                  [apihandyman.io]$ jq -r --arg scope transfer:admin -f search-operations-using-scope.jq demo-api-openapi.json post    /transfers      Transfer moneyget     /transfers      List money transfersget     /transfers/{id} Get a money transferdelete  /transfers/{id} Cancel a money transfer  In an OpenAPI file, you’ll find the scopes that will grant access to an operation in its security property under a {name}.According the OpenAPI Specification, each name MUST correspond to a security scheme which is declared in the Security Schemes under the Components Object. If the security scheme is of type “oauth2” or “openIdConnect”, then the value is a list of scope names required for the execution. For other security scheme types, the array MUST be empty.                                                For our use case, we just need to list all values (scopes) under all security.{name} of each operation and keep the operations for which the provided scope is found in this list. The following listing shows how this is achieved in the search-operations-using-scope.jq.  First (line 4), it lists existing operations using the oas_operations function (coming from module-openapi included on line 1)  Then (line 5), it filters the returned operations based on their scopes by working on each of the original operation’s data coming from the OpenAPI file. To do so:          It first checks if there’s a security property (line 7)      Then creates a list of scopes (line 9 and 10)      And (line 11 to 14), if the index of $scope (provided through the --arg scope &lt;value&gt;) is greater than 0 (meaning it is in the list), the operation is returned        And finally (line 19), it prints the remaining operations as tab separated values using the oas_operations_to_text function (coming from module-openapi included on line 1)                    search-operations-using-scope.jq                                                                            include \"module-openapi\"; # Looks for a module-openapi.jq file# Expects a --arg scope value parameteroas_operations # Comes from module-operations.jq| map(select( # Filters on operation scopes    # security is not always present    if .original.security? != null then      # Creating an array containg all scopes      [ .original.security |         map(to_entries | map(.value)[])[][] ] |       index( # Index returns the index of a value in array        $scope # $scope value is provided on the command line              # --arg scope value      ) &#62;= 0 # If &#60; 0, it has not been found    else      false # No security defined, so return false    end  ))| oas_operations_to_text  # Comes from module-operations.jq  That’s cool, but there’s a little problem. When using the search-operations-using-scope.jq without providing the scope value, it does not work: JQ complains that $scope is not defined, as shown below.  jq -r -f search-operations-using-scope.jq demo-api-openapi.json                    What happens when scope is not provided                                                                  [apihandyman.io]$ jq -r -f search-operations-using-scope.jq demo-api-openapi.jsonjq: error: $scope is not defined at &lt;top-level&gt;, line 12:        $scope # $scope value is provided on the command line        jq: 1 compile error  Does that mean we can’t do a multi-criteria search because it requires to be able to provide multiple optional parameters? Of course not, that problem can be solved.Solving the command line argument “problem”                    Solving the command line argument problem                                                          The following listing shows how to safely access a command line named argument using the $ARGS.named filter. If $name causes an error if no --arg name value is provided on the command line, $ARGS.named['name'] will return null without causing any.  jq -n --arg foo hello --arg bar world &#39;{foo: $foo, bar: $bar}&#39;jq -n --arg foo hello &#39;{foo: $foo, bar: $bar}&#39;jq -n --arg foo hello &#39;{foo: $ARGS.named[&quot;foo&quot;], bar: $ARGS.named[&quot;bar&quot;]}&#39;                    Using $ARGS.named                                                                  [apihandyman.io]$ jq -n --arg foo hello --arg bar world &#39;{foo: $foo, bar: $bar}&#39;{  &quot;foo&quot;: &quot;hello&quot;,  &quot;bar&quot;: &quot;world&quot;}[apihandyman.io]$ jq -n --arg foo hello &#39;{foo: $foo, bar: $bar}&#39;jq: error: $bar is not defined at &lt;top-level&gt;, line 1:{foo: $foo, bar: $bar}                 jq: 1 compile error[apihandyman.io]$ jq -n --arg foo hello &#39;{foo: $ARGS.named[&quot;foo&quot;], bar: $ARGS.named[&quot;bar&quot;]}&#39;{  &quot;foo&quot;: &quot;hello&quot;,  &quot;bar&quot;: null}  That’s very handy, but what if I want to set an argument to a default value if it is not provided? I just need to use the following module-args module. It defines a init_parameter(default_values) function returning an object containing parameters set to the value coming from --arg &lt;name&gt; or a default value it is not provided. To do so, for each entry (key/value) of a default_values object parameter, it checks if the named arguments ($ARGS.named) contains the key and if so, sets the output value to the one provided on the command line. If not, it keeps the default one. By the way, that means that JQ functions can also use parameters besides their regular input. But note that you don’t need to prefix their name by $ to access them.                    module-args.jq                                                                            # Initializes parameters based on provided named arguments (--arg).# If an argument is not provided, its default value is used.# default_values example:# {#   argument: \"default value\",#   anotherArgument: null,# }def init_parameters(default_values):  default_values |   # Updates values for provided parameters  with_entries(    # $ARGS contains all --arg parameters    if $ARGS.named[.key] != null then       .value = $ARGS.named[.key]     else       .value = .value    end  );  The following listing shows how this function can be used. Just call the init_parameter function with an object containing the default values and put its result in a variable (here $parameter) for later use ($parameter.foo for example). Here the default value of foo is default foo and bar’s is null. Only bar is provided, so the output contains foo’s default value and bar command-line-provided value.  jq -n --arg bar &quot;bar from command line&quot; &#39;include &quot;module-args&quot;; init_parameters({foo: &quot;default foo&quot;, bar: null}) as $parameters| {foo: $parameters.foo, bar: $parameters.bar}&#39;                    Optional parameters with default values                                                                  [apihandyman.io]$ jq -n --arg bar &quot;bar from command line&quot; &#39;include &quot;module-args&quot;; init_parameters({foo: &quot;default foo&quot;, bar: null}) as $parameters| {foo: $parameters.foo, bar: $parameters.bar}&#39;{  &quot;foo&quot;: &quot;default foo&quot;,  &quot;bar&quot;: &quot;bar from command line&quot;}  Searching operations on multiple criteria and multiple files                    Searching operations demo                                                          Now that we know how to provide multiple optional parameters, let’s do a multi-criteria search. The following listing shows the get operations on paths containing sources across all available *.json files. The first value on each line is the filename (limited to 20 characters).  jq --arg path_contains sources --arg method get -r -f search-operations.jq *.json                    Operations on path containing source with method get                                                                  [apihandyman.io]$ jq --arg path_contains sources --arg method get -r -f search-operations.jq *.json[demo-another-api-swa]  get     /resources[demo-api-openapi.jso]  get     /sources        List transfer sources[demo-api-openapi.jso]  get     /sources/{id}/destinations      List transfer source&#39;s destinations  Here’s the search-operations.jq file who does that. It reuses functions we have seen before, oas_operations from the module_openapi.jq file and init_parameters from the module-args.jq file. It also uses new functions filter_operations, default_filters, print_oas_operations and default_print_parameters from module-openapi-search.jq. There are 3 steps: getting operations data, filtering them and finally printing them. There’s nothing new on the first step, we already have used this function. Let’s see what is happening on the second and after that the third step.                    search-operations.jq                                                                            include \"module-openapi\";include \"module-args\";include \"module-openapi-search\";# Gets operations dataoas_operations# Filters operations| filter_oas_operations(init_parameters(default_filters))# Prints operations| print_oas_operations(init_parameters(default_print_parameters).format)  The following listing shows the new functions used to filter operations. The default_filters only returns the search filters default value to be used in conjunction with init_parameters and so get cleans values from optional command line arguments. The filter_oas_operation expects a filter object whose structure is the same as the one returned by default filters. This operations runs a map(select()) on the operations list. Each filter is triggered if filters.&lt;name&gt; is not null. There’s nothing really new regarding JQ’s filters besides line 41. The filtering on paths is done using the contains filter which we hadn’t seen before.                    Filtering operations (module-openapi-search.jq)                                                                            # Available filters and their default values# To be used with init_parametersdef default_filters:{  deprecated: null,  method: null,  code: null,  scope: null,  path_contains: null};# Filters operations coming from oas_operations# Each filter is used only if corresponding filters.&#60;name&#62; parameter is provideddef filter_oas_operations(filters):  map(    select(    # Filters on deprecated    (filters.deprecated == null or       (.deprecated | tostring) == filters.deprecated) and    # Filters on HTTP method    (filters.method == null or       .method == filters.method) and    # Filters on HTTP status code    (filters.code == null or       (.original.responses | has(filters.code))) and    # Filters on security scope    (filters.scope == null or      (if .value.security? != null then        [ .value.security |           map(to_entries |           map(.value)[])[][]] |         index(filters.scope) &#62;= 0      else        false      end)    ) and    # Filters on path    (filters.path_contains == null or       (.path | contains(filters.path_contains))    )  ));  The following listing shows the new functions used to print the operations. It uses the same mechanism as the filter functions regarding the command line arguments.                    Printing operations (module-openapi-search.jq)                                                                            # Same as oas_operations_to_text but with sourcedef oas_operations_to_text_with_source:   map( # Applies a transformation to each element    \"[\" + .source[0:20] + \"]\\t\" +    .method + \"\\t\" +     .path + \"\\t\" +     .summary +     (if .deprecated then \" (deprecated)\" else \"\" end)  )  [] # Flattens array for raw output; # oas_operations_to_text function's end# To be used with init_parametersdef default_print_parameters:{  format: \"text_with_source\"  # All values:   #  text_with_source, text_without_source, json_flat or null for json};# Prints oas_operations (filtered or not) in various formatdef print_oas_operations(format):  if format == \"text_with_source\" then      oas_operations_to_text_with_source  elif format == \"text_without_source\" then      oas_operations_to_text  elif format == \"json_flat\" then    .[] # Flattening for multifiles, pipe result into a jq -s  else    .  end;  Here’s the full file:                    Filtering operations (module-openapi-search.jq)                                                                            include \"module-openapi\";# Available filters and their default values# To be used with init_parametersdef default_filters:{  deprecated: null,  method: null,  code: null,  scope: null,  path_contains: null};# Filters operations coming from oas_operations# Each filter is used only if corresponding filters.&#60;name&#62; parameter is provideddef filter_oas_operations(filters):  map(    select(    # Filters on deprecated    (filters.deprecated == null or       (.deprecated | tostring) == filters.deprecated) and    # Filters on HTTP method    (filters.method == null or       .method == filters.method) and    # Filters on HTTP status code    (filters.code == null or       (.original.responses | has(filters.code))) and    # Filters on security scope    (filters.scope == null or      (if .value.security? != null then        [ .value.security |           map(to_entries |           map(.value)[])[][]] |         index(filters.scope) &#62;= 0      else        false      end)    ) and    # Filters on path    (filters.path_contains == null or       (.path | contains(filters.path_contains))    )  ));# Same as oas_operations_to_text but with sourcedef oas_operations_to_text_with_source:   map( # Applies a transformation to each element    \"[\" + .source[0:20] + \"]\\t\" +    .method + \"\\t\" +     .path + \"\\t\" +     .summary +     (if .deprecated then \" (deprecated)\" else \"\" end)  )  [] # Flattens array for raw output; # oas_operations_to_text function's end# To be used with init_parametersdef default_print_parameters:{  format: \"text_with_source\"  # All values:   #  text_with_source, text_without_source, json_flat or null for json};# Prints oas_operations (filtered or not) in various formatdef print_oas_operations(format):  if format == \"text_with_source\" then      oas_operations_to_text_with_source  elif format == \"text_without_source\" then      oas_operations_to_text  elif format == \"json_flat\" then    .[] # Flattening for multifiles, pipe result into a jq -s  else    .  end;  SummaryThat concludes this second path of the JQ and OpenAPI series. Here’s the summary of what we have seen in this post:Functions and modules  Creating a function is done with def name: &lt;filters&gt;;  To invoke a function just use its name like for any regular filter  Functions can have parameters def name(parameter)  Inside a function a parameter can be used with parameter (without $)  A module is a JQ file containing reusable functions  A module is loaded using the include filename_without_extension directive  Use -L command line parameter to tell JQ where to find modules  Put your favorite modules in ~/.jq folder so JQ can find them without using -LCommand line arguments  Passing a named argument to JQ filters is done with --arg name value  A named argument value can be retrieved with $name  Using $name will provoke an error if no --arg name value is provided  All named arguments are available with $ARGS.named  $ARGS.named[name] returns null (wihout error) if no --arg name value is providedThe null argument  The -n (--null) arguments tells JQ to not expect input JSONNew filters              JQ Filters                    index(element)      Returns the index of an element inside an array (-1 if not found)                    contains(element)\"resources\" | contains(\"source\")      Returns true the element is in input                    $ARGS.named      Returns the command line named argument (--arg name value)            What’s nextIn next post, we’ll learn to modify OpenAPI files with JQ."
},{
    "id": "47",
    "type": "post",
    "title": "JQ and OpenAPI Series - Part 1 - Using JQ to extract data from OpenAPI files",
    "url": "https://apihandyman.io/api-toolbox-jq-and-openapi-part-1-using-jq-to-extract-data-from-openapi-files/",
    "banner": "https://apihandyman.io/images/api-toolbox-jq-and-openapi-part-1-using-jq-to-extract-data-from-openapi-files/banner.png",
    "description": "Ever wanted to quickly find, extract or modify data coming from some JSON documents on the command line? JQ is the tool you’re looking for. In this 4 parts post series, you’ll discover why and how I use JQ with OpenAPI Specification files. But more important, you’ll get some basic and more advanced example of how to use JQ on any JSON document to get and modify JSON data as you want. In this first part we’ll focus on what is JQ, why I use it with OpenAPI files and we’ll learn how to invoke JQ and discover some of the many JQ filters that can be used to extract data from JSON.",
    "body": "Ever wanted to quickly find, extract or modify data coming from some JSON documents on the command line? JQ is the tool you’re looking for. In this 4 parts post series, you’ll discover why and how I use JQ with OpenAPI Specification files. But more important, you’ll get some basic and more advanced example of how to use JQ on any JSON document to get and modify JSON data as you want. In this first part we’ll focus on what is JQ, why I use it with OpenAPI files and we’ll learn how to invoke JQ and discover some of the many JQ filters that can be used to extract data from JSON.This 4 parts post is the first one of a new API Toolbox category in which I’ll talk about the tools I use when doing API related stuff, why I use them and how. This post is also my first one using Asciinema, an awesome tool allowing to record and share terminal sessions.      JQ and OpenAPI Series                      JQ’s documentation is quite complete and there are many tutorials and Stackoverflow answers, so why bother writing this series? First reason, I regularly meet people working with APIs and/or JSON files who actually don’t know JQ exists and how it could save their life (or at least their time). Second reason, I often use it with OpenAPI specification files and I found that showing how JQ can be used on such a widely adopted and familiar JSON based format could help to learn how to use it (and also writing this post actually helped me to improve my JQ skills!).                                                      1 - Using JQ to extract data from OpenAPI files                                      2 - Using JQ command line arguments, functions and modules                                      3 - Modifying OpenAPI files with JQ                                      4 - Bonus: Coloring JQ's raw output                                                                                                                  What is JQ and why I use it (on OpenAPI files)According to JQ’s website, jq can mangle the data format that you have into the one that you want with and also jq is like sed for JSON data - you can use it to slice and filter and map and transform structured data with the same ease that sed, awk, grep and friends let you play with text.                                                I have been using JQ to transform JSON data when making API calls on the command line for quite a while, but lately I have been using it to manipulate OpenAPI Specification files. This is the use case I will focus on in this post (I’ll keep the API calls use case for another post).The OpenAPI Specification (or OAS) is a standard and programming-language agnostic REST API description format. It can be used during the design of an API to formally describe the API’s contract. It can also be used to generate documentation, generate code or to configure tools such as API gateways. An OpenAPI file can be in YAML or JSON format. If you want to learn more about this format, read What is the OpenAPI Specification. In order to have a good understanding of an OpenAPI document structure, you should check my OpenAPI Map.In my daily job I have to work with OpenAPI files when doing API design reviews. Tools such as SwaggerUI or ReDoc easily provide a user friendly view of OpenAPI files, but when it comes to have a more specific view to check various design concerns, you need to use something else. I can use JQ when I want to know  which operations can be used with a given Oauth Scope, where a reusable schema is used or checking if an API or multiples APIs are consistent.I also have to deal with OpenAPI files when working on my company’s API catalog. I had to generate API calls body to load OpenAPI files into it, I had to extract some data from them with JQ to do so. I also had to modify them to remove deprecated elements in order to avoid showing them in their documentation.The examples shown in this post are based on my regular use of JQ+OpenAPI but I expanded my original JQ scripts set with other ones in order to show more of JQ’s features.InstallationIf you want to play with JQ and OpenAPI as you read this post, you’ll need to install JQ and download this post’s related content(JQ scripts, OpenAPI demo files and Asciinema sessions and their underlying scripts).Install JQJQ is a portable command line tool that’s very easy to install. Its website states that jq is written in portable C, and it has zero runtime dependencies. You can download a single binary, scp it to a far away machine of the same type, and expect it to work (scp is a file transfer tool). This is actually true, I have tested it on Linux servers, Windows CMD terminal, Windows Gitbash (standalone and inside VS Code) and MacOS terminal: never had a problem with it.To install JQ on my personnal Macbook, I used brew install jq. On my professional Windows laptop, I simply downloaded the binary and added it to my PATH environment variable. Check JQ’s download page to see all available versions and ways to install it.Once installed, open a terminal and run jq --help to check if everything is OK.Get post’s contentAll examples shown in this post are based on JQ 1.6 and OpenAPI 3. All examples can be copied using the  button and downloaded using the  one on code snippets. All source code can be retrieved from the JQ and OpenAPI post series’ github repository.  git clone https://github.com/arno-di-loreto/jq-and-openapi/cd jq-and-openapigit checkout part-1                                                                                      [apihandyman.io]$ git clone https://github.com/arno-di-loreto/jq-and-openapi/[apihandyman.io]$ cd jq-and-openapi[apihandyman.io]$ git checkout part-1  Most of this post’s examples are run against the same OpenAPI file (demo-api-openapi.json) which is a slightly modified version of an example coming from my book The Design of Web APIs, I added a few elements here and there, convert it from YAML to JSON and uglify it.                    demo-api-openapi.json (uglyfied OpenAPI 3.0)                                                                            {\"openapi\":\"3.0.0\",\"info\":{\"title\":\"Banking API\",\"version\":\"1.0.0-snapshot\",\"description\":\"The Banking API provides access to the [Banking Company](http://www.bankingcompany.com) services, which include bank account information, beneficiaries, and money transfer management.&#60;!--more--&#62;\\n\\n# Authentication\\n\\n## How to \\n- Register\\n- Create an APP\\n- Request credentials\\n\\n# Use cases\\n\\n## Transferring money to an account or preexisting beneficiary\\n\\nThe _transfer money_ operation allows one to transfer an `amount` of money from a `source` account to a `destination` account or beneficiary.\\nIn order to use an appropriate `source` and `destination`, we recommend to use _list sources_ and _list source's destinations_ as shown in the figure below (instead of using _list accounts_ and _list beneficiaries_).\\n\\n![Diagram](http://localhost:9090/12.2-operation-manual-diagram.svg)\\n\\n## Cancelling a delayed or recurring money transfer\\n\\n- List money transfers: To list existing money transfers and select the one to delete\\n- Cancel a money transfer: To cancel the selected money transfer\\n\",\"contact\":{\"name\":\"The Banking API team\",\"email\":\"api@bankingcompany.com\",\"url\":\"developer.bankingcompany.com\"}},\"tags\":[{\"name\":\"Transfers\",\"description\":\"Everything you need to manage money transfers. A money transfer consists in transferring money from a source account to a destination account.\"},{\"name\":\"Beneficiaries\",\"description\":\"Everything you need to manage money transfer beneficiaries. Beneficiaries are pre-registred external accounts that can be used as destinations for money transfers.\"}],\"paths\":{\"/accounts\":{\"get\":{\"tags\":[\"Accounts\"],\"summary\":\"List accounts\",\"responses\":{\"200\":{\"description\":\"User's accounts\",\"content\":{\"application/json\":{\"schema\":{\"required\":[\"properties\"],\"properties\":{\"items\":{\"type\":\"array\",\"items\":{\"$ref\":\"#/components/schemas/Account\"}}}}}}}}}},\"/accounts/{id}\":{\"get\":{\"tags\":[\"Accounts\"],\"summary\":\"Get an account\",\"parameters\":[{\"name\":\"id\",\"in\":\"path\",\"description\":\"Account's id\",\"required\":true,\"schema\":{\"type\":\"string\"}}],\"responses\":{\"200\":{\"description\":\"The account\",\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/Account\"}}}}},\"x-implementation\":{\"security\":{\"description\":\"Only accounts belonging to user referenced in security data;\\nreturn a 404 if this is not the case\\n\",\"source\":{\"system\":\"security\",\"location\":\"jwt.sub\"},\"fail\":404}}}},\"/beneficiaries\":{\"post\":{\"tags\":[\"Beneficiaries\"],\"summary\":\"Register a beneficiary\",\"security\":[{\"BankingAPIScopes\":[\"beneficiary:create\",\"beneficiary:admin\"]}],\"responses\":{\"201\":{\"description\":\"Beneficiary added\"}}},\"get\":{\"tags\":[\"Beneficiaries\"],\"summary\":\"List beneficiaries\",\"security\":[{\"BankingAPIScopes\":[\"beneficiary:read\",\"beneficiary:admin\"]}],\"responses\":{\"200\":{\"description\":\"The beneficiaries list\"}}}},\"/beneficiaries/{id}\":{\"parameters\":[{\"name\":\"id\",\"in\":\"path\",\"description\":\"Beneficiary's id\",\"required\":true,\"schema\":{\"type\":\"string\"}}],\"delete\":{\"deprecated\":true,\"tags\":[\"Beneficiaries\"],\"summary\":\"Delete a beneficiary\",\"security\":[{\"BankingAPIScopes\":[\"beneficiary:delete\",\"beneficiary:admin\"]}],\"responses\":{\"204\":{\"description\":\"Beneficiary deleted\"}}},\"patch\":{\"deprecated\":true,\"tags\":[\"Beneficiaries\"],\"summary\":\"Updates a beneficiary\",\"security\":[{\"BankingAPIScopes\":[\"beneficiary:admin\"]}],\"requestBody\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/BeneficiaryUpdate\"}}}},\"responses\":{\"200\":{\"description\":\"The updated beneficiary\"}}},\"get\":{\"tags\":[\"Beneficiaries\"],\"summary\":\"Get a beneficiary\",\"security\":[{\"BankingAPIScopes\":[\"beneficiary:read\",\"beneficiary:admin\"]}],\"responses\":{\"200\":{\"description\":\"The beneficiary\"}}}},\"/sources\":{\"get\":{\"summary\":\"List transfer sources\",\"tags\":[\"Transfers\"],\"description\":\"Not all bank accounts can be used as a source\\nfor a money transfers. This operation returns\\nonly the accounts elligible as a money transfer\\nsource.\\n\",\"responses\":{\"200\":{\"description\":\"The transfer sources\"}}}},\"/sources/{id}/destinations\":{\"parameters\":[{\"name\":\"id\",\"in\":\"path\",\"description\":\"Source's id\",\"required\":true,\"schema\":{\"type\":\"string\"}}],\"get\":{\"summary\":\"List transfer source's destinations\",\"tags\":[\"Transfers\"],\"description\":\"Depending on the source account, only specific\\nbeneficiaries or accounts can be used as a money\\ntransfer destination.\\nThis operation returns them.\\n\",\"responses\":{\"200\":{\"description\":\"The transfer destination\"}}}},\"/transfers\":{\"post\":{\"summary\":\"Transfer money\",\"security\":[{\"BankingAPIScopes\":[\"transfer:create\",\"transfer:admin\"]}],\"tags\":[\"Transfers\"],\"description\":\"This operation allows one to transfer an `amount` of money from a `source` account to a `destination` account.\\nThere are three different types of money transfer:\\n  - Immediate -- these are executed as soon as the request is received \\n  - Delayed -- these are executed upon a given future `date`\\n  - Recurring -- these are executed a given `occurrences` number of times at a given `frequency` -- the first occurrence being executed immediately or at a given `date`\\n\",\"requestBody\":{\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/TransferRequest\"},\"examples\":{\"immediate\":{\"summary\":\"Immediate transfer\",\"description\":\"The money transfer is executed immediately\",\"value\":{\"source\":\"000534115776675\",\"destination\":\"000567689879878\",\"amount\":456.2}},\"delayed\":{\"summary\":\"Delayed transfer\",\"description\":\"The money transfer is executed at a given date\",\"value\":{\"source\":\"000534115776675\",\"destination\":\"000567689879878\",\"amount\":456.2,\"date\":\"2019-03-19\"}},\"recurring\":{\"summary\":\"Recurring transfer\",\"description\":\"The money transfer is executed at a given date reurringly\",\"value\":{\"source\":\"000534115776675\",\"destination\":\"000567689879878\",\"amount\":456.2,\"date\":\"2019-03-19\",\"occurrences\":1,\"frequency\":\"MONTHLY\"}}}}}},\"responses\":{\"201\":{\"description\":\"Immediate or recurring transfer executed\",\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/TransferResponse\"},\"examples\":{\"immediate\":{\"summary\":\"Immediate transfer\",\"description\":\"The money transfer is executed immediately\",\"value\":{\"source\":\"000534115776675\",\"destination\":\"000567689879878\",\"amount\":456.2}},\"recurring\":{\"summary\":\"Recurring transfer\",\"description\":\"The first occurence is executed immediately\",\"value\":{\"source\":\"000534115776675\",\"destination\":\"000567689879878\",\"amount\":456.2,\"date\":\"2019-03-19\",\"occurrences\":1,\"frequency\":\"MONTHLY\"}}}}}},\"202\":{\"description\":\"Delayed or recurring delayed transfer accepted\",\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/TransferResponse\"},\"examples\":{\"delayed\":{\"summary\":\"Delayed transfer\",\"description\":\"The money transfer is executed at a given date\",\"value\":{\"source\":\"000534115776675\",\"destination\":\"000567689879878\",\"amount\":456.2,\"date\":\"2019-03-19\"}},\"recurring\":{\"summary\":\"Recurring transfer\",\"description\":\"The money transfer is executed at a given date reurringly\",\"value\":{\"source\":\"000534115776675\",\"destination\":\"000567689879878\",\"amount\":456.2,\"date\":\"2019-03-19\",\"occurrences\":1,\"frequency\":\"MONTHLY\"}}}}}},\"400\":{\"description\":\"The transfer is rejected due to an error in the request properties or an insufficient balance.\\nEach error provides the property `source` of the error along with a human-readable `message` and its `type`:\\n\\n- MANDATORY_PROPERTY: The property indicated in `source` is missing\\n- INVALID_FORMAT: The format of the property indicated in `source` is invalid\\n- INVALID_VALUE: The value of the property indicated in `source` is invalid\\n- INSUFFICIENT_BALANCE: The `amount` property is higher than the `source` account balance\\n\",\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/ConsumerError\"}}}}}},\"get\":{\"summary\":\"List money transfers\",\"tags\":[\"Transfers\"],\"security\":[{\"BankingAPIScopes\":[\"transfer:read\",\"transfer:admin\"]}],\"responses\":{\"200\":{\"description\":\"Transfers list\",\"content\":{\"application/json\":{\"schema\":{\"$ref\":\"#/components/schemas/TransferList\"}}}}}}},\"/transfers/{id}\":{\"parameters\":[{\"name\":\"id\",\"in\":\"path\",\"description\":\"Transfer's id\",\"required\":true,\"schema\":{\"type\":\"string\"}}],\"get\":{\"summary\":\"Get a money transfer\",\"tags\":[\"Transfers\"],\"security\":[{\"BankingAPIScopes\":[\"transfer:read\",\"transfer:admin\"]}],\"responses\":{\"200\":{\"description\":\"The money transfer\"},\"404\":{\"description\":\"The money transfer does not exist\"}}},\"x-tension-example\":{\"some\":\"value\"},\"patch\":{\"tags\":[\"Transfers\"],\"responses\":{\"200\":{\"description\":\"The money transfer has been update\"}}},\"delete\":{\"summary\":\"Cancel a money transfer\",\"tags\":[\"Transfers\"],\"security\":[{\"BankingAPIScopes\":[\"transfer:delete\",\"transfer:admin\"]}],\"description\":\"Only delayed or recurring money transfer can be canceled\",\"responses\":{\"204\":{\"description\":\"The money transfer has been deleted\"},\"404\":{\"description\":\"The money transfer does not exist\"}}}}},\"components\":{\"securitySchemes\":{\"BankingAPIScopes\":{\"type\":\"oauth2\",\"flows\":{\"implicit\":{\"authorizationUrl\":\"https://auth.bankingcompany.com/authorize\",\"scopes\":{\"transfer:create\":\"Create transfers\",\"transfer:read\":\"Read transfers\",\"transfer:delete\":\"Delete transfers\",\"transfer:admin\":\"Create, read, and delete transfers\",\"beneficiary:create\":\"Create beneficiaries\",\"beneficiary:read\":\"List beneficiaries\",\"beneficiary:delete\":\"delete beneficiaries\",\"beneficiary:admin\":\"Create, read, and delete beneficiaries\",\"account:read\":\"Read accounts\",\"account:admin\":\"Read accounts\"}}}}},\"schemas\":{\"BeneficiaryUpdate\":{\"description\":\"A beneficiary update parameter\",\"properties\":{\"name\":{\"type\":\"string\"}}},\"UselessSchema\":{\"description\":\"An unused useless schema\",\"type\":\"string\"},\"TransferRequest\":{\"description\":\"A money transfer request\",\"required\":[\"source\",\"destination\",\"amount\"],\"properties\":{\"deprecatedPropertyExample\":{\"deprecated\":true,\"type\":\"string\",\"description\":\"An example of a deprecated property\"},\"source\":{\"type\":\"string\",\"description\":\"Source account number\",\"minLength\":15,\"maxLength\":15,\"pattern\":\"^\\\\d{15}$\",\"example\":\"000534115776675\"},\"destination\":{\"type\":\"string\",\"description\":\"Destination account number\",\"minLength\":15,\"maxLength\":15,\"pattern\":\"^\\\\d{15}$\",\"example\":\"000567689879878\"},\"amount\":{\"type\":\"number\",\"example\":456.2,\"minimum\":0,\"exclusiveMinimum\":true},\"date\":{\"type\":\"string\",\"format\":\"date\",\"description\":\"Execution date for a delayed transfer\\nor first execution date for a recurring one\\n\",\"example\":\"2019-03-19\"},\"occurrences\":{\"type\":\"integer\",\"description\":\"Number of times a recurring transfer will be executed\\n\",\"example\":2,\"minimum\":2,\"maximum\":100},\"frequency\":{\"type\":\"string\",\"description\":\"Frequency of recurring transfer's execution\",\"example\":\"MONTHLY\",\"enum\":[\"WEEKLY\",\"MONTHLY\",\"QUARTERLY\",\"YEARLY\"]}}},\"TransferResponse\":{\"allOf\":[{\"required\":[\"id\",\"type\",\"status\"],\"properties\":{\"id\":{\"type\":\"string\",\"example\":\"1611e71f-1bb2-412f-8c43-92b275a5c321\"},\"type\":{\"type\":\"string\",\"enum\":[\"IMMEDIATE\",\"DELAYED\",\"RECURRING\"],\"example\":\"RECURRING\"},\"status\":{\"type\":\"string\",\"description\":\"An immediate transfer is always `EXECUTED`, a delayed transfer can be `EXECUTED` or `PENDING` and a recurring one is always `PENDING`\\n\",\"enum\":[\"EXECUTED\",\"PENDING\"],\"example\":\"PENDING\"},\"requestDate\":{\"type\":\"string\",\"example\":\"2019-09-19\"}}},{\"$ref\":\"#/components/schemas/TransferRequest\"}]},\"TransferList\":{\"properties\":{\"items\":{\"type\":\"array\",\"items\":{\"$ref\":\"#/components/schemas/TransferResponse\"}}}},\"ConsumerError\":{\"required\":[\"errors\"],\"properties\":{\"errors\":{\"description\":\"A list of errors providing detailed information about the problem\",\"type\":\"array\",\"minItems\":1,\"items\":{\"required\":[\"source\",\"type\",\"message\"],\"properties\":{\"source\":{\"description\":\"the property source of the error\",\"type\":\"string\",\"example\":\"amount\",\"enum\":[\"source\",\"destination\",\"amount\",\"date\",\"occurrences\",\"frequency\"]},\"type\":{\"type\":\"string\",\"example\":\"MANDATORY_PROPERTY\",\"enum\":[\"MANDATORY_PROPERTY\",\"INVALID_FORMAT\",\"INVALID_VALUE\",\"INSUFFICIENT_BALANCE\"]},\"message\":{\"description\":\"a human-readable error message\",\"type\":\"string\",\"example\":\"The money transfer's amount must be provided\"}}}}}},\"ProviderError\":{\"properties\":{\"errors\":{\"type\":\"array\",\"minItems\":1,\"maxItems\":1,\"items\":{\"properties\":{\"message\":{\"type\":\"string\"}}}}}},\"Account\":{\"properties\":{\"balance\":{\"description\":\"The balance in the account's default currency\",\"type\":\"object\",\"title\":\"Amount\",\"required\":[\"value\",\"currency\"],\"properties\":{\"value\":{\"description\":\"Balance's value using the number of decimal places defined by ISO 4217\",\"externalDocs\":{\"description\":\"Decimal places table\",\"url\":\"https://www.currency-iso.org/en/home/tables/table-a1.html\"},\"type\":\"number\",\"x-implementation\":{\"description\":\"The real time balance (not the daily one!)\",\"source\":{\"system\":\"Core Banking\",\"data\":\"ZBAL0.RTBAL\"}}},\"currency\":{\"description\":\"An ISO 4217 code\",\"externalDocs\":{\"url\":\"https://www.iso.org/iso-4217-currency-codes.html\"},\"type\":\"string\",\"example\":\"USD\",\"x-implementation\":{\"source\":{\"system\":\"Core Banking\",\"data\":\"ZBAL0.RTCUR\"}}}}}}}}}}  There are also two other almost empty examples used when working on multiple files.Invoke JQIn this first section, we’ll learn how to invoke JQ and its basic principles. The whole content of this section has been recorded with Asciinema (but is available as regular text right after the player).                    Invoking JQ                                                                                                        Chapters                                                                          Beautify and color JSON                                              Extract data with JQ filters                                              Generate JSON                                              Generate text                                              Pipe filters                                              Use JQ files                                                                          Beautify and color JSONAs shown in the following listing, the demo-api-openapi.json file is quite complex to read when printed on a terminal when using cat demo-api-openapi.json.  cat demo-api-openapi.json                    Let's see what's inside the demo-api-openapi.json OpenAPI file                                                                  [apihandyman.io]$ cat demo-api-openapi.json{&quot;openapi&quot;:&quot;3.0.0&quot;,&quot;info&quot;:{&quot;title&quot;:&quot;Banking API&quot;, ...}# The whole document is printed one a single line# That&#39;s totally unreadable 😱  Of course we could open our favorite code editor and beautify it. But this can also be done on the command line thanks to JQ. All we need to do is piping (with |) the file content to JQ like this cat api-openapi.json | jq '.'. Icing on the cake, the output is colored. Note that you can also simply call JQ with the JSON’s filename like this: jq '.' demo-api-openapi.json.  cat demo-api-openapi.json | jq &#39;.&#39;                    Let's pipe this into JQ to see if it's better                                                                  [apihandyman.io]$ cat demo-api-openapi.json | jq &#39;.&#39;{  &quot;openapi&quot;: &quot;3.0.0&quot;,  &quot;info&quot;: {    &quot;title&quot;: &quot;Banking API&quot;,    ...}# JSON is beautified and colored 😍    jq &#39;.&#39; demo-api-openapi.json                    JQ can also be called with a file parameter                                                                  [apihandyman.io]$ jq &#39;.&#39; demo-api-openapi.json{  &quot;openapi&quot;: &quot;3.0.0&quot;,  &quot;info&quot;: {    &quot;title&quot;: &quot;Banking API&quot;,    ...}# JSON is beautified and colored 😍  The first parameter of a JQ command, here '.', is the JQ filter that will be used to process the provided JSON. This . filter, named identity, is the most simple one, it only returns what it gets. Obviously, I wouldn’t write such a huge blog post to talk about a tool that only beautifies and colors JSON. Let’s see some basic JQ filtering in action.Extract data from JSONEven beautified and colored, the file is still quite complex to read. Indeed, the beautified JSON file is around 750 lines long. What if we only want to see the info section? It’s dead simple, we only need to use the .info JQ filter on the file with jq '.info' demo-api-openapi.json as shown below. And you probably already guessed how to get only the API’s name (called title in OpenAPI): .info.title.  jq &#39;.&#39; demo-api-openapi.json | wc -ljq &#39;.info&#39; demo-api-openapi.jsonjq &#39;.info.title&#39; demo-api-openapi.json                    Only showing the info section or the API's name (title)                                                                  [apihandyman.io]$ jq &#39;.&#39; demo-api-openapi.json | wc -l     753# Beautified JSON is 750 lines long [apihandyman.io]$ jq &#39;.info&#39; demo-api-openapi.json{  &quot;title&quot;: &quot;Banking API&quot;,  &quot;version&quot;: &quot;1.0.0-snapshot&quot;,  &quot;description&quot;: &quot;The Banking API provides access ...&quot;,  &quot;contact&quot;: {    &quot;name&quot;: &quot;The Banking API team&quot;,    &quot;email&quot;: &quot;api@bankingcompany.com&quot;,    &quot;url&quot;: &quot;developer.bankingcompany.com&quot;  }}[apihandyman.io]$ jq &#39;.info.title&#39; demo-api-openapi.json&quot;Banking API&quot;  The most simple JQ filters simply consist in describing the paths of the element you want to get.                                                Being able to simply extract a value from a JSON is quite interesting, but that’s only the tip of the tip of the tip the iceberg.Generate tailor made JSONWith a JQ filter, you can generate tailor made JSON containing exactly what you want, how you want it. To do so, use the {} object constructor and describe what you want in it almost just like you would write a JSON object. The following listing show how to create an object containing the API name, its version and the contact’s name. Each value is the result of a JQ filter applied to the JSON provided to the filter.  jq &#39;{name: .info.title, version: .info.version, contact: .info.contact.name}&#39; demo-api-openapi.json                    JQ can totally transform the provided JSON                                                                  [apihandyman.io]$ jq &#39;{name: .info.title, version: .info.version, contact: .info.contact.name}&#39; demo-api-openapi.json{  &quot;name&quot;: &quot;Banking API&quot;,  &quot;version&quot;: &quot;1.0.0-snapshot&quot;,  &quot;contact&quot;: &quot;The Banking API team&quot;}  Generate raw textJQ is also able to output raw text instead of JSON. To do so, a filter just need to return a value. The following listing shows three attempts of printing text. The first example (line 1) simply prints the API name (.info.title) as we already have done before. The output contains no JSON structure, only the requested value as a quoted string (\"Banking API\"). The second one (line 4) tries to outputs tab separated API’s name, version and contact’s name. Note that the + operator is used to concatenate the different values which can come from the provided JSON (.info.title for example) but can also be static ones (\"\\t\", the tab separator). Unfortunately, the result is not what is expected, the tabs (\\t) are not interpreted. In order to actually get raw text that will be fully interpreted by the terminal, the -r flag must be provided to JQ. This is what is shown in the last example (line 10): there is no more quotes, and the value are separated by tabs.  jq &#39;.info.title&#39; demo-api-openapi.jsonjq &#39;.info.title + &quot;\\t&quot; + .info.version + &quot;\\t&quot; + .info.contact.name&#39; demo-api-openapi.jsonjq -r &#39;.info.title + &quot;\\t&quot; + .info.version + &quot;\\t&quot; + .info.contact.name&#39; demo-api-openapi.json                    JQ can generate raw text (don't forget -r flag)                                                                  [apihandyman.io]$ jq &#39;.info.title&#39; demo-api-openapi.json&quot;Banking API&quot;[apihandyman.io]$ jq &#39;.info.title + &quot;\\t&quot; + .info.version + &quot;\\t&quot; + .info.contact.name&#39; demo-api-openapi.json&quot;Banking API\\t1.0.0-snapshot\\tThe Banking API team&quot;[apihandyman.io]$ jq -r &#39;.info.title + &quot;\\t&quot; + .info.version + &quot;\\t&quot; + .info.contact.name&#39; demo-api-openapi.jsonBanking API     1.0.0-snapshot  The Banking API team  Pipe JQ commands and filtersPiping is a powerful command line concept: the result of a first command can be forwarded to another one using a pipe (|) . This is what we have done on our first JQ command: we took the result of a cat command (which outputs the content of a file) to provided it to JQ and the output of JQ can be forwarded to another command which could be, for example, another JQ one, as shown in the following listing.  cat demo-api-openapi.json | jq &#39;{name: .info.title, version: .info.version, contact: .info.contact.name}&#39; | jq -r &#39;.name + &quot;\\t&quot; + .version&#39;                    JQ commands can be chained with pipe (like many other command line ones)                                                                  [apihandyman.io]$ cat demo-api-openapi.json | \\jq &#39;{name: .info.title, version: .info.version, contact: .info.contact.name}&#39; | \\jq -r &#39;.name + &quot;\\t&quot; + .version&#39;Banking API     1.0.0-snapshot  JQ also takes advantage of this piping concept. Indeed, JQ filters can be chained using pipe as shown in the following listing. The full JSON document is (implicitly) provided to the first filter which creates an object containing a name, version and title and its result is forwarded, using |, to another filter which return a string containing tab separated name and version.  jq -r &#39;{name: .info.title, version: .info.version, contact: .info.contact.name} | .name + &quot;\\t&quot; + .version&#39; demo-api-openapi.json                    More interesting, JQ filters can be chained too with (also with pipe)                                                                  [apihandyman.io]$ jq -r &#39;{name: .info.title, version: .info.version, contact: .info.contact.name} | .name + &quot;\\t&quot; + .version&#39; demo-api-openapi.jsonBanking API     1.0.0-snapshot  Use JQ filesAs a JQ filter chain becomes complex, writing it on the command line can become cumbersome and error prone. Fortunately, JQ comes with a useful -f file flag allowing to load filters from a file as shown in the following listing. The new command line gives the same result as the one before, the only difference is that the filters are now loaded from the basics.jq file (files containing JQ filters usually have a .jq extension).  jq -r -f basics.jq demo-api-openapi.json                    When JQ scripts become complex, better use a JQ file (-f file.jq)                                                                  [apihandyman.io]$ jq -r -f basics.jq demo-api-openapi.jsonBanking API     1.0.0-snapshot                      basics.jq                                                                            # Files are easier to read and can be commented# Creates an object{  name: .info.title,   version: .info.version,   contact: .info.contact.name} |# Outputs tab separated name and version# + can be used to concatene almost everything# (as you will see in later examples)# Don't forget the -r flag.name + \"\\t\" + .version  Now that we know the basics of JQ, let’s try more complex stuff on OpenAPI JSON files.Use JQ filters on an OpenAPI fileIn this section, we’ll learn to use some of the many JQ filters by extracting data from an OpenAPI file. For each example, you get:  A fully detailed, step by step asciinema bash session explaining how the result is achieved  An OpenAPI structure figure and description (based on the OpenAPI Map)  A list of (new) JQ filters used  A summarized explanation of how the result is achieved (⚠️ far less details than in the asciinema bash session)  A fully commented JQ fileList pathsLet’s start by extracting the API’s paths:                    List API's paths                                                            jq -r -f list-paths.jq demo-api-openapi.json                    List API's paths                                                                  [apihandyman.io]$ jq -r -f list-paths.jq demo-api-openapi.json /accounts/accounts/{id}/beneficiaries/beneficiaries/{id}/sources/sources/{id}/destinations/transfers/transfers/{id}  In an OpenAPI file, the available paths are the keys of the paths object.                                                To get these paths, we’ll use the following JQ filters:              JQ Filters                    .foo.foo.bar      Returns element targeted by period separated path                    keys      Returns object's keys (properties names)                    .[].[index]      Returns all or some elements of an object or array identified by an index            To extract the paths, we only need to use the keys filter on the paths object identified by .paths. This keys filter returns an array containing the keys (property names, hence the paths in our case) of an object. Then we use [] on the result to flatten the array in order to get raw text.                    list-paths.jq                                                                            # 1 - Selects the paths object#-----------------------------.paths# 2 - Keeps only the keys in paths (/whatever)#---------------------------------------------| keys# 3 - Flattens the array (for raw output)#---------------------------------------- []  List HTTP methodsLet’s go a level deeper to list all HTTP methods used in an API:                    List HTTP methods                                                            jq -r -f list-http-methods.jq demo-api-openapi.json                    List used HTTP methods                                                                  [apihandyman.io]$ jq -r -f list-http-methods.jq demo-api-openapi.jsondeletegetpatchpost  In an OpenAPI file, HTTP methods are keys inside a path object. Unfortunately, path objects may have other properties than HTTP methods ones, like summary, description, parameters or x- custom properties (we take for granted that there is no $ref properties). So we’ll need to clean this array to get rid of all other properties than HTTP methods.                                                To list all of these HTTP methods, we’ll use 4 new  JQ filters:              JQ Filters                    [][1, 2, 3][.foo, .bar][.items[].name]      Creates an array                    map(filter)      Applies a filter to each element of an array                    select(filter returning boolean)      Returns element for which filter returns true                    IN(value1, value2, value3)      Returns true if element is one of the values            The JQ file that follows can be roughly split in 4 steps:      (Line 1) To create the array of path objects properties, we use the array constructor [filter] and inside it do the necessary with various filters to get all keys of all path objects. Note how [] is used on .paths to only keep its properties content without caring about the actual paths names.        (Line 11) Then to clean the array of unwanted values, we use the map filter which allows to apply a filter to each element of a list. The filter executed by map consists in select(. | IN(\"value 1\", ..., \"value N\")). The select filter let pass values for which its parameter filter returns true. In our case, the select parameter filter use IN which returns true if the provided value is one of its parameter (here, all possible HTTP methods). Note that inside select . represents the current element of the array being processed.        (Line 23) Then, we apply the unique filter to the array of all HTTP methods of all paths in order to keep a single occurrence of each.        (Line 27) And eventually the resulting array is flatten with [] for raw output.                      list-http-methods.jq                                                                            # 1 - Creates an array of all HTTP methods#     inside paths[\"/whatever\"]#-----------------------------------------# It returns [\"get\", \"post\",\"summary\",\"x-example\", \"post\"][  .paths[] # Selects the paths[\"/whatever\"] properties content           # to keeps only the operations  | keys[] # Keeps only the keys (HTTP methods and few other things)           # and flattens array]# 2 - Cleans keys to keep only HTTP method#-----------------------------------------# It returns [\"get\", \"post\", \"post\"]| map( # Applies a filter to each element  select( # Keeps only elements for which the following is true   # With IN, which returns true if the value is one of its   # parameters, we can get rid of x- , parameters   # description and summary properties   IN(\"get\", \"put\", \"post\", \"delete\",       \"options\", \"head\", \"patch\", \"trace\")  ))# 3 - Keeps an occurrence of each HTTP method#--------------------------------------------# It returns [\"get\", \"post\"]| unique # Keeps only an occurence of each element# 4 - Generates raw string#-------------------------[] # Flattens array for raw output  Count HTTP status codes usageNow we take another step deeper into the OpenAPI file by listing all HTTP status codes and sorting them by how many times they are used.                    Count HTTP status codes usage                                                            jq -r -f list-http-status-codes.jq demo-api-openapi.json                    Count how many times HTTP status codes are used                                                                  [apihandyman.io]$ jq -r -f list-http-status-codes.jq demo-api-openapi.json200     10201     2204     2404     2202     1400     1  In an OpenAPI files, HTTP status codes used to signify how went the API call are located in the responses properties of all operations (identified by an HTTP method) which are located inside all paths (identified by a path like /whatever) in the paths property. In the responses object, each response object is identified by its HTTP status code or by “default”. Note that the response object can also contains x- custom properties that we’ll need to get rid of.                                                To list HTTP status codes and how many times they are used, we’ll learn how to use the following new JQ filters:              JQ Filters                    .foo?      Does not return an error if targeted element does not exist                    test(regex)test(regex;flags)      Returns true if element matches regex                    not      Returns opposite boolean element                    group_by(path_expression)group_by(.foo)      Groups array elements according to provided path (returns array of array)                    {}{name1: filter, name2: another_filter}      Creates an object                    length      Returns the length of element (array, object, string, null)                    sort_by      Returns element sort by value or path_expression                    tostring      Turns any element into a string            The JQ file that follows is split in 5 steps:      (Line 1) The first step looks like previous example’s, but this time we go 2 levels deeper. We also use ? when getting responses property content because not all properties inside a path object are actual operations. Indeed some of them can be simple string (summary, description), object (servers) or array (parameters) and therefore not have a responses properties. Without ?, using .responses would return an error when used on properties such as summary or description. With ?, no error but a null value is returned. The same goes for keys? which may be fed with a null values having no keys at all.        (Line 12) On the second step, we need to get rid of possible x- properties. This is done like in previous example with a map(select(filter)). In this case, the select’s filter checks if the value does not start by x- using the test filter which return true if the value matches the regex parameter and then not to negate this result.        (Line 21) Now we have an array containing all HTTP status codes of all operations, we can count how many times each one is used. This is done using group_by which group equal values together. It takes an array of something and returns an array of array of something. Each internal array containing equal values. Once that is done we can create on object for each internal array using map. It contains the HTTP status code which is the first value in the array (which contains the same value multiple times) and a count which is the length of the array.        (Line 32) Then we can sort this array of {code, count} by descending count using sort_by(-.count).        (Line 37) And eventually we generate the tab separated raw text output with map and []. Note how count is converted into a string before being concatenated.                      list-http-status-codes.jq                                                                            # 1 - Selects all properties of all responses#--------------------------------------------# It returns [\"404\", \"200\", \"200\", \"x-example\"][  .paths[][].responses? # ? avoid getting an error if                        # responses does not exist  | keys? # ? avoid getting an error if . is not an          # object and has no keys  | .[] # [ [\"404\", \"200\"], [\"200\", \"x-example\"] ] ⤵️      #                     [\"404\", \"200\", \"200\", \"x-example\"]]# 2 - Removes x- properties#--------------------------# It returns [\"200\", \"404\", \"200\"]| map( # Applies a filter to each element  select( # Keep elements for which what follows return true    test(\"^x-\") # Returns true if value match the regex parameter    | not # Returns the opposite of a boolean value  )) # 3 - Counts how many times each code is used#--------------------------------------------# It returns [ {\"code\": \"404\", \"count\": 1}, #              {\"code\": \"200\", \"count\": 2} ]| group_by(.) # [\"404\", \"200\", \"200\"] ➡️ [[\"400\"],[\"200\", \"200\"]]| map( # Applies a filter to each element  { # Creates an object    code: .[0], # [\"200\", \"200\"] ➡️ [\"200\"] ➡️ \"200\"    count: length # [\"200\", \"200\"] ➡️ 2  })# 4 - Sorts by descending count#------------------------------# It returns [ {\"code\": \"200\", \"count\": 2}, #              {\"code\": \"404\", \"count\": 1} ]| sort_by(-.count) # Sort array by parameter value# 5 - Generates tab separated string output#------------------------------------------| map( # Applies a filter to each element  .code +   \"\\t\" +   (.count | tostring) # count is a number                      # it must be converted to string                      # to be concatenated to other string)[] # Flattens array for raw output  List operationsNow, let’s try something more interesting: extracting the API’s operation list.                    List operations                                                          As the following listing shows, we will extract for each operation, its HTTP method, path, summary and indicate if the operation is deprecated.  jq -r -f list-operations.jq demo-api-openapi.json                    List operations                                                                  [apihandyman.io]$ jq -r -f list-operations.jq demo-api-openapi.json get     /accounts       List accountsget     /accounts/{id}  Get an accountpost    /beneficiaries  Register a beneficiaryget     /beneficiaries  List beneficiariesdelete  /beneficiaries/{id}     Delete a beneficiary (deprecated)patch   /beneficiaries/{id}     Updates a beneficiary (deprecated)get     /beneficiaries/{id}     Get a beneficiaryget     /sources        List transfer sourcesget     /sources/{id}/destinations      List transfer source&#39;s destinationspost    /transfers      Transfer moneyget     /transfers      List money transfersget     /transfers/{id} Get a money transferpatch   /transfers/{id}delete  /transfers/{id} Cancel a money transfer  Thanks to previous examples, we start to know an OpenAPI file structure. The operation’s paths come first, then their HTTP method and a level below, we can access to summary and deprecated properties which are both optional.                                                To generate the operations list, we’ll learn how to use the following new JQ filters:              JQ Filters                    to_entries      Takes an object and returns an array of key and value objects                    .foo as $some_variable      Defines a reusable variable                    if condition then filter else another_filter end      Conditions filter execution            The following JQ script is split in 3 steps:      (Line 1) We start by creating an array of {key: /path, value: path content} using to_entries on .paths. Then we filter this array to get rid of possible x-tensions checking the key value does not start by “x-“ using map, select, test and not as already seen in a previous example.        (Line 11) Then we create an array of {path, method, summary, deprecated} objects. To get rid of possible extensions we reuse the IN filter seen previously. The interesting thing in this step is how we define (line 15) and use (line 35) the $path variable. Such variable definition is very useful to keep some values for later use without impacting the data flow. Indeed the data coming out of .key as $ path is the exactly the same as the one that came in.        (Line 42) And to finish, we output tab separated raw text (adding deprecated mention when necessary). See line 48 how an if then else can be used.                      list-operations.jq                                                                            # 1 - Selects paths objects#--------------------------# returns [{key: path, value: path value}].paths # Selects the paths property content| to_entries # Transforms             # { \"/resources\": { \"get\": {operation data}}}              # to              # [ { \"key\": \"/resources\",              #     \"value\": { \"get\": {operation data}} ]| map(select(.key | test(\"^x-\") | not)) # Gets rid of x-tensions# 2 - Creates an array of operations#-----------------------------------# returns [{path, method, summary, deprecated}]| map ( # Applies a transformation to each element  .key as $path # Stores the path value (.key)                   # in a variable ($path) for later use  | .value # Keeps only the path's content            # { \"get\": {operation data}}  | to_entries # Transforms                # { \"get\": {operation data}}               # to               # [ { \"key\": \"get\",                #     \"value\": {operation data}} ]  | map( # Applies a transformation to each element    select( # Keeps only elements for which the following is true      # With IN, which returns true if the value is one of its      # parameters, we can get rid of x- , parameters      # description and summary properties      .key | IN(\"get\", \"put\", \"post\", \"delete\",          \"options\", \"head\", \"patch\", \"trace\")    )    | # Creates a new JSON object    {      method: .key,      path: $path, # Using the variable defined on line 4      summary: .value.summary?,      deprecated: .value.deprecated?    }  )[] # Flattens array to avoid having an array       # of array of {path, method, summary, deprecated}) # Now we have an array of {path, method, summary, deprecated}# 3 - Outputs tab separated raw text#-----------------------------------| map( # Applies a transformation to each element  .method + \"\\t\" +   .path + \"\\t\" +   .summary +   (if .deprecated then \" (deprecated)\" else \"\" end))[] # Flattens array for raw output  List x-tensionsIt can be of interest to know which extensions are used in an OpenAPI document, where they are located and what are their values.                    List x-tensions                                                            jq -r -f list-xtensions.jq demo-api-openapi.json                    Listing extensions, their locations and values                                                                  [apihandyman.io]$ jq -r -f list-xtensions.jq demo-api-openapi.json[  {    &quot;name&quot;: &quot;x-implementation&quot;,    &quot;path&quot;: [      &quot;paths&quot;,      &quot;/accounts/{id}&quot;,      &quot;get&quot;,      &quot;x-implementation&quot;    ],    &quot;ref&quot;: &quot;#/paths/~1accounts~1{id}/get/x-implementation&quot;,    &quot;value&quot;: {      &quot;security&quot;: {        &quot;description&quot;: &quot;Only accounts belonging to user referenced in security data;\\nreturn a 404 if this is not the case\\n&quot;,        &quot;source&quot;: {          &quot;system&quot;: &quot;security&quot;,          &quot;location&quot;: &quot;jwt.sub&quot;        },        &quot;fail&quot;: 404      }    }  },  {    &quot;name&quot;: &quot;x-tension-example&quot;,    &quot;path&quot;: [      &quot;paths&quot;,      &quot;/transfers/{id}&quot;,      &quot;x-tension-example&quot;    ],    &quot;ref&quot;: &quot;#/paths/~1transfers~1{id}/x-tension-example&quot;,    &quot;value&quot;: {      &quot;some&quot;: &quot;value&quot;    }  },  {    &quot;name&quot;: &quot;x-implementation&quot;,    &quot;path&quot;: [      &quot;components&quot;,      &quot;schemas&quot;,      &quot;Account&quot;,      &quot;properties&quot;,      &quot;balance&quot;,      &quot;properties&quot;,      &quot;value&quot;,      &quot;x-implementation&quot;    ],    &quot;ref&quot;: &quot;#/components/schemas/Account/properties/balance/properties/value/x-implementation&quot;,    &quot;value&quot;: {      &quot;description&quot;: &quot;The real time balance (not the daily one!)&quot;,      &quot;source&quot;: {        &quot;system&quot;: &quot;Core Banking&quot;,        &quot;data&quot;: &quot;ZBAL0.RTBAL&quot;      }    }  },  {    &quot;name&quot;: &quot;x-implementation&quot;,    &quot;path&quot;: [      &quot;components&quot;,      &quot;schemas&quot;,      &quot;Account&quot;,      &quot;properties&quot;,      &quot;balance&quot;,      &quot;properties&quot;,      &quot;currency&quot;,      &quot;x-implementation&quot;    ],    &quot;ref&quot;: &quot;#/components/schemas/Account/properties/balance/properties/currency/x-implementation&quot;,    &quot;value&quot;: {      &quot;source&quot;: {        &quot;system&quot;: &quot;Core Banking&quot;,        &quot;data&quot;: &quot;ZBAL0.RTCUR&quot;      }    }  }]  The OpenAPI Specification is extensible, it means that custom data can be added to it for various purpose. The custom data structures can either be called extensions, x-tensions or vendor extension. In order to allow standard parsers to not raise an error, such custom data structure must be added using a specific key name starting by “x-“ in order to identify them. The tricky part with extensions in our case, is that they can be located (almost) anywhere in a document, the only sure thing is that they have a key name starting by “x-“. To learn more about this, check OpenAPI (Swagger) 2.0 Tutorial - Part 9 - Extending the OpenAPI Specification (note: extension management did not change between version 2.0 and 3).                                                To list all extensions as shown in the terminal listing above, we’ll learn how to use the following JQ filters:              JQ Filters                    paths      Lists all possible paths in documents, each path is represented as an array                    +value1 + value2      Adds/concatenates/merges numbers/strings/arrays or objects                    map_values(filter)      Updates all provided values with filter                    gsub(regex;replacement)gsub(\"toreplace\";\"replaced)      Replaces a string within a string                    join(separator)join(\",\")      Joins string with a separator                    getpath(path)getpath([\"a\",\"path\"])      Returns value corresponding to a path (defined as an array), see also paths            The following JQ script consist in 3 steps:  (Line 1) First, we need to store the full document for later use (to get the extensions value)  (Line 5) Then we list all extensions paths by using paths which returns all possible paths and removing the ones that do not have a leaf starting with a “x-“.  (Line 18) And last step, we build an object containing data for each found extension. This data consists in a name, a path, a JSON pointer named ref and the value.          (Line 26) A in-file JSON pointer starts with “#/” and then each level is separated from its neighbour by a “/”. This is easily achieved by using + and join. But a JSON pointer cannot contains “/”. That’s why we use map_values in order to replace them by ~1 with gsub. The map_values works like map but do not return result in an array and therefore allows to do in place modification.      (Line 42) In order to get the extension value we use getpath on the saved document. Note how we have to define a $path variable to use it in getpath.                          list-xtensions.jq                                                                            # 1 - Stores document for later use#----------------------------------. as $document # Variable used on line 23 to get                # extension value from its path# 2 - Lists extensions paths#---------------------------| [  paths # Lists ALL possible paths in documents         # (each path is represented as an array)  | select( # Keeps only the values for which             # what follows return true    .[-1] # Gets the path leaf (last item in array)          # Equivalent to .[.|length-1]    | tostring # Converts to string for next step     | test(\"^x-\") # Checks if leaf name starts with x-  )]# 3 - Sets all data for each extension occurence#-----------------------------------------------# returns an array of {name, path, ref, value}| map( # Applies a filter to each element  {    name: .[-1], # Gets the path leaf (last item in array)                 # Equivalent to .[.|length-1]    path: .,    # 3.1 - Creates a JSON pointer to extension    #------------------------------------------    ref: (      \"#/\" + # adds numbers, strings, arrays or objects      (        .         | map_values( # Applies a filter on each value                      # (in place modification)          gsub(\"/\";\"~1\" ) # replaces a value in a string                          # / must be replace by ~1                          # in a JSON pointer        )        | join(\"/\") # concatenates string with                   # a separator      )    ),     # 3.2 - Gets extension value from original document    #--------------------------------------------------    value: (      . as $path # storing value path in                  # a variable for next step      | $document | getpath($path) # extracting value                                    # from original document                                   # variable defined on line 3    )  })  Process multiple OpenAPI filesSo, we have learned to use JQ filters on a single OpenAPI file, but what if we need to work on multiple files? In this section we’ll learn how to invoke JQ on multiple files and see it in action on two OpenAPI files.Invoke JQ on multiple filesJQ’s filename parameter can contain wildcards, allowing to work on multiple files at once.                    Invoke JQ on multiple files                                                          We can, for example, extract the API name of each OpenAPI file using the following command as shown in the following listing (the github repository contains two OpenAPI demo files, both having the .json extension).  jq -r &#39;.info.title&#39; *.json                    Processing multiple files with JQ                                                                  [apihandyman.io]$ jq -r &#39;.info.title&#39; *.json Banking APIAnother Example API  That’ looks good, but if the filter outputs JSON, the result is a concatenation of the JSONs returned for each file, which is not a valid JSON document, as shown on line 1 of the following listing. In order to get something valid, like an array containing all results, you can pipe this result to a jq -s command (line 11) which will magically creates a valid JSON array. The -s flag (or --slurp) reads the entire input stream into a large array and run the filter just once instead of running the filter for each JSON object in the input. Not also that we didn’t provide any filter to the second JQ command. The ‘.’ filter is actually optional (either you use the -s flag or not).  jq &#39;{name: .info.title, file: .info.version}&#39; *.jsonjq &#39;{name: .info.title, file: .info.version}&#39; *.json | jq -s                    Pipe to jq -s (or --slurp) to create arrays                                                                  [apihandyman.io]$ jq &#39;{name: .info.title, file: .info.version}&#39; *.json{  &quot;name&quot;: &quot;Another API&quot;,  &quot;file&quot;: &quot;1.2&quot;}{  &quot;name&quot;: &quot;Banking API&quot;,  &quot;file&quot;: &quot;1.0.0-snapshot&quot;}[apihandyman.io]$ jq &#39;{name: .info.title, file: .info.version}&#39; *.json \\                | jq -s[  {    &quot;name&quot;: &quot;Another API&quot;,    &quot;file&quot;: &quot;1.2&quot;  },  {    &quot;name&quot;: &quot;Banking API&quot;,    &quot;file&quot;: &quot;1.0.0-snapshot&quot;  }]  Obviously, when it comes to work with multiple elements on the command line, you can use your favorite commands such as xargs and/or find as shown below.  ls *.json | xargs jq -r &#39;.info.title&#39;find . -type f -name &quot;*.json&quot; -exec jq -r &#39;.info.title&#39; {} \\;find . -type f -name &quot;*.json&quot; | xargs jq -r &#39;.info.title&#39;                    Use JQ with xargs and find                                                                  [apihandyman.io]$ ls *.json | \\                  xargs jq -r &#39;.info.title&#39;Banking APIAnother Example API[apihandyman.io]$ find . -type f -name &quot;*.json&quot; -exec \\                  jq -r &#39;.info.title&#39; {} \\;Banking APIAnother API[apihandyman.io]$ find . -type f -name &quot;*.json&quot; | \\                xargs jq -r &#39;.info.title&#39;Banking APIAnother API# Note that find -exec is far less faster than# find | xargs when working a large number of files  List basic API information from multiple filesFor this last (but not least) example, we’ll gather basic information from different OpenAPI files.                    List APIs                                                          We’ll build an array of objects containing for each file:  Information about the file itself (its type, version and name),  A subset of the info section (API’s name, version and a shorten description)  The number of operationsNote that now jq is used on *.json files and its results is piped into another jq with -s flag in order to generate an array (as seen in previous section).  jq -f list-apis.jq *.json | jq -s                    Getting some basic information about different APIs                                                                  [apihandyman.io]$ jq -f list-apis.jq *.json | jq -s[  {    &quot;specification&quot;: {      &quot;type&quot;: &quot;swagger&quot;,      &quot;version&quot;: &quot;2.0&quot;,      &quot;file&quot;: &quot;demo-another-api-swagger.json&quot;    },    &quot;name&quot;: &quot;Another API&quot;,    &quot;version&quot;: &quot;1.2&quot;,    &quot;summary&quot;: &quot;Does almost nothing&quot;,    &quot;operations&quot;: 1  },  {    &quot;specification&quot;: {      &quot;type&quot;: &quot;openapi&quot;,      &quot;version&quot;: &quot;3.0.0&quot;,      &quot;file&quot;: &quot;demo-api-openapi.json&quot;    },    &quot;name&quot;: &quot;Banking API&quot;,    &quot;version&quot;: &quot;1.0.0-snapshot&quot;,    &quot;summary&quot;: &quot;The Banking API provides access to the [Banking Company](http://www.bankingcompany.com) services, which include bank account information, beneficiaries, and money transfer management&quot;,    &quot;operations&quot;: 14  }]  To get that result, we need to use the following new JQ filters:              JQ Filters                    input_filename      Returns the name of the file being processed                    indices(string)indices(\"foo\")indices(.foo)      Returns the list indices (in array of string) where a string is found                    .[start:end].[10:15]      Returns a subset of an array or a substring            The following JQ scripts which generates an array of objects containing information about the specification file itself, the API and its number of operations is composed of 3 parts:  (Line 2) Part 1 deals with file information. When working on multiple files, it can be very interesting to know from which file comes the data. It’s the case here, hopefully, the input_filename returns the name of the file being processed (line 8).  (Line 11) Part 2 deals with data coming from the info section. The summary is a shorter version of .info.description. If it contains a &lt;!--more--&gt; tag (found using indices) we split right before it using .[0:tag position]. If not we take the first hundred characters (or the whole string if shorter). Note how elif is used to have more conditions.  (Line 28) Part 3 concerns counting operations, it is done almost like counting HTTP status codes.                    list-apis.jq                                                                            {   # 1 - Information about the file itself  #--------------------------------------  specification: {    # Determines the type of specification and the version used    type: (if has(\"openapi\") then \"openapi\" else \"swagger\" end),    version: (if has(\"openapi\") then .openapi else .swagger end),    file: input_filename # The file name because we work                         # on multiple files  },  # 2 - Information about the API (.info)  #--------------------------------------  name: .info.title,  version: .info.version,  summary: (    # indices returns an array containing all indices of the    # provided string found in the input value    (.info.description | indices(\"&#60;!--more--&#62;\")[0]) as $more |    if $more != null then       .info.description[0:$more]      # summary cannot be longer than 100 characters    elif (.info.description | length) &#60;= 100 then      .info.description    else      .info.description[0:100] + \"[...]\"    end  ),  # 3 - Number of operations (an operation is get /path for example)  #-----------------------------------------------------------------  operations: (    [ # Creates an array containing all HTTP methods      # to count the number of operations      .paths[] | # Returns the content of eah path object      keys[] | # Returns the keys of the returned object               # and flattens the array      select( # Keeps only the value for which what follows is true         IN(\"get\", \"put\", \"patch\", \"post\",             \"delete\", \"head\", \"options\")      )    ] | length # Return the length of the array,               # hence the number of operations  )}  SummaryThat’s it for this first JQ and OpenAPI post. You know now how to invoke JQ on one or more files and you know how to use the 30ish following JQ filters. These are only a subset of all available filters, check JQ’s documentation to discover them all.              JQ Filters                    .      Returns what is provided                    .foo.foo.bar      Returns element targeted by period separated path                    .foo?      Does not return an error if targeted element does not exist                    keys      Returns object's keys (properties names)                    {}{name1: filter, name2: another_filter}      Creates an object                    [][1, 2, 3][.foo, .bar][.items[].name]      Creates an array                    map(filter)      Applies a filter to each element of an array                    select(filter returning boolean)      Returns element for which filter returns true                    IN(value1, value2, value3)      Returns true if element is one of the values                    test(regex)test(regex;flags)      Returns true if element matches regex                    not      Returns opposite boolean element                    group_by(path_expression)group_by(.foo)      Groups array elements according to provided path (returns array of array)                    sort_by      Returns element sort by value or path_expression                    length      Returns the length of element (array, object, string, null)                    tostring      Turns any element into a string                    to_entries      Takes an object and returns an array of key and value objects                    .foo as $some_variable      Defines a reusable variable                    if condition then filter else another_filter end      Conditions filter execution                    paths      Lists all possible paths in documents, each path is represented as an array                    getpath(path)getpath([\"a\",\"path\"])      Returns value corresponding to a path (defined as an array), see also paths                    map_values(filter)      Updates all provided values with filter                    +value1 + value2      Adds/concatenates/merges numbers/strings/arrays or objects                    gsub(regex;replacement)gsub(\"toreplace\";\"replaced)      Replaces a string within a string                    join(separator)join(\",\")      Joins string with a separator                    indices(string)indices(\"foo\")indices(.foo)      Returns the list indices (in array of string) where a string is found                    .[].[index]      Returns all or some elements of an object or array identified by an index                    .[start:end].[10:15]      Returns a subset of an array or a substring                    input_filename      Returns the name of the file being processed            You may also have learn a few things about an OpenAPI document structure. If you want to fully master it, look at the OpenAPI Map.                                                What’s nextIn next post, we’ll learn to search into OpenAPI files and simplify JQ code by using command line arguments, functions and modules."
},{
    "id": "48",
    "type": "post",
    "title": "Lessons learned while demoing API to non-developers",
    "url": "https://apihandyman.io/lessons-learned-while-demoing-api-to-non-developers/",
    "banner": "https://apihandyman.io/images/lessons-learned-while-demoing-api-to-non-developers/banner.png",
    "description": "What would you do if you had to demo API to non-developers in a highly-constrained context? How would you do without curl, Postman or any other API tool usually used? How would you do without your usual fun API examples? I had to do that a few weeks ago and was quite happy by the questions that arose and the solutions found. The whole story definitely deserves a post in order to share what I’ve learned!",
    "body": "What would you do if you had to demo API to non-developers in a highly-constrained context? How would you do without curl, Postman or any other API tool usually used? How would you do without your usual fun API examples? I had to do that a few weeks ago and was quite happy by the questions that arose and the solutions found. The whole story definitely deserves a post in order to share what I’ve learned!The requestA part of my job is explaining to developers and non-developers what are APIs and what can be done with them from both technical and business perspectives. I regularly do some presentations or training to do so, especially a very first API 101 session simply consisting in some slides without any hands-on. A few weeks ago, I received a request that seemed quite simple at first: “we want to organize the usual API 101 for non developers … but this time, it would be great to let them make code some API stuff. And you have less than 45 minutes, probably half an hour”. The objective was to make these people grasp a little bit more than usual what APIs are and let them understand their simplicity during this first session.At first, I was like: “oh no problem, we’ll use curl and Postman to make calls to the SWAPI API (an API providing information about the Star Wars movies) or the PokeAPI (providing information Pokemons), it shouldn’t take more than 10 minutes during the presentation, so even with half an hour that should be OK. Unfortunately that was not that simple.Beware the context when choosing hands-on toolsProblems started with the tooling. Indeed, the people attending this session have standard-for-non-developer laptops. These laptops do not come with Postman or curl, and even if the attendees were admins (highly improbable) on these laptops, installing tools would be far too complicated and would take a too long time in such a short session (and it would probably ruin the “APIs are simple” message).OK, no problems, only solutions. These machines come with Windows 10 and PowerShell, I’m not familiar with it but I thought “Well, a PowerShell-curl probably exists”. Yes it does, there are Invoke-RestMethodand Invoke-WebRequest that seem to do the job. Unfortunately, I did not succeed to make them work with our f****** corporate proxy. As far as I’ve seen, it would have required to make too much complicated stuff and would have taken too much time (I may have missed something).And there was also this “code some API stuff” idea. One of my colleagues suggested to use JSFiddle. Brilliant! It’s a browser based tool and therefore it requires absolutely no installation. It allows to tinker with HTML, JS and CSS. I first checked that it was not blocked by our corporate proxy … and yes! It worked. I discovered that JSFiddle (and other similar tools) comes with some useful features (if you pay of course) for training sessions, especially private fiddles. That could be interesting to manage calls to API needing authentication (to safely store credentials). I keep that in a corner of my mind for another time as I didn’t want to use secured APIs during this session. I developed a simple example with basic HTML and JavaScript doing an API call.                                      Using JSFiddle and HTML/JS code is maybe too complex for non-developers          I thought I could let attendees modify it to make some API calls themselves. From the very beginning I was not comfortable with that. Hopefully, I could test the idea with the persons (non-developers) who made the request and specifically asked for the “code some API stuff”. It didn’t take us long to realize that was a terrible idea. JSFiddle would look terribly complex and having to modify some JS code would be a nightmare for people who never have done that before.OK, if attendees could not actually write code in that context, they could at least use their browser to call an API, that’s web APIs we had to talk about after all. All that is needed is typing something in the browser’s address bar. And people could “code” some API stuff by tweaking the URLs and parameters. We, all agreed that was the best option in our context and it fulfilled the requirements.But which API to use?Take care of finding API examples adapted to the audienceI’m used to use SWAPI (Star War API) when demoing APIs in such 101 sessions. It’s simple, fun and requires no authentication. But, in that context, I realized that using SWAPI would lead to two problems.The first problem was simply technical. In such demo I usually use curl to call SWAPI. But in that context I had to use a browser and unfortunately SWAPI is too smart, it handles content negotiation very well. Indeed, when you call SWAPI from a browser, you don’t get raw JSON data but an HTML page. But, I wanted to show some ugly raw JSON data and not HTML! So, I found another funny API, the D&amp;D API. Typing the http://www.dnd5eapi.co/api/classes URL in the browser’s address bar shows some beautifully-ugly JSON raw data listing available characters class in the fifth edition of Dungeons &amp; Dragons rule books. I thought it was perfect … but not at all: that’s the seconde problem.Indeed, the second problem with such fun API is functional. SWAPI or D&amp;D are totally fun from my perspective, but their fields were thousands light-years away of what matters for the attendees. For this demo we needed an API that would resonate with them. I needed an example that makes sense for people in the financial industry. Hopefully, I found a more suitable API: the Foreign Exchange Rate API. This API provides current and historical foreign exchange rates published by the European Central Bank. Basically, if you want to know how much Japan Yen you can get for a Euro, this API is for you. OK, forex is not a field as fun as Star Wars and D&amp;D but this API provides data the attendees are familiar with (especially the ISO 4217 currency codes), it’s dead simple and provides enough functions and parameters to let total API beginners have fun with it.Once the API chosen, I listed the API calls the attendees would have to do and the questions I would ask them during the “API call exercises” part of the session. I was almost done but I wanted to show how this Foreign Exchange Rate API could be used in a simple application along with another API (to show how by combining easily simple API you can do interesting stuff).Build an all-in-one demo applicationSo, I wrote a simple webapp (using JS Fiddle and Github pages by the way) combining the Foreign Exchange Rate API and the REST Countries API which provide information about countries such as languages, borders, flags, … It consists in a simple form that let users convert an amount in a source currency to a target currency. It also shows trivia about the selected currencies such as the countries which use them and their flags. The available currencies and exchange rate come from the exchange rate API and the country/currency relationship and country flag come from REST country API.And then I thought it would be interesting to show the actual API calls that were triggered when using the web application. I first though to use the browser’s developer tools. Indeed, using the network panel and filtering to XHR request, you can see the API calls made by the JavaScript code. But again, that would have been too complex just like showing them JSFiddle (IMHO).                                      Filtering XHR request in browser dev tools? Too scary!          So I came to the idea of adding an API call log directly within the web application. This log shows which called are done and why. API calls are log during the webpage initial loading but also when users interact with it. On each new action, the new call are added to the top of the list and the previous calls are shown in light grey.                                      Demo application including detailed API call log? Far more non-developers friendly!          ConclusionSo I was totally ready for this special 101 session with a bonus hands-on. And hopefully everything went very well, but even if that presentation was very important (because of the very important people in the audience), I will remember more its preparation as it helped me (re)discover very interesting things. Preparing this unusual session reminded me that whatever you do: beware the context before making any choice. I’m also quite happy to have find this idea of building an all-in-one demo application which explain what happens behind the hood and will reuse and expand this concept in the future.PS: Oh, and I almost forgot … it also reminded me how so many tools are unable to deal with corporate proxies easily. I may write something about that one day."
},{
    "id": "49",
    "type": "post",
    "title": "API Design Tips And Tricks - What if consumers can't do PATCH, PUT or DELETE?",
    "url": "https://apihandyman.io/api-design-tips-and-tricks-what-if-consumers-cant-do-patch-put-or-delete/",
    "banner": "https://apihandyman.io/images/api-design-tips-and-tricks-what-if-consumers-cant-do-patch-put-or-delete/banner.png",
    "description": "There are quite many APIs out there taking advantage of all standard HTTP methods (GET, POST, PATCH, PUT and DELETE). Unfortunately, there are still some cases where consumers can’t use them all. As far as I know, GET and POST do not cause any problem at all. But as an API provider, do not take for granted that DELETE, PUT and the more dreaded PATCH HTTP methods can always be used by your consumers. I encountered this problem several times throughout the years and no later than a few weeks ago. Let’s see why and how to solve this problem.",
    "body": "There are quite many APIs out there taking advantage of all standard HTTP methods (GET, POST, PATCH, PUT and DELETE). Unfortunately, there are still some cases where consumers can’t use them all. As far as I know, GET and POST do not cause any problem at all. But as an API provider, do not take for granted that DELETE, PUT and the more dreaded PATCH HTTP methods can always be used by your consumers. I encountered this problem several times throughout the years and no later than a few weeks ago. Let’s see why and how to solve this problem.What could prevent consumers from using PUT, PATCH or DELETE?I encountered this problem several times, the first one was probably around 2012 and the last one in 2019 a few weeks ago (hence this post). These two experiences, reflect the two possible causes of the inability of consumers to use HTTP methods such as PATCH, PUT or DELETE: network or framework limitations.Network limitationsThe first time I encountered such problem, it was around 2012. I was building my first “RESTish” API. At that time I was a total beginner regarding REST APIs (and made quite a few mistakes, but that’s another story). I had read a some books and blog posts about such APIs and discovered that you had to use the HTTP semantic when designing them. So, here I was, carefully choosing the adequate HTTP method depending on what I wanted to do: GET to read something, POST to create something, PUT to replace/update something and DELETE to delete something (yep, I did not used PATCH at that time).This API was supposed to be used by various consumers including a website built by another team in another company belonging to the same group as mine. This consumer had to pass through various internal network zones of the group to access our APIs. Unfortunately, on their side all their reverse proxies and firewalls only allowed the use of GET and POST. Why? Because for a very long time that was all what websites (or most HTTP based software) needed to operate, so anything else was forbidden (usually for security purpose).Framework limitationsThe last time, I encountered this problem was a few weeks ago in 2019. I am now a little bit more experienced (I even wrote a book about web API design, but that’s another story you can read here) and a part of my job is helping people design APIs.One of the team I’m working with is building an API that is supposed to be used in some famous SAAS CRM solution. As their API deals with some updates, it uses the PATCH HTTP method as said in our API design guidelines. Unfortunately, the team in charge of calling this API from the SAAS solution encountered some unexpected problems. The SAAS solution’s development framework only knows GET, POST, PUT and DELETE, it’s impossible to make a call to an external API using PATCH.Some other cases of “framework limitations” I encountered were due to the use of ancient on-premise COTS (Commercial-Off-The-Shelf) facing the same problem as this SAAS solution and also the use of old browsers.Whatever the reason, that’s a real problem: some consumers may simply be unable to use all of the API features. There are two ways to solve the problem: solving the root cause and if that is not possible find a design workaround.First solution: solve the root causeSolving the root cause regarding the network limitations shouldn’t be a problem. Indeed, I think that it is probably not a problem anymore, so there’s nothing to solve. But just in case and more for historical purpose, here’s how to handle it. There are probably two categories of people to talk to: the security people and the network people. Back in 2012, when I was building my first API, I encountered the same problem as my colleagues. Our mobile application couldn’t use our brand new API because our reverse proxies also only allowed GET and POST. To solve this problem, I just had to explain to those people that our mobile application actually needed PUT and DELETE to work properly and show them how other companies were doing to demystify the “new” HTTP methods. Thanks to that, I learned one important thing: before considering any design modification due to some contextual problems, I always check if the problem cannot be solve.Unfortunately, my 2012 fellow colleagues, didn’t had the same chance. Modifying the reverse proxies configuration was more complicated for them and would have took a longer time than what we had. And more recently, my colleagues also couldn’t fix the root cause: the framework’s bug or missing feature has been known by the SAAS company for at least 3 years and still hasn’t been solve. So I had to find a design workaround.Last resort solution: find a design workaroundHow to modify an API design which takes advantage of the HTTP method semantics in order to be used by consumers which cannot use all the API’s HTTP method? There are two ways to do so: the bad one and the clever one.The bad way of modifying the API design to solve this problem would be to simply get rid of the HTTP semantic and simply use POST for everything (or possibly GET to read and POST for the rest). Not using HTTP method semantic is not the problem here, the problem is to heavily modify a design for only a handful of consumers. In Star Trek II The Wrath of Khan (1982), Mr Spock says “Logic clearly dictates that the needs of the many outweigh the needs of the few.”, and he is totally right (at least when it comes to designing APIs). It means, that to solve this problem, the design must be modified in a sufficiently clever way that allows the handful of HTTP restricted consumers to use the API without bothering the vast majority which can shamelessly use all of HTTP methods.So, let’s do it the clever way. The minimal set of HTTP methods that can be used by any HTTP consumer is composed of GET and POST. As we need to find a replacement to methods such as PUT, PATCH or DELETE which are not safe (they may change resources), the only possible solution is to use POST to simulate them (because GET is safe). In order to be able to make the difference between a regular POST and a POST simulating let’s say a PATCH request, a parameter indicating the real HTTP method must be provided. This can be done by providing a HTTP header named X-HTTP-Method, X-Method-Override or X-HTTP-Method-Override (I prefer the last one, it seems to be used more than the others) which value is PATCH.A consumer which is not restricted in its use of HTTP methods will do a regular PATCH request as follows:PATCH /some-resources/some-id HTTP/1.1{  \"some\": \"data\"}A consumer which cannot do a PATCH request, will send a POST request along with the parameter stating the “true” HTTP method to be used:POST /some-resources/some-id HTTP/1.1X-HTTP-Method-Override: PATCH{  \"some\": \"data\"}And now, what if I tell you that some (really annoying) consumers limited to GET and POST are also unable to send custom HTTP headers? Better be ready to also allow them to pass the overridden HTTP method as a query parameter such as _httpMethod or _method.POST /some-resources/some-id?_httpMethod=PATCH HTTP/1.1{  \"some\": \"data\"}Such design trick is implemented in many APIs and products offering APIs, but don’t be fooled by its simplicity, there are some consequences that you must be aware of.ConsequencesUsing this trick will have consequences on security, API gateway configuration, documentation and logs.SecurityFirst above all: security. Let’s say that an API provides the following operations:  POST /resources which creates some resource, requires the create Oauth scope  DELETE /resources which allows to massively delete some resources, requires the delete Oauth scopeIf the HTTP method override is implemented without caution (at the actual implementation or on the API gateway securing the API), a consumer which only has the create scope could unduly massively delete resources by sending a POST /resources?_httpMethod=DELETE request. So do not forget that security controls must be adapted when adding such mechanism: when an overridden call comes, the relevant security control must be made (in this case, check if the consumer has the delete scope).API Gateway configurationIf an API gateway sits in front of the API’s implementation (to deal with high level security), it is usually configured by providing the sets of available operation (as an OpenAPI file if the API gateway provider is smart). If you need to use the HTTP method override trick, you’ll have to update your configuration.Let’s says the API provides the following operations:  POST /resources  DELETE /resources  PUT /resources/{resourceId}In that case, to support HTTP method override, you’ll need to declare:  A modified POST /resources with the additional query (_httpParam for example) and/or header (X-HTTP-Method-Override) parameters to handle overridden DELETE /resources requests  An unmodified DELETE /resources  An unmodified PUT /resources/{resourceId}  A new POST /resources/{resourceId} to handle overridden PUT /resources/{resourceId} requestsNote that security and gateway configuration could be simplified by implementing directly the trick at the gateway level once and for all. That way, backend API implementation would not have to deal with that (I’ll probably make a post about dos and don’ts or API gateways).LogsSuch design modification will obviously impacts your API calls logs and dashboards, you’ll have to separate true POST requests from the overridden PATCH, PUT and DELETE ones or find a way to log them cleverly to avoid doing so. Note that you should not totally hide these overridden request, it is always useful to know if this feature is actually used and how.DocumentationAnd finally do not forget to update your documentation. The better is to fully explain the trick once and for all and add links to this explanation when needed. If your reference documentation relies on the same OpenAPI file used for your gateway, you should get rid of trick-specific parameters and operations (the ones you add for the gateway configuration for example) to keep it readable.Conclusion: always analyze consumers contextsWhile a bit annoying, such a problem teaches us a good lesson: always analyze consumers contexts in order to propose an accurate design.And if you wonder what this post banner means: it’s a toy version of the french Peugeot 405 made by french toy company Majorette. The HTTP status code 405 means Method not allowed."
},{
    "id": "50",
    "type": "post",
    "title": "Few things I learned writing The Design of Web APIs",
    "url": "https://apihandyman.io/few-things-i-learned-writing-the-design-of-web-apis/",
    "banner": "https://apihandyman.io/images/few-things-i-learned-writing-the-design-of-web-apis/banner.png",
    "description": "At last, my book The Design of Web APIs is finished and printed! I gradually got back to a “normal” life since the end of summer as the book entered in its production phase, but it was only when I received the printed copies two weeks ago that I had the feeling that this adventure was really over. And then holding the book in my hands, I wondered if it was worth having spent two years of my life on it, what did I learn spending almost all my free time working on this book? That sounded like a good topic to revive the API Handyman blog.",
    "body": "At last, my book The Design of Web APIs is finished and printed! I gradually got back to a “normal” life since the end of summer as the book entered in its production phase, but it was only when I received the printed copies two weeks ago that I had the feeling that this adventure was really over. And then holding the book in my hands, I wondered if it was worth having spent two years of my life on it, what did I learn spending almost all my free time working on this book? That sounded like a good topic to revive the API Handyman blog.The Design of Web APIsThe Design of Web APIs is my first book. Before that, I have been blogging for 2 years before being contacted by Manning to write a book about the OpenAPI Specification. It’s an interesting topic (I spend almost a year writing a extensive tutorial on version 2) but I had other ideas in mind at that time: The Design of Everyday APIs. I wanted to write a book that teaches API design principles and not a book about a given technology, I wanted to make a sort of API design version of The Design of Everyday Things by Don Norman. I discovered this book thanks to Mike Amundsen, it changed the way I envision software.  The Design of Everyday Things is a best-selling book by cognitive scientist and usability engineer Donald Norman about how design serves as the communication between object and user, and how to optimize that conduit of communication in order to make the experience of using the object pleasurable. One of the main premises of the book is that although people are often keen to blame themselves when objects appear to malfunction, it is not the fault of the user but rather the lack of intuitive guidance that should be present in the design. (Wikipedia)The Design of Everyday APIs was only a working title, I never have been comfortable with it as I had the feeling that I was borrowing the fame of Don Norman’s book. Hopefully it was changed to the more simple and obvious The Design of Web APIs.The title is not the only thing that has changed during the creation of this book. The table of content and the content itself has greatly evolve during these two years to become the book I’m so proud of. But more important, I changed by learning a few things.How to actually write a technical book (or other things)I’m glad I made this book with a publisher and did not self-publish it because the result would probably have been a terrible mess … if I actually finished it. Having a (good) publisher was great because the people working there helped me in many ways like, for example, fixing typos, challenging the book’s content or gently asking me when I planned to finish the next chapter and so help me keeping the pace. But more important, if I know quite a few things about API design and I like story telling, I didn’t knew how to actually write a book and my publisher taught me to do so. I’m not a professional writer, I may even be wrong, there are probably thousands of books and blog posts about writing, but here’s what I retain after writing this book (and what I try to reuse now when writing anything):First define what you will actually talk about in your book. To do so, ask yourself:  Who are your readers?  What do they need to know/do before reading the book?  What will they learn/be able to do by reading it?Once the book’s objective is defined, write the table of content (ToC). It is the backbone of the book, your battle plan. It should tell a story that will help readers to achieve the book’s objective.The first versions can be rough without going to deep into details, just think about the main steps of the story. You’ll fill the details by working on each chapter and maybe adjust the ToC.Then for each chapter:  Make the elevator pitch of why readers should care about this chapter’s content. It shouldn’t take more than a few sentences.  List what readers need to know/do before reading it, basically topics from previous chapters. It may help to spot missed topics.  List new concept taught  List the examples used to explain the new concepts  Sketch the main diagrams that will be usedIt’s not that easy to do, don’t be afraid if it takes time but if if really doesn’t work, maybe you should get rid of this chapter and rethink your ToC. With all these elements, it’s easier to write the chapter: once you have a good view the content, you “only” need to focus on how to tell the story in an entertaining way. Without them, be ready to face the white page syndrome and rewrite the chapter endlessly.There’s more than what (you think) you know about the book’s topicBy writing a 400 pages book about API design, I ending by knowing far more about this topic than what I knew before starting it. This is not specific to book’s writing, I already noticed that after I started to blog.Writing a book about API design forced me to actually list all the topics that readers need to be aware of and I “discovered” some topics I didn’t care much about before starting the book. I had to deeply investigate topics these topics but also ones I thought I knew. And most interesting, I had to find new ways of explaining things, finding examples and drawing diagrams while preparing chapters was of great help to do so.How to receive and provide feedbackI received a lot of feedback during the book’s writing. I worked with a development editor and a technical editor who provided feedback on each chapter. There have been 3 readers reviews made on the first third (6 readers), second third (10 readers) and then first complete version of the book (16 readers). There were comments on the forum/live book. And I also got feedback from my friends and colleagues.The two first readers reviews, especially the second one, left me totally depressed. It was really hard to deal with them because some of them were negative. I even felt that some were too harsh if not mean. I usually consider myself sufficiently adult to be able to get some negative feedback as long as it is argued and there can be a discussion. But, when you get feedback from a dozen readers at once and there is no possible discussion with the PDF file summing up their reviews, that’s really hard to manage, at least for me. Hopefully, I could get beyond that thanks to two things.First, I step back and objectively analyze the reviews to split them in smaller elements. Frankly, I don’t remember how I came to do that, probably because my development editor told me to do so or because I usually work like that. But I looked at the reviews and identified every good and bad point, check how many readers talk about them. Doing so I realized that it was not that bad and, even if that always hurt a bit, I agreed with most of the identified problems. I also realized that there was actually only one or two shitty reviewers (sorry, these persons may probably not actually be like that but this is how I felt based on the review) and this lead to my second point.So, the second thing that help me to go on after the reviews is that I’m lucky to know some authors who have been there and one of them gave me a really good advice. It could be summarized as “you under no obligation to give a shit about what people say”. Listen to what people say, take what is of interest for you and your book and leave the rest. And if they are not happy with that, tell them to write their own book.After these reviews, I realized that I may have been one of these assholes myself. So, I’m really happy that they taught me how to provide better feedback, especially when not face to face, and (I hope) not to be an asshole anymore when providing feedback.Be more confidentHopefully, my development and technical editors feedback were more constructive and encouraging, also were comments from my trusted friends and colleagues. That really gave me confidence. I realized that what I was creating was really good (and I just realized that I became confident enough to actually write that the book is good). Besides having good feedback, I got even more confident seeing how all the book’s pieces fit together so well. And being confident about the book’s content made me more confident about what I do in my daily job, that’s priceless.Trust, but verifyWhen you finish to write a book, the work is not over. The final phase is called the production phase. It mostly deals with copy-editing, graphics-editing, typesetting.  Copy-editing consist in fixing typos, grammar and vocabulary and also ensure a certain consistency in your writing. Note that in my case there was a previous ESL (english as second language) copy-editing phase to fix my frenglish. You must check every single modification made to YOUR text in order to be sure that what is written is ok for YOU. Some modifications may not make sense at all or you may simply not like them. It is your right to not accept such modification.  Graphics-editing is copy-editing for figures. Their texts will be copy-edited and their design may be more or less modified depending on their quality/style/size. In my case, my figures were only finally slightly modified but there has been some bug in the process. For an unknown reason, my figures were being totally remade in a new style that I totally hated. Hopefully, I noticed it and made that stopped. Everyone can make mistakes, that is why there are verifications phases, so don’t take them lightly even if you trust the third-parties modifying your work.  My definition of typesetting is: ajdusting words (split them sometime) and figure positions to avoid empty spaces. If you ever wondered why in some books figures seem in awkward places, in my experience, that is due to typesetting. I had to request a few modifications, but taking typesetting contraints into consideration, in order to avoid such problems on a few figures.So, you can trust, be never forget to verify. Even if it is hard and boring as hell, you must be very careful when your book is modified by third-parties. You have to exhaustively check ALL modifications. Be confident and never refrain yourself to say no if something seem wrong for you.Find a balance between the book and the restFinding a balance between the book and the rest, especially my family is something that I didn’t do so well at the beginning. If you do write a book, consider defined precisely when you work on it and keep time for your family and possibly for other activities (like reading, playing video games or playing the guitar in my case). That will keep everyone happy (including you) and increase your productivity when writing.Never complain when reading others booksAnd finally, now that I know how hard it is to write a book (and especially to spot all those fucking typos), I will never complain again when I read others books (but I may try to provide some useful and friendly feedback).A new beginningDon’t know if so many people will find this post interesting, but I needed to write it to not forget what I’ve been through. Know that I never regretted starting to write blog posts or the book, so maybe you should think about writing too. Whatever, I’m back on the blog, so stay tune for more API related posts."
},{
    "id": "51",
    "type": "post",
    "title": "Explore the OpenAPI Specification 3.0 with the OpenAPI Map",
    "url": "https://apihandyman.io/explore-the-openapi-specification-3.0-with-the-openapi-map/",
    "banner": "https://apihandyman.io/images/explore-the-openapi-specification-3.0-with-the-openapi-map/banner.png",
    "description": "So you want to explore in depth the OpenAPI Specification version 3.0? You should take the OpenAPI Map with you!",
    "body": "So you want to explore in depth the OpenAPI Specification version 3.0? You should take the OpenAPI Map with you!The OpenAPI Specification Visual Documentation is dead, long live the OpenAPI Map! Very special thanks to Marsh Gardiner for helping me find this name.What is the OpenAPI Map?Just in case you missed previous releases, the OpenAPI Map is a representation of the OpenAPI Specification documentation as a tree. Using it, you can see how an OpenAPI document is organized and discover all OpenAPI objects and properties dark secrets.                                      OpenAPI Map          Updated 3.0.0-rc0 to 3.0Besides changing the tool’s name, I have replaced the OAS 3.0.0-rc0 version by 3.0 (3.0.1 precisely). You can now fully explore the OpenAPI Specification 3.0 version. This update from 3.0.0-rc0 to 3.0 was a bit longer than expected. There were quite some changes between the early 3.0.0-rc0 version and 3.0 official release. The version 3.0 is now fully documented and includes a complete changelog from version 2.0.Other enhancements  The Open API Map shows version 3.0 by default  Version 2.0 is still available via the navigation bar and you can now even access it directly using this link: http://openapi-map.apihandyman.io/?version=2.0.  Mandatory properties labels are now in red, no more need to pass mouse over a property to see it Issue #10.Source available on GithubYou can fork this project on github. I have updated the readme in order to help people understand how it works but it may need some further updates. So do not hesite to tell me if you need help to use it."
},{
    "id": "52",
    "type": "post",
    "title": "How public web APIs raise software bar",
    "url": "https://apihandyman.io/how-public-web-apis-raise-software-bar/",
    "banner": "https://apihandyman.io/images/how-public-web-apis-raise-software-bar/banner.png",
    "description": "While answering some question on my Design of Web APIs book’s forum, I wrote: Now that I have seen brilliant Web APIs that can be used so easily because of their design but also the overall experience some can provide (the famous “DX”) I have become far more demanding and challenging with software in general Yes. Public web APIs definitely raise software bar. The whole software industry should take example on them …",
    "body": "While answering some question on my Design of Web APIs book’s forum, I wrote:  Now that I have seen brilliant Web APIs that can be used so easily because of their design but also the overall experience some can provide (the famous “DX”) I have become far more demanding and challenging with software in generalYes. Public web APIs definitely raise software bar. The whole software industry should take example on them … The Ideal world of public web APIsI have been tinkering with web services and web APIs for a while now and it’s really interesting how the quite technical concept of remote Application Programming Interface moved my perception of sofware from a purely technical vision to something more human centered. I switched from code software that solve problems to design software that people use to fulfill their needs. How some companies envision providing public web APIs is even pushing this vision into design software that people will love to use.How is this possible?Willingly or in order to make profit or both, we don’t care, these companies design APIs that you can understand at first sight and use easily to do what you want. But that’s not all, the API comes with all needed material in order to help you seamlessly; reference documentation, tutorial, sandbox, ready to use examples, sdks, … Everything is designed in order to provide a wonderful experience with a minimal effort. Sometimes, this experience is so perfect, that you are just happy when using this API. Sometimes this experience so invisible that you feel incredibly smart because the whole system let you think that you use it instinctively.Both provider and consumer benefits from such experience. Consumers are autonomous, don’t lose time and money to use the API. They are so happy that may even promote the solution. Providers gain easily customers and lessen the need of support (or at least can focus on support where it’s really needed).Of course, not all public APIs provide such experience. And in some other domains of the software industry, we are at light years of that…The crude reality of not so dark corners of the software industrySome words about me and my job: I am an architect in the banking industry…  Nobody expects the Architect Inquisition!… but not the dreaded enterprise architect living in his ivory tower. Throwing utopian or unrealistic edict. Burning the heretics who dare to not apply them. No, definitely not that kind. I come from the trenches, I have been a developer, a project manager, a developer team manager. Now as an architect from the trenches, I have to deal with real world problems and find real world solutions. Always striking a balance between the sanity of our IT system, people building it, people running it and people using it and of course … money.In my daily job, I work with a motley collection of software solutions: homemade, open source, vendor ones, as a service, on premise, … All these software can be roughly separated in two categories: the software I choose on a shelf and the software I design.To tell the truth, I’m getting tired of software solutions I have to choose on a shelf that are only created to solve problems and not designed for people to fullfil their needs.The gap between some enterprise grade software solutions and some (ideal) public web APIs is sometimes so wide that the Hubble telescope would probably not be able to see something from one end to the other. The cost of using some crappy designed solution is sometime really frightening.When I choose a software, I mainly these criterias:  Does it fullfil our business needs?  How is it complicated/easy to install, run and use it?  Does it provide an API? what’s its quality?  How does look like its documentation?If the first question is usually not a problem, the others are too often problematic. And this is usually a huge source of problems, time losed and money losed.A open letter to enterprise grade vendor solutionsDear enterprise grade software solution vendors,When I use a public web API, I don’t know what’s happening behind the interface and I don’t care. I can also use it easiliy. When I have to install a software on premise, I would like to have something equivalent. Of course I may have to install something and do some configuration. But please, I don’t want to be an expert of your product implementation nor its installation. I don’t want to lose months to install you product. Do you know that you can automate many things when you use software? Do you know that now you can even package your solution to provide “one click” installation in some cloud services?When I use a public web API, you know what? I have an API to use. I would be glad if your product provide one. Having an API would definitely ease the job of making my motley collection of software work together.When I use a public web API, I have some decent and sometimes even pleasant documentation to understand how to use it on my own. I almost never have to talk to someone to get help. So, just stop to provide totally not user friendly, huge and useless documentation that you wouldn’t even use yourself. Stop selling support that you cannot afford. I have seen some product coming with a 300 pages PDF as documentation. Yes 300 pages. And that’s not the most fun, this document contained some code samples… some of them 20 pages long. Unreadable. Unusable.When I use a public web API, I sometimes can use it instinctively, because its design conforms to some common pratices. If your solution provides an API (which is a good thing), you would be wise to stick to these common practices. I do not want to have to learn you very smart but very specific and totally different way of thinking to use your API.When I use a public web API, it may evolve. Such evolution may bring some breaking change. But I am warned and I have time to handle them. I can even use the old and new version at the same time. Some provider even support all past versions seamlessly. I would love do the same thing with your software.Sincerely,Your not future customer.There’s light at the end of the tunnelIs this situation hopeless? No.In an ideal world, I would get rid of all these on premise shitty enterprise proprietary software and use only software as a service with API solutions (the brilliant ones, offering an outstanding experience, of course).But we do not live in an ideal and simple world. If such solutions to your need exist, some obstables may prevent its use: regulations, security, sensitive data, performance, legacy systems…So beside this solution, the light at the end of the tunnel may come thanks to three things.  First, as a software solutions designer myself, I now try to promote and create human centered solutions that are simple to build, deploy and operate by following what I’ve seen in the public web API space. I try to take into account all users of such solutions from dev to end user and also ops.  Second, when I choose software solutions, I always provide constructive feedback in order to help vendors enhance their solutions whether I select or reject them.  Third, some vendors start to understand by themselves, like I did, that creating human centered solutions is worth the cost for both vendor and customer.But is this really new?Fundamentally, what we see in the public web APIs space is only what should be done with any software solution and even with any crafted thing since the beginning of all things.Would you willingly buy a vegetable peeler that comes with a 200 pages user manual, needs 2 months for installation and is a total pain in the ass to use?Definitely no.Then why have we considered such experience totally normal with software for decades?So, yes public web APIs raise the software bar, but only to the level it should have been since the beginning of time."
},{
    "id": "53",
    "type": "post",
    "title": "The story behind The Design of Web APIs book",
    "url": "https://apihandyman.io/the-story-behind-the-design-of-everyday-apis-book/",
    "banner": "https://apihandyman.io/images/the-story-behind-the-design-of-everyday-apis-book/banner.png",
    "description": "I’m thrilled to announce that I’m writing a book about API design: The Design of Everyday APIs (edit: the book has been renamed The Design of Web APIs since this post has been written). This book is published by Manning Publications and the first two chapters are now available on the Manning Early Access Program or MEAP (affiliate link, use fcclauret discount code to get 37% off). This book is for everyone who wants to learn API design. But, what’s the story behind this book about API design? To answer this question, let’s talk about my other passion: guitar.",
    "body": "I’m thrilled to announce that I’m writing a book about API design: The Design of Everyday APIs (edit: the book has been renamed The Design of Web APIs since this post has been written). This book is published by Manning Publications and the first two chapters are now available on the Manning Early Access Program or MEAP (affiliate link, use fcclauret discount code to get 37% off). This book is for everyone who wants to learn API design.But, what’s the story behind this book about API design? To answer this question, let’s talk about my other passion: guitar.                                       Guitar tabs          I have been playing the guitar for quite a long time. I’m definitely not an outstanding guitar player, I do that just for fun. Even if I have basic knowledge of solfeggio, I mostly use tablatures (or tabs) to learn to play songs. The guitar strings are represented by lines. And numbers on the lines indicate where to put fingers on the fret board. Pretty simple. I can play any song. Well, as long as my fingers dexterity allows it. So, I can play almost any song without even kwnowing which musical note I’m doing. But it can take me a long time to master songs, because I mostly do not get immediately how it works. I cannot play a song without a tablature by just listening to it. I’m also unable to compose music, I’m unable to improvise. And if I want to play another musical instrument like the piano, I would have to relearn everything. All this because I simply (but with dexterity!) move my fingers on a guitar fretboard without really understanding what I’m doing and why. When you really know music, it’s quite different. A friend of mine is a music teacher. He knows everything about solfeggio and music theory. He can improvise and compose. He can play any musical instrument as long as he understand how doing notes.But what has this to do with API design?    use fcclauret discount code to get 37% off (affiliate link)I’ve been doing distributed software and working with web services and web APIs for a long time now, designing, building, using and providing them. Like many others, I’ve learned many things from the trenches about API design by practicing … and doing many mistakes. Mistakes, that I could have probably easily avoided if I had been warned. I have discovered the not so obvious scope of the API designer’s job and you know what? Choosing HTTP methods and designing URLs is only a part of it. I have also learned how to design APIs that do exactly what they have been created for. And I have also learned how to shape APIs in order to make them easy-to-understand and easy-to-use.But I have also learned something beyond these technical tips and tricks. I have learned what really is an API and what it means to design it.Knowing that /library/books/the-design-of-everyday-apis/chapters is a good a way of designing some REST resource’s URL is important. Knowing that simply returning a 400 Bad Request HTTP status code is not enough is important. Knowing that content negociation is a solution to some use case is important. But knowing and understanding the true reasons why we should or shouldn’t design API like this or that is far more important. This is guitar tablature vs solfeggio and music theory. Would you be able to improvise when facing a new use case? What would you do when designing a SOAP web services (yes, some people still have to do that), a gRPC API or whatever will come in the future?I could have been a better API designer faster if I had understood earlier the true essence of API design. There are reasons why designing APIs in certain ways gives outstanding results. Understanding the reasons behind techniques and tips that make APIs great is far more important than just knowing them, because it can help to face any situation and design any type of API. Just like being able to play any musical instrument, improvise and compose.                                      A quite cryptic interface          But is it hard to master the API design solfeggio? Hopefully not at all! The API design solfeggio is quite simple to grasp as long as you understand what really is an API and how you can find inspiration from everyday objects.OK, an API is an Application Programming Interface, but it’s first and foremost an interface that people will use in their software to interact with your software.APIs are interfaces like any others. Look at this UDRC 1138 control panel, its interface. What could be this device’s purpose? How use it? hard to guess thanks to its poorly designed interface. Think about the many times you have been puzzled or you have grumbled when using a everyday object like a door, a microwave oven, a remote control, a toy, a web site, a mobile application because its design was flawed. Think about the many times you did not complain and were even quite happy using something. What seems ridiculous for everyday objects interfaces is as ridiculous for application programming interface. And the opposite is quite true, what works for everyday objects interfaces works for APIs.So, while The Design of Everyday APIs (edit: the book has been renamed The Design of Web APIs since this post has been written) book is a practical one showing every aspects of API design and many techniques, tips and tricks to design great APIs. It will also explain why you should design APIs that way and therefore, I hope, give you the eye of the API designer.I hope you’ll enjoy this book and find it useful to design your everyday APIs and build an API designer mindset. As you can read it on MEAP (affiliate link, use fcclauret discount code to get 37% off) while it is written, I look forward to your feedbacks on MEAP forum."
},{
    "id": "54",
    "type": "post",
    "title": "API Styleguide, the Lord of API Designs",
    "url": "https://apihandyman.io/api-styleguide-the-lord-of-api-designs/",
    "banner": "https://apihandyman.io/images/api-styleguide-the-lord-of-api-designs/banner.png",
    "description": "Join Frodo, Gollum and Gandalf on an epic API design adventure. In this session, based on my own experience defining and sharing API design common practices in my company and based on the API styles guides that I have collected on apistylebook.com, we will discover why we desperately need API style guides and how they can or cannot help us create a smooth API surface for a company.",
    "body": "Join Frodo, Gollum and Gandalf on an epic API design adventure. In this session, based on my own experience defining and sharing API design common practices in my company and based on the API styles guides that I have collected on apistylebook.com, we will discover why we desperately need API style guides and how they can or cannot help us create a smooth API surface for a company.Very special thanks to Mister Lapin for designing my T-shirt and Kristof Van Tomme for recording the video with my phone.AbstractEvery company’s API surface grows irremediably. More and more APIs means more and more people designing APIs, therefore keeping a company’s API surface consistent is quite a challenge. Failing this challenge may lead to a less efficient and even be counterproductive.In this session, based on my own experience defining and sharing API design common practices in my company and based on the API styles guides that I have collected on the API Stylebook, we will discover why we desperately need API style guides, what we can put in them, how to build them and how they can or cannot help us and our fellow API designers to create together a flawless consistent API surface for our company. We will also see how API style guides could be used in the API ecosystem with tools such as the OpenAPI specification and API design tools to ensure that their rules are followed retrospectively and preemptively.Video                                                This content is hosted on youtube.com.                By showing this third party content you accept YouTube (Google)'s                     privacy policy.                                                    Show third party content                                                                    Remember my choice                        (can be changed in privacy settings)                                                                                      SlidesDownload PDFOpen PDF    "
},{
    "id": "55",
    "type": "post",
    "title": "...And GraphQL for all?",
    "url": "https://apihandyman.io/graphql-for-all-talk-video-on-infoq/",
    "banner": "https://apihandyman.io/images/graphql-for-all-talk-video-on-infoq/banner.png",
    "description": "GraphQL is new. GraphQL is cool. Look! Github dumped REST for it! We MUST do it too! Well, why not. GraphQL could be a great tool, but like any tool, you don&#39;t choose it &quot;just because&quot;.You choose it because it solves a problem in a given context. You choose it knowing its strengths and weaknesses. During this session, while discovering what is GraphQL we will see what REST API providers should think about before blindly dumping REST for it",
    "body": "My talk …And GraphQL for all? A few things to think about before blindly dumping REST for GraphQL which I gave at API Days Paris 2016 last December was recorded and the video is now available on InfoQ.You can also read my write up here on the blog.AbstractGraphQL is new. GraphQL is cool. Look! Github dumped REST for it! We MUST do it too! Well, why not. GraphQL could be a great tool, but like any tool, you don’t choose it “just because”.You choose it because it solves a problem in a given context. You choose it knowing its strengths and weaknesses.During this session, while discovering what is GraphQL we will see what REST API providers should think about before blindly dumping REST for it. From design and implementation to pricing model and analytics down to developers experience and implementations, choosing an API design style will have impact on the whole API lifecycle. Therefore, this choice must be an enligthned one and not based on simple beliefs.VideoAvailable on InfoQ.SlidesDownload PDFOpen PDF    "
},{
    "id": "56",
    "type": "post",
    "title": "Deliveroo API Design Guidelines added to the API Stylebook",
    "url": "https://apihandyman.io/deliveroo-api-design-guidelines-added-to-the-api-stylebook/",
    "banner": "https://apihandyman.io/images/deliveroo-api-design-guidelines-added-to-the-api-stylebook/banner.png",
    "description": "I’ve added the Deliveroo API Design Guidelines to the API Stylebook. These guidelines are definitely a MUST read for any API designer. To discover this API design guide and a short review, let’s go to the API Stylebook blog.",
    "body": "I’ve added the Deliveroo API Design Guidelines to the API Stylebook.  These guidelines are definitely a MUST read for any API designer.To discover this API design guide and a short review, let’s go to the API Stylebook blog."
},{
    "id": "57",
    "type": "post",
    "title": "API Design Tips And Tricks - Getting, creating, updating or deleting multiple resources in one API call",
    "url": "https://apihandyman.io/api-design-tips-and-tricks-getting-creating-updating-or-deleting-multiple-resources-in-one-api-call/",
    "banner": "https://apihandyman.io/images/api-design-tips-and-tricks-getting-creating-updating-or-deleting-multiple-resources-in-one-api-call/banner.png",
    "description": "Getting, creating, updating or deleting multiple resources in a single API call is a common need in REST APIs. But how to achieve that in a consistent way accomodating how we work with a single resource and REST principles? This is what we’ll see in this post.",
    "body": "Getting, creating, updating or deleting multiple resources in a single API call is a common need in REST APIs. But how to achieve that in a consistent way accomodating how we work with a single resource and REST principles? This is what we’ll see in this post.Working with a single resourceBefore talking about how to work with multiple resources all at once, let’s see how to handle a single resource with a REST API.Creating a resourceThe common way of creating a resource is to do a POST request on /resources. The body of the request containing the resource to create.                                                                                        POST /resources HTTP/1.1{  &quot;some&quot;: &quot;some data&quot;,  &quot;other&quot;: &quot;some other data&quot;}  If everything is OK and the resource created, the response’s status to this request will be a 201 Created and the response’s body will contain at least the ID (id) or the URL/URI (href) of the created resources. It may also contain the full resource itself.                                                                                        HTTP/1.1 201 Created{  &quot;id&quot;: &quot;ID&quot;,  &quot;href&quot;: &quot;/resources/ID&quot;,  &quot;some&quot;: &quot;some data&quot;,  &quot;other&quot;: &quot;some other data&quot;}  If there’s something wrong, the response’s status will be an error, for example a 400 Bad Request because of some missing data and the response’s body will contain information about the error.                                                                                        HTTP/1.1 400 Bad Request{  &quot;message&quot;: &quot;missing some data&quot; }  Getting a resourceOnce created a resource can be accessed with a GET /resources/ID request. If everything is OK, the server will return a 200 Accepted and the resource. If there’s something wrong, it will return an error like 404 Not Found if the resource does not exist or a 403 Forbidden if the user is not allowed to access that resource.Updating a resourceA PATCH /resources/ID request will update partially a resource:                                                                                        PATCH /resources HTTP/1.1{  &quot;other&quot;: &quot;modified data&quot;}  If everything is OK, the server will return a OK status like 200 Accepted, and just like with the POST request, the body may contain the updated resource.                                                                                        HTTP/1.1 200 Accepted{  &quot;id&quot;: &quot;ID&quot;,  &quot;href&quot;: &quot;/resources/ID&quot;,  &quot;some&quot;: &quot;some data&quot;,  &quot;other&quot;: &quot;modified data&quot;}  If there’s a problem, the server will return an error. This error could be, for example, a 404 Not Found due to an invalid ID.                                                                                        HTTP/1.1 404 Not Found{  &quot;message&quot;: &quot;Resource &lt;ID&gt; not found&quot; }  Replacing or creating a resourceWhile a PATCH /resources/ID updates partially a resource, a PUT /resources/ID one will replace the resource. It may also create a new resource with the provided ID if it does not exist (and if it is allowed).                                                                                        PUT /resources/ID HTTP/1.1{  &quot;some&quot;: &quot;some new data&quot;,  &quot;other&quot;: &quot;some other new data&quot;}  If everything is OK, the server will return a OK status. Depending on what happened the status may be, for example, a 200 Accepted for a replacement of an existing resource or a 201 Created when a resource has been created.                                                                                        HTTP/1.1 200 Accepted{  &quot;id&quot;: &quot;ID&quot;,  &quot;href&quot;: &quot;/resources/ID&quot;,  &quot;some&quot;: &quot;some new data&quot;,  &quot;other&quot;: &quot;some other new data&quot;}  Deleting a resourceAnd finally, to delete a resource, the request is DELETE /resources/ID without a body. If everything is OK, the server will return a 200 Accepted. If there’s something wrong, it will return an error like 404 Not Found if the resource does not exist or a 403 Forbidden if the user is not allowed to delete that resource.But why explaining all that? I want to work with multiple resources!To work with multiple resources with a REST APIs, you definitely need to know how to work properly with a single one. This quick reminder is there to show how we use the HTTP protocol in REST APIs to express what we want to do and what happened in a clear and consistent way when working with a single resource:  the URI define which resource we are using  the HTTP method express what we want to do  the HTTP response status explain what happenedNow we’ll see how continue to do so when working with multiple resources.Same action on resources of the same typeSo what if I want to PATCH /resources/ID1 and PATCH /resources/ID2 at the same time? When it comes to do one thing with multiple resources of the same type all at once:  We send a request providing:          the type of all resources      the action which will be applied to all these resources      the identified data for all resources        We expect a response providing the result for each resource containing exactly the same information as if we had made a single requestA request containing multiple resourcesTo tell the resources type we’re working with, we will use the endpoint corresponding to a collection of resources, for example /resources or /users/bob/friends.To identify the action we want to apply on the resources we’ll simply use the matching HTTP verb:  GET /resources to get multiple resources  POST /resources to create new resources  PATCH /resources to update multiple resources  PUT /resources to replace multiple resources  DELETE /resources to delete multiple resourcesHow to provide resources data and identifier will slightly vary depending on the action.Create multiple resourcesTo provide all needed information for a creation, we have to send an array of items containing a unique identifier determined by the consumer (id) and the resource’s data (body):                                                                                        [  {    &quot;id&quot;: &quot;CREATION1&quot;,    &quot;body&quot;: {&quot;resource&#39;s&quot;: &quot;data&quot;}  },  {    &quot;id&quot;: &quot;CREATION2&quot;,    &quot;body&quot;: {&quot;resource&#39;s&quot;: &quot;data&quot;}  }]  It can also be done with a key/value map, the resource’s ID being the key and its data the value:                                                                                        {  &quot;CREATION1&quot; : {&quot;resource&#39;s&quot;: &quot;data&quot;},  &quot;CREATION2&quot; : {&quot;resource&#39;s&quot;: &quot;data&quot;}}  Receiving these data with a POST /resources request, the server will create the 2 resources provided. The provided id will be used in the response to identify the response corresponding to this resource.Update or replace multiple resourcesTo update or replace multiple resources, it’s exactly the same thing, besides the value of the resource’s id, which will be the one we would have use for a single resource (/resources/ID).                                                                                        {  &quot;ID1&quot; : {&quot;resource&#39;s&quot;: &quot;data&quot;},  &quot;ID2&quot; : {&quot;resource&#39;s&quot;: &quot;data&quot;}}  Receiving these data with a PATCH /resources request, the server will execute both PATCH /resources/ID1 and PATCH /resources/ID2 (it works the same with PUT). Just like with POST, the provided ids will be used to identify each response.Get or delete multiple resourcesTo get or delete multiple resources we will again use the resources ids but as a GET or DELETE request does not have a body, they will be provided in a query parameter like this DELETE /resources?ids=ID1,ID2.A response containing responsesA response to such a request will have to contain exactly the same data we would have had doing single calls. We need to provide a response containing multiple responses, how can we do that?  One Status Code to bring them all and in the lightness bind themThe Lord of the HTTP Status CodesThe 207 HTTP status code is exactly what we’re looking for:  The 207 (Multi-Status) status code provides status for multiple independent operationsThis status has been defined by RFC 4918 HTTP Extensions for Web Distributed Authoring and Versioning (WebDAV). Here’s an example of a WebDAV 207 response when deleting some resources:                                                                                        &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot; ?&gt;&lt;d:multistatus xmlns:d=&quot;DAV:&quot;&gt;  &lt;d:response&gt;    &lt;d:href&gt;http://www.example.com/container/resource3&lt;/d:href&gt;    &lt;d:status&gt;HTTP/1.1 423 Locked&lt;/d:status&gt;    &lt;d:error&gt;&lt;d:lock-token-submitted/&gt;&lt;/d:error&gt;  &lt;/d:response&gt;  &lt;d:response&gt;    &lt;d:href&gt;http://www.example.com/container/resource4&lt;/d:href&gt;    &lt;d:status&gt;HTTP/1.1 200 OK&lt;/d:status&gt;  &lt;/d:response&gt;&lt;/d:multistatus&gt;                                                  Oops, sorry for the XML, it’s only to show that a WebDAV 207 response contains a list of response. Each of this response point to a resource (href) and contains also the response itself, how could it look in a less frightening JSON way:                                                                                        [  {    &quot;id&quot;: &quot;ID1&quot;,    &quot;status&quot;: &quot;201&quot;,    &quot;headers&quot;: [      {&quot;header&#39;s name&quot;: &quot;header&#39;s value&quot;}    ],    &quot;body&quot;: { &quot;the&quot;: &quot;response&#39;s body&quot;}  },  {    &quot;id&quot;: &quot;ID2&quot;,    &quot;status&quot;: &quot;400&quot;,    &quot;headers&quot;: [      {&quot;header&#39;s name&quot;: &quot;header&#39;s value&quot;}    ],    &quot;body&quot;: { &quot;the&quot;: &quot;response&#39;s body&quot;}  }]  A 207 will response will contain a list of responses, each response containing:  An identifier (id) matching the one provided in the request  The HTTP response’s data composed of a status, headers and a body. These data are exactly the same we would have received for a single call.Note that we can also use a map in which the keys are the responses identifiers:                                                                                        {  &quot;ID1&quot;: {    &quot;status&quot;: &quot;201&quot;,    &quot;headers&quot;: [      {&quot;header&#39;s name&quot;: &quot;header&#39;s value&quot;}    ],    &quot;body&quot;: { &quot;the&quot;: &quot;response&#39;s body&quot;}  },  &quot;ID2&quot;: {    &quot;status&quot;: &quot;400&quot;,    &quot;headers&quot;: [      {&quot;header&#39;s name&quot;: &quot;header&#39;s value&quot;}    ],    &quot;body&quot;: { &quot;the&quot;: &quot;response&#39;s body&quot;}  }}  We could even match request and response based on position in the list.Two levels of errorIn that case, we must be aware that there are two types of errors, the one concerning one or more of the resources and the one concerning the multiple request itself.For errors concerning the action on each resource), the HTTP status returned by the server will be a 207 and each sub-response will contains the status for each sub-request (as explained in previous paragraph).For errors concerning the main request (misspelled query parameter for DELETE, or invalid body map/list structure for example), the server may return a 400 Bad Request for example.Single and multiple creations with the same endpointNote that POST /resources was supposed to be used to create a single resource. If we want to handle the single/multiple duality we have two options:Use a list/map for both caseThe input is exactly the same for 1 or more resources, we will only provide a single one item to create a single resource.                                                                                        {  &quot;CREATION1&quot; : {&quot;resource&#39;s&quot;: &quot;data&quot;}}  The server’s response should be always be the one described earlier for multiple creations even if there’s only a single item.Accept both a list/map and single objectThe input for a single resource contains only the resource’s data:                                                                                        {&quot;resource&#39;s&quot;: &quot;data&quot;}  The server response will be the one expected for a single creation.The input for multiple resource contains a list/map:                                                                                        {  &quot;CREATION1&quot; : {&quot;resource&#39;s&quot;: &quot;data&quot;}  &quot;CREATION2&quot; : {&quot;resource&#39;s&quot;: &quot;data&quot;}}  The server response will be the one expected for a multiple creations as seen earlier.Different actions on resources of the same typeWhat if we want to DELETE /resources/ID1 and PATCH /resources/ID2 at the same time? As it is an action that impacts the data in various way we should use the POST HTTP verb. Concerning the URI, we have two options, use /resources or create a specific resources for this use case like /resource-modifications for example. The request will be then something like POST /resources or POST /resource-modifications and we will have to provide the action (method) for each resource:                                                                                        [  {    &quot;id&quot;: &quot;ID1&quot;,    &quot;method&quot;: &quot;DELETE&quot;  },  {    &quot;id&quot;: &quot;ID2&quot;,    &quot;method&quot;: &quot;PATCH&quot;,    &quot;body&quot;: {&quot;resource&#39;s&quot;: &quot;data&quot;}  }]  The server will do DELETE /resources/ID1 and PATCH /resources/ID2 and the response will be a 207 using the structure using the provided id as seen previously in his post.Different actions on resources of different typesWhat if I want to do DELETE /resources/ID1 and PATCH /another-resources/ID2 at the same time?                                                This is really nasty and definitely not REST, but it can be useful for backend for frontend or experience API for example.To do that we’ll need to POST data on a specific endpoint which could something like /batch, /bulk or even / and we will have to add a uri and replace the id value by something provided by the consumer:                                                                                        [  {    &quot;id&quot;: &quot;ACTION1&quot;,    &quot;uri&quot;: &quot;/resources/ID1&quot;,    &quot;method&quot;: &quot;DELETE&quot;  },  {    &quot;id&quot;: &quot;ACTION2&quot;,    &quot;uri&quot;: &quot;/another-resources/ID2&quot;,    &quot;method&quot;: &quot;PATCH&quot;,    &quot;body&quot;: {&quot;resource&#39;s&quot;: &quot;data&quot;}  }  ,  {    &quot;id&quot;: &quot;ACTION3&quot;,    &quot;uri&quot;: &quot;/resources&quot;,    &quot;method&quot;: &quot;POST&quot;,    &quot;body&quot;: {&quot;resource&#39;s&quot;: &quot;data&quot;}  }]  Actions number 1 is DELETE /resources/ID1 and its result will be identified in the 207 response by the id ACTION1.To see a complete example you should take a look at Facebook’s Graph API batch endpoint documentation. Note that this batch endpoint match request/response based on index and does far more than just processing a bunch of request."
},{
    "id": "58",
    "type": "post",
    "title": "OpenAPI Visual Documentation updated with 3.0.0-rc0",
    "url": "https://apihandyman.io/openapi-visual-documentation-updated-with-3.0.0-rc0/",
    "banner": "https://apihandyman.io/images/openapi-visual-documentation-updated-with-3.0.0-rc0/banner.png",
    "description": "The OpenAPI Visual Documentation has been updated. The new version 3.0.0-rc0 of the OpenAPI specification has been added. The addition brings a fully detailed change log of what has change from version 2.",
    "body": "The OpenAPI Visual Documentation has been updated. The new version 3.0.0-rc0 of the OpenAPI specification has been added. The addition brings a fully detailed change log of what has change from version 2.OpenAPI 3.0The OpenAPI specification is evolving, the 3.0.0-rc0 implementer draft version has been released.This new OpenAPI specification version 3.0.0 offers many welcomed improvements and new features (see OpenAPI blog post series about this).Updating the OpenAPI Specification Visual DocumentationIt was past time to update the OpenAPI Specification Visual Documentation to fully grasp what happens with this update.                                      OpenAPI Specification Visual Documentation showing v3.0.0-rc0          The tool can handle now multiple versions that you select with the buttons on the top right navigation bar. The v3.0.0-rc0 comes with a fully detailed changelog for each level and property."
},{
    "id": "59",
    "type": "post",
    "title": "Google API Design Guide added to the API Stylebook",
    "url": "https://apihandyman.io/google-api-design-guide-added-to-the-api-stylebook/",
    "banner": "https://apihandyman.io/images/google-api-design-guide-added-to-the-api-stylebook/banner.png",
    "description": "I’ve just added the Google API Design Guide to the API Stylebook. This guide is slightly different from the other ones because it deals with REST and RPC API design focusing on gRPC APIs using Protocol Buffers v3. To discover this API design guide and a short review, let’s go to the API Stylebook blog.",
    "body": "I’ve just added the Google API Design Guide to the API Stylebook.  This guide is slightly different from the other ones because it deals with REST and RPC API design focusing on gRPC APIs using Protocol Buffers v3.To discover this API design guide and a short review, let’s go to the API Stylebook blog."
},{
    "id": "60",
    "type": "post",
    "title": "Writing OpenAPI (Swagger) Specification Tutorial Series - Part 9 - Extending the OpenAPI specification",
    "url": "https://apihandyman.io/writing-openapi-swagger-specification-tutorial-part-9-extending-the-openapi-specification/",
    "banner": "https://apihandyman.io/images/writing-openapi-swagger-specification-tutorial-part-9-extending-the-openapi-specification/banner.png",
    "description": "This is the end, my OpenAPI friends, the end. The end? Not really. This last part of the OpenAPI tutorial is a new beginning. With previous parts we have learned to master the OpenAPI specification but there’s a last thing to learn to unleash its full power: extensions. This format is easily extensible, it allows to add custom data within an API description. But for what purposes? Let’s have a glimpse of these extensions endless possibilities.",
    "body": "This is the end, my OpenAPI friends, the end. The end? Not really. This last part of the OpenAPI tutorial is a new beginning. With previous parts we have learned to master the OpenAPI specification but there’s a last thing to learn to unleash its full power: extensions. This format is easily extensible, it allows to add custom data within an API description. But for what purposes? Let’s have a glimpse of these extensions endless possibilities.      Writing OpenAPI (Swagger) Specification Tutorial Series                      This tutorial teaches everything about the OpenAPI 2.0 Specification (fka. as Swagger), most of what you’ll read here can still be applied on version 3.If you’re a bit lost in the specification (version 2 or 3), take a look at the OpenAPI Map:                                                                                                      1 - Introduction                                      2 - The basics                                      3 - Simplifying specification file                                      4 - Advanced Data                                      5 - Advanced Input And Output Modeling                                      6 - Defining Security                                      7 - Documentation                                      8 - Splitting specification file                                      9 - Extending the OpenAPI specification                                      In this final part we’ll learn how to extend the OpenAPI specification to add custom data and most important, we’ll discover why we would do that.One size may not fit allAfter working for a while with the OpenAPI format, you WILL want to add other data into you API descriptions, this is your destiny. Fortunately, the creator of the format had foreseen that:  While the Swagger Specification tries to accommodate most use cases, additional data can be added to extend the specification at certain points.OpenAPI SpecificationOnce known as Vendor Extensions, these Specification Extensions can be created by anyone, don’t be fooled by their original name.Custom propertyTo add a custom property with an OpenAPI definition file you only need to prefix its name by x-:                                                                                        x-&lt;what you want&gt;: &lt;value&gt;  Here’s a custom property x-custom-info in the info section of an OpenAPI file:                                                                                                info:  version: 1.0.0  title: x-tended OpenAPI Specification  description: An OpenAPI specification containing custom data  x-custom-info: Here's some custom information  If a standard Swagger/OpenAPI parser encounters such property, it will ignore it because it’s prefixed with x-. This info section with a custom property is valid:                                                Custom objectExtensions are not only meant to be atomic properties, they can also be objects:                                                                                                info:  version: 1.0.0  title: x-tended OpenAPI Specification  description: An OpenAPI specification containing custom data  x-custom-info:    comment: Here's some custom information    authors:      - name: John Doe        email: john@doe.com      - name: Jane Doe        email: jane@doe.com  Note that sub-properties names do not need to be prefixed with x-.Extensions almost anywhereThese custom data structures can be added almost anywhere in the specification. You can test if a location is ok by simply adding your extension where you want within the online editor and see if the validator complains or not.You can also take a look at my visual documentation to check if the location you want to use allows extension or not:                                                Here’s an example using various location (non-exhaustive example):                                                                                                swagger: '2.0'x-root: some custom root datainfo:  version: 1.0.0  title: x-tended OpenAPI Specification  description: An OpenAPI specification containing custom data  x-custom-info:    comment: Here's some custom information    authors:      - name: John Doe        email: john@doe.com      - name: Jane Doe        email: jane@doe.compaths:  /resources:    get:      description: gets some resource      responses:        200:          description: everything is ok          x-custom-response-data: I told you everything was really OK!          schema:            type: array            items:              $ref: \"#/definitions/Resource\"definitions:  Resource:    x-custom-definition-data: some.dummy.class.Resource    properties:      data:        description: some data        type: string        x-custom-property-data: More blah blah about this property  Why customizing the OpenAPI specification?So, adding custom information within an OpenAPI specification file is fairly easy. But the question is less about the how and more about the why. Why would you add custom data to your OpenAPI files?You can use some extensions provided by open source or commercial tools or create your own. You can simply add custom data without processing them for documentation purpose or use these informations to generate documentation, client code, server code or tests or even configure some tools.Let’s see some examples.  nb: This post is not a sponsored one.Example 1: DocumentationGelato, the Mashape Developer Portal solution, uses the x-gelato-group extension to group operations in the portal navigation.                                                Of course, as an OpenAPI expert you would have use tags to do that. Beware to not reinvent the wheel when creating your extensions.Example 2: Client code generationAPI Matic, a SDK/DX kits generator uses extension ton control SDK generation.                                                Example 3: Server code generationSwagger Node, a node module which help to build API implementation with a design first approach uses a x-swagger-router-controller extension to link an API endpoint to its controller implementation.                                                Example 4: API gateway configurationNot only the AWS API gateway allows to import a Swagger/OpenAPI file but it also provides a complete set of extensions to configure how the API is linked to backend systems (like lambda).                                                ConclusionThis post concludes the OpenAPI/Swagger specification tutorial. You master now every single aspect of the OpenAPI specification and with this last post I hope to have given you some ideas to be creative to include this format in each step of the API lifecycle."
},{
    "id": "61",
    "type": "post",
    "title": "...And GraphQL for all? A few things to think about before blindly dumping REST for GraphQL",
    "url": "https://apihandyman.io/and-graphql-for-all-a-few-things-to-think-about-before-blindly-dumping-rest-for-graphql/",
    "banner": "https://apihandyman.io/images/and-graphql-for-all-a-few-things-to-think-about-before-blindly-dumping-rest-for-graphql/banner.png",
    "description": "GraphQL is new. GraphQL is cool. Look! Github dumped REST for it! We MUST do it too! Well, why not. GraphQL could be a great tool, but like any tool, you don’t choose it just because. You choose it because it solves a problem in a given context. You choose it knowing its strengths and weaknesses. While discovering what is GraphQL we will see what REST API providers should think about before blindly dumping REST for it. From design and implementation to pricing model and analytics down to developers experience and implementations, choosing an API design style will have impact on the whole API lifecycle. Therefore, this choice must be an enligthned one and not based on simple beliefs.",
    "body": "GraphQL is new. GraphQL is cool. Look! Github dumped REST for it! We MUST do it too!Well, why not. GraphQL could be a great tool, but like any tool, you don’t choose it just because. You choose it because it solves a problem in a given context. You choose it knowing its strengths and weaknesses.While discovering what is GraphQL we will see what REST API providers should think about before blindly dumping REST for it. From design and implementation to pricing model and analytics down to developers experience and implementations, choosing an API design style will have impact on the whole API lifecycle. Therefore, this choice must be an enligthned one and not based on simple beliefs.Informed choiceBefore talking about GraphQL, I would like to ask you two really important questions.The first one is:                                      Metallica or Iron Maiden. Who is the best heavy metal band?          Iron Maiden of course. You may disagre, that is your absolute right. Metallica could also the best metal band… For you. The answer to this question is only a matter of personnal feelings.The second question is:                                      Hammer or screwdriver. Which is the best tool?          It’s a pretty dumb question isn’t it? The only possible answer to this question is it depends.It depends on the tools capabilities and the context (what you want to do, what is your environnement, your budget, your objective).Without context, my hammer cannot be better than your screwdriver.Acting as a fanboy may be acceptable when it comes to choose your favorite heavy metal band. But it’s definitely not a good idea when it comes to choose a tool, a product or an API style… From design and implementation to pricing model and analytics down to developers experience and backend implementations, choosing an API design style will have impact on the whole API lifecycle.So before blindly yelling …and GraphQL for all! just because Facebook created it and Github decided to use it, remember that GraphQL, just like REST, is only a tool. A tool that you choose with a purpose within a certain context.Let’s dig into GraphQL and see what we should think about from a REST API provider prespective when evaluating it as a possible solution for our API projects.What is GraphQL?GraphQL is a query language for data created in 2012 by Facebook when switching to native mobile applications.  We were frustrated with the differences between the data we wanted to use in our apps and the server queries they required.GraphQL was our opportunity to rethink mobile app data-fetching from the perspective of product designers and developers. It moved the focus of development to the client apps, where designers and developers spend their time and attention.GraphQL, a data query language. Post by Lee ByronFacebook open sourced it in 2015 and companies like Pinterest, Coursera or Github started to use it.Let’s take a look at Github GraphQL API to discover GraphQL.What you want is what you getGraphQL motto is  What you want is what you getQuerying dataThe Github GraphQL API propose a viewer query, returning the connected User data. This query is the equivalent of GET /user in the Github REST API. The difference with the REST query is that I can select the properties I want to retrieve.With this query, I retrieve only the viewer’s name and avatarURL.                                                                                        {  viewer {    name    avatarURL  }}  To get server’s response I have to POST this query in a JSON object to the GraphQL endpoint:                                                                                        POST https://api.github.com/graphql{ &quot;query&quot;: &quot;{ me: viewer { name avatarURL} }&quot;}  The result is in JSON format and the requested data are located in the data property. These data mirror perfectly my query.                                                                                        {  &quot;data&quot;: {    &quot;viewer&quot;: {      &quot;name&quot;: &quot;Arnaud Lauret&quot;,      &quot;avatarURL&quot;: &quot;https://avatars0.githubusercontent.com/u/10104551?v=3&quot;    }  }}  Customizing responsesYou can create more custom data structures by using aliases.Here, viewer becomes me, name becomes fullname and avatarURL becomes picture.                                                                                        {  me: viewer {    fullname: name    picture: avatarURL  }}  The result is exactly what I requested:                                                                                        {  &quot;data&quot;: {    &quot;me&quot;: {      &quot;fullname&quot;: &quot;Arnaud Lauret&quot;,      &quot;picture&quot;: &quot;https://avatars0.githubusercontent.com/u/10104551?v=3&quot;    }  }}  Querying sub-resourcesNow let’s say I want to retrieve some viewer’s data and the names of his last two created repositories.To do that with the Github REST API, I need two calls:  GET /user to get the viewer information  GET /user/repos?sort=created&amp;direction=desc to get the repositories list. Unfortunately the API do not propose a length parameter for the listThe responses will contains all available data, the REST API do not propose to filter returned properties.With GraphQL, I can do that with a single query:                                                                                        {  me: viewer {    fullname: name    picture: avatarURL    repositories(first: 2, orderBy: {field: CREATED_AT, direction: DESC}) {      edges {        node {          name        }      }    }  }}  I just have to add the repositories property in my viewer query with the good parameters and indicate the properties I want to get back for each repository. The response contains exactly what I requested.                                                                                        {  &quot;data&quot;: {    &quot;me&quot;: {      &quot;fullname&quot;: &quot;Arnaud Lauret&quot;,      &quot;picture&quot;: &quot;https://avatars0.githubusercontent.com/u/10104551?v=3&quot;,      &quot;repositories&quot;: {        &quot;edges&quot;: [          {            &quot;node&quot;: {              &quot;name&quot;: &quot;apistylebook-api&quot;            }          },          {            &quot;node&quot;: {              &quot;name&quot;: &quot;restfest-videos-data-postprocessor&quot;            }          }        ]      }    }  }}  Aggregating queriesNot only can I seamlessly retrieve a resource and its sub resources, I can also make multiple different queries in one API call.Here I retrieve information about:  me (the viewer)  two other users (Kin Lane and Mike Amundsen)  and a search on repositoriesin a single request to the GraphQL server:                                                                                        {  me:   viewer                 { name avatarURL }  kin:  user(login: &quot;kinlane&quot;) { name avatarURL }  mike: user(login: &quot;mamund&quot;)  { name avatarURL }  graphqlRepos: search(first: 2, query: &quot;graphql&quot;, type: REPOSITORY) {  \tedges { node { ... on Repository {      name      description    }}}    }}  The response contains all requested data:                                                                                        {  &quot;data&quot;: {    &quot;me&quot;: {      &quot;name&quot;: &quot;Arnaud Lauret&quot;,      &quot;avatarURL&quot;: &quot;https://avatars0.githubusercontent.com/u/10104551?v=3&quot;    },    &quot;kin&quot;: {      &quot;name&quot;: &quot;Kin Lane&quot;,      &quot;avatarURL&quot;: &quot;https://avatars1.githubusercontent.com/u/56100?v=3&quot;    },    &quot;mike&quot;: {      &quot;name&quot;: &quot;Mike Amundsen&quot;,      &quot;avatarURL&quot;: &quot;https://avatars2.githubusercontent.com/u/38344?v=3&quot;    },    &quot;graphqlRepos&quot;: {      &quot;edges&quot;: [        {          &quot;node&quot;: {            &quot;name&quot;: &quot;graphql&quot;,            &quot;description&quot;: &quot;GraphQL is a query language and execution engine tied to any backend service.&quot;          }        },        {          &quot;node&quot;: {            &quot;name&quot;: &quot;graphql&quot;,            &quot;description&quot;: &quot;An implementation of GraphQL for Go / Golang&quot;          }        }      ]    }  }}  GraphQL is not SQL nor an ETLGraphQL is really powerful but be warned that it’s not SQL nor an ETL, you can select the data you want, agregate queries, change names but not join queries or change the data structure.You cannot join queries like you would join tables in SQL.                                                                                        SELECT * FROM A, B WHERE A.COL = B.COL  You cannot select sub-properties or flatten objects. If I want to retrieve the name of my first repository without the edges and repo level, I cannot change this hierarchy:                                                                                        {  &quot;data&quot;: {    &quot;me&quot;: {      &quot;myFirstTwoRepos&quot;: {        &quot;edges&quot;: [          {            &quot;repo&quot;: {              &quot;name&quot;: &quot;apistylebook-api&quot;            }          }        ]      }    }  }}  into this one:                                                                                        {  &quot;data&quot;: {    &quot;me&quot;: {      &quot;myFirstTwoRepos&quot;:        [          {&quot;name&quot;: &quot;apistylebook-api&quot;}        ]      }    }  }}  Schema, introspection, documentationAll the available data are described within a schema.This schema let you describe your data model like you would do with OpenAPI/Swagger, Blueprint or RAML specification.The schema can be queried on runtime like all of the data.This query let me know what are the properties of the User resource which is returned by the viewer and user query                                                                                        {  __type(name:&quot;User&quot;) {    fields {      name      description    }  }}  This schema can also be used to generate documentation:                                      GraphiQL documentation          EcosystemGraphQL do not comes alone, it’s a part of an ecosystem including:  Consumer libraries like Relay  API explorer GraphiQL  And server libraries in many different languages like Node, Ruby, Python, Java, Scala or ClojureGraphQL in few wordsSo basically with GraphQL you can  Retrieve only the data you need on consumer side  Reduce the data volume returned by the server because you retrieve only what you need  Reduce the number of calls to retrieve data by seamlessly retrieving linked resources and agregating queries  Discover the schema you are queryingAnd GraphQL comes with a full ecosystem which ease both API provider and consumer job.I have played with the official node js library to create a GraphQL server and I was really impressed by how it was easy to achieve a proof of concept. You define your schema. You define resolver function for your resources, and bang! it’s done.If you want to discover GraphQL you should try the tutorial available at learngraphql.com and play with the Github GraphQL APIWhat GraphQL could mean when you’re acustomed to RESTThis is very cool. My geek side is really excited about GraphQL. But Let’s keep a cool head and try to think about what GraphQL could mean for people acustomed to REST APIs? Let’s see what are some impacts on the consumer and provider sides.GraphQL brings a different developer experienceWhen people speak of GraphQL and developer experience, the main focus is on what you want is what you get which is really a killer feature that can greatly enhance DX in a certain context. But as GraphQL offers a radically different DX than a REST API, some aspects should be investigated to evaluate if these changes can be real issues.Being protocol agnostic has consequences on predictability and consistencyGraphQL is protocol agnostic, it means that you can use it with any protocol as long as you can send and retrieve a string. This can be useful but people acustomed to using the HTTP protocol with REST API should then be aware that, when used over HTTP, GraphQL do not use any of its features and it has consequences on DX.Reading and writing resourcesWith a REST API, if I retrieve a user’s data with GET /users/{id}, I can try to update it with PATCH /users/{id} and delete it with DELETE /users/{id} without even reading the documentation and it will probably work… like it will work with another another resource in the same API and even with another resource in another REST API.And icing on the cake: both humans and machines can discover and understand the meaning of each operation.Using the HTTP protocol enforce a certain consistency and allow predictability.In a GraphQL API, reading and writing actions are separated in 2 sets of queries.  query for reading  mutation for writingMachines will only be able to understand that a query do not modify underlying system and a mutation does, all other semantic will be based on naming conventions.If I get a user with the query user:                                                                                        query {  user(id: &quot;{id}&quot;) {    name  }}  Updating or deleting this user with GraphQL will not be as clear as with REST.How will be named the mutation allowing me to delete a user? deleteUser, removeUser or suppressPeople?You’ll have to dig in the documentation to find out. You cannot guess it because different API providers will have different naming conventions and these naming convention may event not be consistent within an API.                                                                                        mutation {  deleteUser(id: &quot;{id}&quot;)  removeUser(id: &quot;{id}&quot;)  suppressPeople(id: &quot;{id}&quot;)}  Handling errorsBeing protocol agnostic also means that everything is going to be 200 OK when using GraphQL over HTTP, wheither the query was OK or not. With REST APIs we are acustomed to be able to tell what happens just by looking at the HTTP status. Whatever the API, if we receive a 404 HTTP status we known what it means: resource not found.If I try to retrieve a user that do not exists with a GraphQL API:                                                                                        {  user(login: &quot;dummy-user-123&quot;) {name}}  I get this GraphQL standard error with a text message telling me the user do no exists.:                                                                                        {  &quot;data&quot;: {    &quot;user&quot;: null  },  &quot;errors&quot;: [    {      &quot;message&quot;: &quot;Could not resolve to a User with the login of &#39;dummy-user-123&#39;.&quot;,      &quot;locations&quot;: [        {          &quot;line&quot;: 2,          &quot;column&quot;: 3        }      ],      &quot;path&quot;: [        &quot;user&quot;      ]    }  ]}  If I forget the login parameter:                                                                                        {  user { name }}  I get exactly the same error format:                                                                                        {  &quot;data&quot;: null,  &quot;errors&quot;: [    {      &quot;message&quot;: &quot;Field &#39;user&#39; is missing required arguments: login&quot;,      &quot;locations&quot;: [        {          &quot;line&quot;: 2,          &quot;column&quot;: 3        }      ]    }  ]}  The message shows me explicitely what the problem is, but I cannot determine the error type programmatically in a generic way. These errors are not really fit to be analyzed automatically by machines. Of course there’s obviously a pattern in the message but will this message have the same pattern for another resource or use case? Will this pattern be consistent as the API evolve? And will I find exactly the same pattern in another GraphQL API?GraphQL focuses on data and not actionsA well design REST API implementing hypermedia is able to tell you what are the resources connected to the resource you just get but it can also provide the possible affordances to tell you what you can do. With an hypermedia API you’ll be able to describe a complex process step by step providing information about the next requests you can do. But be aware that if HTTP protocol ensure a certain consistency across APIs concering resources manipulation, the hypermedia aspect of REST APIs is not standardized even if some format like Siren, Hydra or HAL exist.A GraphQL API focus on data, you read data, you write data. But these aspects are totally disconnected and, for now, describing affordance is not a GraphQL feature. You can of course rely on documentation to describe these processes but therefore machines will not be able to handle that automatically. Looking at how it’s implemented in REST API, I’m sure that sooner or later we will have such features in GraphQL.CacheCaching data is always a tricky thing. With a REST API, a consumer could rely on HTTP caching system and could rely on HTTP caching data provide in response’s header to build it’s own cache.With GraphQL there’s no such mecanism, for now, you’ll have to rely totally on the client to handle cache. Hopefully client library like Facebook’s Relay propose a complex cache system but as GraphQL do not provide information about how long the data are valid, it will be up to the consumer to choose when to refresh the cache.I’m sure that as GraphQL evolve, we will have better cache mecanism in the future.Does GraphQL offer a good or bad DX?So with GraphQL you gain great flexibility when querying data but you lose a certain predictability and consistency inside an API and across APIs. You may also not clearly see what you can do with these data and GraphQL gives more responsability on the client side to cache these data.Is this a problem?. Like always, the answer to this question will depend on the context. You just have to think about these elements (and probably others) regarding your context to determine if it’s a problem or an advantage.GraphQL does not ease API provider job and brings new challengesLet’s see now what GraphQL means on the provider side.First, let me be clear:  If you suck at providing REST API, you WILL suck at providing GraphQL API.Arnaud Lauret, API HandymanGraphQL may bring new challenges and questions on the provider side but it mainly highlights matters that you should master whatever the type of API you provide.GraphQL will not solve your API design problems  What the hell is this amsus2 field?Anonym consumerAfter a in-depth analysis of a use case or a problem, you may come to the logical and enligtened conclusion that GraphQL is the most appropriate solution instead of REST regarding the context. Be warned that GraphQL is not a magic thing that you just put on top of a good old database or existing system and it’s over.Don’t dare to think: We have data, let people decide how to query them and what to make of them!. Don’t forget that a GraphQL API is STILL an API. It’s supposed to be a consumer friendly abstraction of a usually complex underlying system.Remember all the terrible things you’ve done while designing crappy REST APIs. API without really defined purpose, dumb database mapping, dumb legacy service mapping, dumb internal organization and processes exposition … A GraphQL API, just like a REST one, must be created with a purpose and designed from an outside in perpective and not an inside out one.If you don’t do that, be ready for a total failure.We have seen while talking about Developer Experience that queries and mutations are disconnected and that consumer can only rely on mutation’s name and documentation to know what they’re up to. You will have to increase control on design because naming thing consistently is hard and you’ll definitely need consistency to help consumers understand how your query and mutations are connected and what mutations actually do. If you know some people who were involved in SOA governance in the SOAP protocol era you may call them because they have faced such things.GraphQL will not solve your API documentation problemsA GraphQL API comes with an integrated documentation system describing the schema that can be queried.You can discover the available queries and the data returned.  A5 Amsus2 B B5 B7 B7/D# C C5 C#5 Cadd9 D D5 D#5 E5 Em F#m GMaster of Puppets Guitar ChordsThis is the list of guitar chords you need to play Master Of Puppets. Having only this list, and without being a guitar hero, will you be able to play the song? Well maybe … after a very long struggle.An interface contract description, an inventory of queries and objects, was, is and will NEVER be the API documentation, it’s only a part of it. It’s just like providing guitar chords without explaing how to chain them to play a song. How to connect? How is handled rate limiting? How is handle security? How to respond to this use case? Code snippets, SDK, tutorials …API documentation is something that go way beyond the description of its interface contract. Don’t forget that the API itself and its documentation are the main ingredients of a good developer experience. Without a good DX, no users, no business.So don’t be fooled by this kind of documentation and note that also applies to REST APIs when you use API description format like OpenAPI, Swagger, RAML of Blueprint.GraphQL may have unexpected side effects and data volumes and server usageWith GraphQL, what you want is what you get. But you always have to explicitely tell what you want, there’s no select * from user like in SQL. So on each request, consumers have to send a full query.Where you would have a simple GET /dashboard with a REST API, you may end with a huge GraphQL query.In some use case, you may reach your input bandwidth limit because the number of requests has not really diminished but the requests size has increased. Remember that not everybody has a fully scalable cloud infrastructure with illimited bandwidth.Proposing a smart system allowing consumers to retrieve in one shot what they want do not mean that it will be used wisely. Some lazy consumers may simply fired huge requests retrieving far more data than they really need. Some huge and complex request may impact all you infrastructure, so you should really think about your GraphQL schema and what runs behind it, because you’re giving the full power to consumers.GraphQL may force you to rethink API analytics and pricing modelIf you were relying on HTTP access logs for rate limiting, API analytics and billing you will have to find a new way to handle that. The most important impact will be on pricing model and billing: how to make people pay when you have a single endpoint allowing to do what you want like you want? Counting queries and mutations can be agood start, you’ll maybe have to include data volume and queries depth in your calculations to design a new pricing model. Getting these new variables will probably have impacts on your API tooling, especially your API gateway.Does GraphQL offer a good or a bad PX (provider experience)?Providing a GraphQL API will not make you magically a better API provider. You still have to design and document your API, you still have to create the best architecture and infrastructure, you still have to define a pricing model. Providing GraphQL API brings the same challenges has providing REST API with a few subtles differences that you must be aware of to choose the right API style for the right context.Should I choose GraphQL or REST?In conclusion, GraphQL is really a powerful and interesting technology that impacts deeply both API provider and consumer who are acustomed to REST APIs. It’s a new technology that may need some improvments, that will surely come.You MUST see it as a new tool in your API toolbox alongside REST and Streaming APIs. A new tool that you will choose wisely regarding your context. And don’t forget that sometime you’ll need a hammer AND a screwdriver to build awesome things.Now I hope you will be able to the answer this really important question:  REST or GraphQL.Which one is the best API style?You’re supposed to yell it depends!This post is a writeup of my API Days Paris 2017 talk."
},{
    "id": "62",
    "type": "post",
    "title": "Dr Jekyll and Mr API Handyman",
    "url": "https://apihandyman.io/dr-jekyll-and-mr-api-handyman/",
    "banner": "https://apihandyman.io/images/dr-jekyll-and-mr-api-handyman/banner.png",
    "description": "ICYMI, I’ve just switched from a self hosted Wordpress to a Jekyll static website hosted on Github. The code is available in the apihandyman.io repository. If you’re looking for information and tips about how to enable pagination on categories pages and have infinite scroll with Jekyll or how to to deploy a Jekyll website using custom plugins on Github Pages, you should take a look at it.",
    "body": "ICYMI, I’ve just switched from a self hosted Wordpress to a Jekyll static website hosted on Github. The code is available in the apihandyman.io repository. If you’re looking for information and tips about how to enable pagination on categories pages and have infinite scroll with Jekyll or how to to deploy a Jekyll website using custom plugins on Github Pages, you should take a look at it."
},{
    "id": "63",
    "type": "post",
    "title": "Read Evolving a Company’s IS in the Lego Computing Age on Nordic APIs blog",
    "url": "https://apihandyman.io/read-evolving-a-companys-is-in-the-lego-computing-age-on-nordic-apis-blog/",
    "banner": "https://apihandyman.io/images/read-evolving-a-companys-is-in-the-lego-computing-age-on-nordic-apis-blog/banner.png",
    "description": "If you wonder how to evolve a company’s IS in the lego computing age, read my post on Nordic APIs blog.",
    "body": "If you wonder how to evolve a company’s IS in the lego computing age, read my post on Nordic APIs blog."
},{
    "id": "64",
    "type": "post",
    "title": "OpenAPI Trek Series - Part 3 - OpenAPI Trek Beyond API Documentation",
    "url": "https://apihandyman.io/openapi-trek-beyond-api-documentation-api-strat-2016/",
    "banner": "https://apihandyman.io/images/openapi-trek-beyond-api-documentation-api-strat-2016/banner.png",
    "description": "OpenAPI offers many possibilities that span the full API lifecycle, yet it is seen purely as a solution for generating API documentation. This session will tell the story of AXA Banque&#39;s evolution from .doc and .pdf API documentation to the extensive use of OpenAPI Specification (formerly Swagger). Throughout the journey, we will identify the many advantages of API definition languages beyond simply generating API documentation, including design, testing, documentation continuous delivery, code generation, mocking, and prototyping new ideas.",
    "body": "After API Days London, and Nordic APIs Summit in Stockholm, Scottie beamed me to API Strat Boston 2016 for the final part of my OpenAPI specification (fka. Swagger specification) talk series: OpenAPI Trek Beyond API Documentation. This last talk is the (not so uncommon) story of how I came to use Swagger/OpenAPI for API documentation and how it changed many things beyond API documentation.You’ll find here the abstract, slides and the video (very special thanks to Matthew Reinbold for recording this talk with my crappy phone).      OpenAPI Trek Series                      This 3 talk series provide insight on what is the OpenAPI Specification and how to take advantage of it during the whole API life cycle, especially for design and documentation, and also how to use it to secure and accelerate API creations and evolutions.                                                      1 - OpenAPI Trek                                      2 - OpenAPI Trek Into Fastness                                      3 - OpenAPI Trek Beyond API Documentation                                      AbstractOpenAPI offers many possibilities that span the full API lifecycle, yet it is seen purely as a solution for generating API documentation. This session will tell the story of AXA Banque’s evolution from .doc and .pdf API documentation to the extensive use of OpenAPI Specification (formerly Swagger). Throughout the journey, we will identify the many advantages of API definition languages beyond simply generating API documentation, including design, testing, documentation continuous delivery, code generation, mocking, and prototyping new ideas.Video                                                This content is hosted on youtube.com.                By showing this third party content you accept YouTube (Google)'s                     privacy policy.                                                    Show third party content                                                                    Remember my choice                        (can be changed in privacy settings)                                                                                      SlidesDownload PDFOpen PDF    "
},{
    "id": "65",
    "type": "post",
    "title": "Swagger, OpenAPI and API Stylebook interview (API Strat Boston 2016)",
    "url": "https://apihandyman.io/swagger-openapi-and-api-stylebook-interview-api-strat-boston-2016/",
    "banner": "https://apihandyman.io/images/swagger-openapi-and-api-stylebook-interview-api-strat-boston-2016/banner.png",
    "description": "Just before the Developing an API Strategy for 2017 panel, I have been interviewed about Swagger/OpenAPI specification and the API Stylebook by Keshav Vasudevan from Smartbear.",
    "body": "Just before the Developing an API Strategy for 2017 panel, I have been interviewed about Swagger/OpenAPI specification and the API Stylebook by Keshav Vasudevan from Smartbear. Here’s the video:                                                This content is hosted on youtube.com.                By showing this third party content you accept YouTube (Google)'s                     privacy policy.                                                    Show third party content                                                                    Remember my choice                        (can be changed in privacy settings)                                                                                      "
},{
    "id": "66",
    "type": "post",
    "title": "Developing an API Strategy for 2017 (API Strat Boston 2016)",
    "url": "https://apihandyman.io/developing-an-api-strategy-for-2017-api-strat-boston-2016/",
    "banner": "https://apihandyman.io/images/developing-an-api-strategy-for-2017-api-strat-boston-2016/banner.png",
    "description": "Shortly before API Strat, I have participated to an API experts panel on Developing an API Strategy for 2017 organized by Smartbear with Laura Heritage, Matt Bernier, Ole Lensmar and Tony Tam hosted by John Purcell.",
    "body": "Shortly before API Strat, I have participated to an API experts panel on Developing an API Strategy for 2017 organized by Smartbear with Laura Heritage, Matt Bernier, Ole Lensmar and Tony Tam hosted by John Purcell.Smartbear blog posts:  Meet our Panelists  Expert Panel: Developing an API Strategy for 2017 (Video)Here’s the panel video:                                                This content is hosted on youtube.com.                By showing this third party content you accept YouTube (Google)'s                     privacy policy.                                                    Show third party content                                                                    Remember my choice                        (can be changed in privacy settings)                                                                                      And a 2 minutes summary:                                                This content is hosted on youtube.com.                By showing this third party content you accept YouTube (Google)'s                     privacy policy.                                                    Show third party content                                                                    Remember my choice                        (can be changed in privacy settings)                                                                                      "
},{
    "id": "67",
    "type": "post",
    "title": "People First: A not so gonzo API Strat Boston 2016 coverage",
    "url": "https://apihandyman.io/people-first-a-not-so-gonzo-api-strat-boston-2016-coverage/",
    "banner": "https://apihandyman.io/images/people-first-a-not-so-gonzo-api-strat-boston-2016-coverage/banner.png",
    "description": "The last API Strat 2016 day, after the last talk, a man living in kentucky asked me something like What is the one thing you will remember about this conference?. I answered something like People First. People First. This is definitely what sticks in my mind after this conference.",
    "body": "The last API Strat 2016 day, after the last talk, a man living in kentucky asked me something like What is the one thing you will remember about this conference?. I answered something like People First.People First. This is definitely what sticks in my mind after this conference.  But this is not the only thing.Let’s go back a few days earlier …The British API nerds are comingI got off the plane with my family around noon the friday prior the event. It was freezing. It was raining. I didn’t cared. There I was in Boston. Not only to visit this wonderful city and its neighborhoods, I was there for APIStrat 2016.It was going to be an awesome trip.It was going to be an awesome conference.After a few days of tourism, a panel discussion and the speakers dinner, it was time to go to API Strat.Thursday. 8 am. I grabbed my speaker badge and the API Strat 2016 official t-shirt.    One if by RESTTwo if by SOAPThis t-shirt was a bit cryptic for a foreigner like me. It seems that I was not the only one in that case.  Boston is a city steeped in history and it seemed that the american revolution hero Paul Revere or the american poet Henry Wadsworth Longfellow gave a hand to design this year’s t-shirt. This quote has been inspired by:  One if by seaTwo if by landIt was a signal, popularized by Henry Wadsworth Longfellow in his poem Paul Revere’s Ride that indicated if the british troops were coming by land or by sea in the days before the first military engagement of the American Revolutionary War, the battle of Lexington and Concord:  In the days before April 18, Revere had instructed Robert Newman, the sexton of the North Church, to send a signal by lantern to alert colonists in Charlestown as to the movements of the troops when the information became known. In what is well known today by the phrase “one if by land, two if by sea”, one lantern in the steeple would signal the army’s choice of the land route while two lanterns would signal the route “by water” across the Charles RiverSource WikipediaWhether by sea or by land, the API nerds were coming. The API community was gathering in Boston. Not for a battle of course, but for a very friendly and inclusive conference. Speakers and attendees. Experts and beginners. Old friends and total strangers. All these people gathered to talk about APIs together whatever their so-called status. Finally, everybody got back home with new lessons learned, new ideas and most important: new friends.This is bowling, there are rulesSo many different people gathered in a friendly and inclusive event, what could go wrong?In an ideal world, nothing. But we do not live in an ideal world.  Thursday 9 am. Main Stage. The staff announced that someone has been expelled from the conference (the conference has started the day before with workshops, speakers dinner and attendees meetup).In case you missed it, API Strat has a code of conduct.A code of conduct?Yes, a code of conduct:  A Code of Conduct is a public statement that sets the ground rules for participating in an eventAshe DrydenEverybody was now aware that this code was NOT a paper tiger.  This is sad, not for the person who has been expelled, but for the person who had to suffer inappropriate behavior.This is good, not because someone had to report an inappropriate behavior, but because someone was able to report an inappropriate behavior and because the API Strat staff reacted promptly and efficiently.Next time you attend an event, read the code of conduct and don’t be a jerk.Next time you get out of your home, don’t be a jerk, even if there’s no code of conduct.Selective memoryThusday 9:15 am. Main Stage. The show began. Here’s what stood out for me.Consuming API is mainstream and you can make money out of itObviously we, API nerds, are accustomed to breath, eat, sleep and live API, but Mark O’Neil showed us that APIs are becoming maintream. They are so incredibily mainstream that anyone use them and therefore these APIs become a vector of shadow IT (for the better or the worse).We are so focused on providing APIs, even if we want to provide good ones, that we don’t see that consuming API is more common than exposing them and that there’s still an entire business to create there: helping people to consume API at large scale.API Business Strategy and MonetizationConsuming API is mainstream so providing API is more and more important. You may even, like Susan Danziger, face unexpected API challenges. Ziggio was a recrutment platform before becoming a video API service. They had to build a video recording component (with an API) and realize that it was a wonderful product. This product allowed Ziggio to turn to an API based model company and turn its competitor into customers.Once you provide API, you’ll have to find the right monetization model. As Mark O’Neil and Susan Danziger stated: API monetization doesn’t just mean charging for API calls. Finding a good model is hard. For Ziggio, the success came from the Mickey Mouse model, based on how Disney was monetizing its licences.  Whatever the model you choose, allways give the means to let your customers know what the bill will be (with a simulator for instance).ArchitectureArchitecture is not a matter of belief, it’s a matter of context and purpose. Erin McKean reminded us that in a very entertaining and insightful talk which showed us how the Wordnik architecture was being simplified. When designing architecture you MUST know the constraints to make the right decision. James Higginbotham also told us to step back from digital transformation focusing only on technology. We need to choose tools wisely with a purpose, a goal and not just because it’s cool and shining new (who said GraphQL and microservices?).The future of API architecture’s scalability lies in event driven architecture instead of request driven architecture told us Mark O’Neil. But it’s mainstream present lies in managed service like AWS API Gateway and Lambda as told us Erin McKean: these solutions lower heavily the knowledge and expertise needed to handle scalability. In the last month zero time was spent on this new architecture, and it costs less money.The future is dark for big API management solutions: Mark O’Neil told us that the microgateway , a small low-footprint, scriptable, API gateway in nginx or node.js is becoming mainstream.Design &amp; GovernanceWhen you provide an API, you don’t do that just because. You do that hoping that people will use it. So don’t be a jerk: take care of what you provide and how you provide it.  My parts are showing?C3PODo you know how your microwave oven works? Probably not. But, still, you can use it by using its simple interface which do not mirror its internal organization. This is the perfect example of an outside in design approach.But the design road to hell is paved with good intentions. The desire of perfection will be hit by reality. As Matt Bernier tolds us: People will not care about a bad designed canonical REST API.If you design API, listen to James Higginbotham “Consumers don’t care about what’s behind the API. Be outside in and not inside out” and Mark O’Neil “Don’t dump your internal data model on your mobile clients!” (who said GraphQL?).  And don’t dare to think that the outside in approach is only a technical matter or you may see a snarling Matthew Reinbold looking at you with fierce eyes. He reminded us that Conway’s law waits in the darkness like a sword of Damocles hanging upon your API design. Internal organization is different from external perception and mirroring it in an API may not be the best idea. James Higginbotham even urge enterprises to get rid of project based IT and embrace product based IT. Splitting resource on multiple teams or building separate APIs from each entity in a big group will not provide a unifed view and consistent, understandable and usable API.Beyond the risk of having people NOT using your API, you may even loose customers because your API sucks. Amber Fallon asked us: “what will happen when a bank provides a terrible API which is used in a popular pfm (personal finance management) app with other banks API?”, customers may just switch to the bank offering the best experience with this pfm application.You get it now. You have to take care of your design and do it the best way. So, as Jeremiah Lee told us: work HARD on API design so it will be easy to use on the client side.  DX = SPEC + DOC + LIBAPI design is only an ingredient in the developer experience (DX) recipe. Take care of all aspects of API consuming. As Matt Bernier explained, developer experience is a combination of API specification documentation and client libraries.Once designed the hard work is not over. Your API WILL evolve. You WILL introduce breaking changes. You’ll have to find an incentive to make your consumers move to the new version of your API, especially for technical upgrades.Jeremiah Lee showed us that when migrating from Oauth1 to Oauth2, introducing new functionnalities only in the Oauth2 version of the Fitbit API was a successful strategy.Even if developers suck at designing API (just kidding), some of your dev may have good ideas. At Fitbit, developers can submit API modification by making a pull request on an OpenAPI specification.Law and OrderJournalist by trade, lawyer by training, Sarah Jeong bringed us the story of the epic Oracle vs Google battle with her amazing talk You wouldn’t reimplement an API.  This appalling and insightful story reminded us that explaining what is an API to non technical people (the jury), especially in a trial, is quite a challenge. Did the jury understand? Probably not. They may have abandoned after trying to read source code with notepad. Don’t get me wrong, the problem is not with the jury but with what they have faced.  Finally Google won… for the time being. But what are the consequences? Nobody knows.  You can read the full story in Sarah Jeong’s post In Oracle v. Google, a Nerd Subculture Is on Trial.Chaos, opportunities and attentionMike Amundsen unleashed a life-saving chaos upon us. He showed us how chaos saved Nintendo from financial ruin.  Alas, Radar Scope was not a hit in America. In fact, it sold only 1,000 units, leaving 2,000 arcade machines with very expensive hardware sitting in Nintendo’s warehouse. The implications were potentially devastating. Nintendo could either give up, and face financial ruin, or it could develop a conversion kit that would turn those cabinets into something marketable. The secret history of Donkey Kong by Travis FahsHiroshi Yamauchi, CEO of Nintendo, chose to give the lead of this last chance project to a young and inexperienced Shigeru Miyamoto … the future creator of Super Mario. Miyamoto created of totally new type of game, Donkey Kong, that was a huge success. He broke all the existing video games rules because he was not aware of them.Mike showed us also us we needed leaders who can maintain stability around chaos. Serendipity needs a fertile ground, we must create openness to enable new ideas. Opportunities will come from the people around us. On the contrary, asking for data and measurements is the best way to stop creative works.On a more personal level, he told us that our life is like a lego box and not like a jigsaw that has only one way to get it right. We need to create whitespace for ourselves to think. When working on something, we need a break, we need to do something else to refuel our brain and free it. And Jeremiah Lee gave us this whitespace at API Strat! Before his talk he made all the room moving, jumping, running in place, yelling, refueling everyone.  Charles Ashley told us his story, how he came to create the Cultivating Coders Foundation. He reminded us that we shouldn’t take for granted our heavily connected life. In this world, even in developed countries, people still have to go to a library to have access to knowledge.And opportunities heavily depend on what you can access. So he asked us: are you committed or interested?.  My friend, Kin Lane, the API Evangelist, captured the public attention with an unvarnished talk Drone Recovery In The Attention Economy. He shared with us his very personal story, leaving me thoughtful on my very existence. I urge you to read this story on the API Evangelist blog.  “Attention” is a noun, but it refers to an action and/or a state of being. Attention is a mental activity. An earnest activity – which I particularly like.Kin LanePay attention to yourself, to your life, to your job, to your family, to the people around you.People FirstFriday 10pm. So there we were the last API nerds standing, having a long but last discussion before flying back home. All topics and items, weither technical or personnal, sticking in my selective memory have something in common. This last discussion was about this common denominator too.People.  No single piece of technology is what truly matters, not even the API, it all depends on what I do with them, and how we empower (or hurt) humans with them. This is a human story. This is my story. It is not a technology story. It is my personal journey. The technology is just one of the tools in my toolbox. Kin LaneWhen we do API (or anything), we must not think code first or API first. We must think people first.The people directly involved by our projects. What problem are we solving? Does our architecture/solution can be created and managed easily by people? Does our API/Service/Product is useable by people? People ARE what will make our projects succeed.But we also need to think about the people beyond our projects. What do we do to help people around us? Are we committed?So maybe in the future will we try to talk less about how we build APIs (but we still need to talk about it) and more about what we (try to) solve with them.Thanks to all people involved, it was an awesome trip, it was an awesome conference.See you at next API Strat.Boston Library Photography by Cinzia Dosa Lauret"
},{
    "id": "68",
    "type": "post",
    "title": "OpenAPI Trek Series - Part 2 - OpenAPI Trek Into Fastness",
    "url": "https://apihandyman.io/openapi-trek-into-fastness-nordic-apis-summit-2016/",
    "banner": "https://apihandyman.io/images/openapi-trek-into-fastness-nordic-apis-summit-2016/banner.png",
    "description": "Often reduced to Swagger UI and seen purely as a solution for generating API documentation, the OpenAPI (fka. Swagger) Specification format offers many possibilities that span the full API lifecycle. In this session we will identify some of the many advantages of this API definition from design to production, including topics such as design, mock, development, test, documentation continuous delivery, securely evolve an existing API. All this contributing in accelerating and securing API&#39;s lifecycle.",
    "body": "After API Days London, I’ve been to the Nordic APIs Summit in Stockholm for the second part of my OpenAPI specification (fka. Swagger specification) talk series with OpenAPI Trek Into Fastness. Fastness means being fast, but it also means being secured. In this session, I demonstrate how to secure and accelerate APIs’ lifecycle with the OpenAPI specification.       OpenAPI Trek Series                      This 3 talk series provide insight on what is the OpenAPI Specification and how to take advantage of it during the whole API life cycle, especially for design and documentation, and also how to use it to secure and accelerate API creations and evolutions.                                                      1 - OpenAPI Trek                                      2 - OpenAPI Trek Into Fastness                                      3 - OpenAPI Trek Beyond API Documentation                                      AbstractOften reduced to Swagger UI and seen purely as a solution for generating API documentation, the OpenAPI (fka. Swagger) Specification format offers many possibilities that span the full API lifecycle. In this session we will identify some of the many advantages of this API definition from design to production, including topics such as design, mock, development, test, documentation continuous delivery, securely evolve an existing API. All this contributing in accelerating and securing API’s lifecycle.Video                                                This content is hosted on youtube.com.                By showing this third party content you accept YouTube (Google)'s                     privacy policy.                                                    Show third party content                                                                    Remember my choice                        (can be changed in privacy settings)                                                                                      SlidesDownload PDFOpen PDF    "
},{
    "id": "69",
    "type": "post",
    "title": "API Style Guides Fireside Chat with Ronnie Mitra (API Days London 2016)",
    "url": "https://apihandyman.io/api-style-guides-fireside-chat-with-ronnie-mitra-api-days-london-2016/",
    "banner": "https://apihandyman.io/images/api-style-guides-fireside-chat-with-ronnie-mitra-api-days-london-2016/banner.png",
    "description": "API Days London 2016, take 2! I was very happy when Ronnie Mitra (@mitraman) from the API Academy invited me to do a fireside chat on API Style Guides at API Days London.",
    "body": "API Days London 2016, take 2! I was very happy when Ronnie Mitra (@mitraman) from the API Academy invited me to do a fireside chat on API Style Guides at API Days London. Here’s the video:                                                This content is hosted on youtube.com.                By showing this third party content you accept YouTube (Google)'s                     privacy policy.                                                    Show third party content                                                                    Remember my choice                        (can be changed in privacy settings)                                                                                      "
},{
    "id": "70",
    "type": "post",
    "title": "OpenAPI Trek Series - Part 1 - OpenAPI Trek",
    "url": "https://apihandyman.io/openapi-trek-api-days-london-2016/",
    "banner": "https://apihandyman.io/images/openapi-trek-api-days-london-2016/banner.png",
    "description": "For many still known as Swagger, the OpenAPI specification is often reduce to auto-generated API documentation. But the OpenAPI specification universe is boundless. Design, mock, development, test, documentation continuous delivery, governance, deployment... there are countless possibilities that span the full API lifecycle. Let&#39;s board the starship OpenAPI to explore unexpected use cases, to seek out new usage and new ideas, to boldly go where almost no one has gone before.",
    "body": "I was thrilled to start my OpenAPI specification (fka. Swagger specification) talk series at API Days London with this first part simply titled OpenAPI Trek. This first talk, OpenAPI Trek, aims to explain what is the OpenAPI specification and how it can be extensively used throughout the API lifecycle.      OpenAPI Trek Series                      This 3 talk series provide insight on what is the OpenAPI Specification and how to take advantage of it during the whole API life cycle, especially for design and documentation, and also how to use it to secure and accelerate API creations and evolutions.                                                      1 - OpenAPI Trek                                      2 - OpenAPI Trek Into Fastness                                      3 - OpenAPI Trek Beyond API Documentation                                      AbstractFor many still known as Swagger, the OpenAPI specification is often reduce to auto-generated API documentation. But the OpenAPI specification universe is boundless. Design, mock, development, test, documentation continuous delivery, governance, deployment… there are countless possibilities that span the full API lifecycle. Let’s board the starship OpenAPI to explore unexpected use cases, to seek out new usage and new ideas, to boldly go where almost no one has gone before.Video                                                This content is hosted on youtube.com.                By showing this third party content you accept YouTube (Google)'s                     privacy policy.                                                    Show third party content                                                                    Remember my choice                        (can be changed in privacy settings)                                                                                      SlidesDownload PDFOpen PDF    "
},{
    "id": "71",
    "type": "post",
    "title": "HTTP Status Trek (REST Fest 2016)",
    "url": "https://apihandyman.io/http-status-trek-rest-fest-2016/",
    "banner": "https://apihandyman.io/images/http-status-trek-rest-fest-2016/banner.png",
    "description": "I had the luck to go back to REST Fest, this second time was as awesome as last one. Here’s the video and slides of my 5 in 5 about HTTP Status Codes.",
    "body": "I had the luck to go back to REST Fest, this second time was as awesome as last one. Here’s the video and slides of my 5 in 5 about HTTP Status Codes.Video                                                This content is hosted on vimeo.com.                By showing this third party content you accept Vimeo's                     cookie policy.                                                    Show third party content                                                                    Remember my choice                        (can be changed in privacy settings)                                                                                      SlidesDownload PDFOpen PDF    "
},{
    "id": "72",
    "type": "post",
    "title": "The API Stylebook",
    "url": "https://apihandyman.io/the-api-stylebook/",
    "banner": "https://apihandyman.io/images/the-api-stylebook/banner.png",
    "description": "I’m a thrilled to announce that apistylebook.com is now online. The API Stylebook aims to help API Designers to solve API design matters and build their API design guidelines by providing quick and easy access to selected and categorized resources. Read more on the API Stylebook blog",
    "body": "I’m a thrilled to announce that apistylebook.com is now online.  The API Stylebook aims to help API Designers to solve API design matters and build their API design guidelines by providing quick and easy access to selected and categorized resources.Read more on the API Stylebook blog"
},{
    "id": "73",
    "type": "post",
    "title": "Writing OpenAPI (Swagger) Specification Tutorial Series - Part 8 - Splitting specification file",
    "url": "https://apihandyman.io/writing-openapi-swagger-specification-tutorial-part-8-splitting-specification-file/",
    "banner": "https://apihandyman.io/images/writing-openapi-swagger-specification-tutorial-part-8-splitting-specification-file/banner.png",
    "description": "With previous posts we have learned to produce an OpenAPI specification containing all OpenAPI specification subtleties. Some specification files may become quite large or may contain elements which could be reused in other APIs. Splitting a specification file will help to keep it maintainable by creating smaller files and also help to ensure consistency throughout APIs by sharing common elements.",
    "body": "With previous posts we have learned to produce an OpenAPI specification containing all OpenAPI specification subtleties. Some specification files may become quite large or may contain elements which could be reused in other APIs. Splitting a specification file will help to keep it maintainable by creating smaller files and also help to ensure consistency throughout APIs by sharing common elements.      Writing OpenAPI (Swagger) Specification Tutorial Series                      This tutorial teaches everything about the OpenAPI 2.0 Specification (fka. as Swagger), most of what you’ll read here can still be applied on version 3.If you’re a bit lost in the specification (version 2 or 3), take a look at the OpenAPI Map:                                                                                                      1 - Introduction                                      2 - The basics                                      3 - Simplifying specification file                                      4 - Advanced Data                                      5 - Advanced Input And Output Modeling                                      6 - Defining Security                                      7 - Documentation                                      8 - Splitting specification file                                      9 - Extending the OpenAPI specification                                      In previous parts we’ve learned to create highly accurate API description which can become quite large or may contain elements that can be reused, in this eighth part we’ll learn how to split an OpenAPI specification file into smaller and reusable elements.JSON PointersIn part 3 - Simplifying spefication file we have learned how to simplify the specification by creating reusable elements. In the example below, the Person definition is defined once in definitions and used as  A body parameter in POST /persons  A response schema in GET /persons/{username}  A sub-elements in Persons definition                                                                                                swagger: \"2.0\"info:  version: 1.0.0  title: Simple API  description: A simple API to learn how to write OpenAPI Specificationschemes:  - httpshost: simple.apibasePath: /openapi101paths:  /persons:    get:      summary: Gets some persons      description: Returns a list containing all persons. The list supports paging.      parameters:       - name: pageSize         in: query         description: Number of persons returned         type: integer       - name: pageNumber         in: query         description: Page number         type: integer      responses:        200:          description: A list of Person          schema:            $ref: \"#/definitions/Persons\"    post:      summary: Creates a person      description: Adds a new person to the persons list.      parameters:        - name: person          in: body          description: The person to create.          schema:            $ref: \"#/definitions/Person\"      responses:        204:          description: Persons succesfully created.        400:          description: Persons couldn't have been created.  /persons/{username}:    get:      summary: Gets a person      description: Returns a single person for its username.      parameters:        - name: username          in: path          required: true          description: The person's username          type: string      responses:        200:          description: A Person          schema:            $ref: \"#/definitions/Person\"        404:          description: The Person does not exists.definitions:  Person:    required:      - username    properties:      firstName:        type: string      lastName:        type: string      username:        type: string  Persons:    type: array    items:      $ref: \"#/definitions/Person\"  To use the Person definition in these different places, we use a JSON Pointer (defined by RFC6901):                                                                                                      $ref: \"#/definitions/Person\"  This pointer describes a path in the document, pointing to Person in definitions which is as the root (#) of the current document.But JSON pointers are not only meant to point something within the current document, they can be used to reference something in another document.Basic splittingLet’s see how we can split the file we created in part 3Referencing a local fileWe can create a person.yaml file containing the Person definition:                                                                                                Person:  required:    - username  properties:    firstName:      type: string    lastName:      type: string    username:      type: string  Then we can remove the Person definition in definitions and replace all existing references to person #definitions/Person by a reference to Person in the person.yaml file:                                                                                                swagger: \"2.0\"info:  version: 1.0.0  title: Simple API  description: A simple API to learn how to write OpenAPI Specificationschemes:  - httpshost: simple.apibasePath: /openapi101paths:  /persons:    get:      summary: Gets some persons      description: Returns a list containing all persons. The list supports paging.      parameters:       - name: pageSize         in: query         description: Number of persons returned         type: integer       - name: pageNumber         in: query         description: Page number         type: integer      responses:        200:          description: A list of Person          schema:            $ref: \"#/definitions/Persons\"    post:      summary: Creates a person      description: Adds a new person to the persons list.      parameters:        - name: person          in: body          description: The person to create.          schema:            $ref: \"person.yaml#/Person\"      responses:        204:          description: Persons succesfully created.        400:          description: Persons couldn't have been created.  /persons/{username}:    get:      summary: Gets a person      description: Returns a single person for its username.      parameters:        - name: username          in: path          required: true          description: The person's username          type: string      responses:        200:          description: A Person          schema:            $ref: \"person.yaml#/Person\"        404:          description: The Person does not exists.definitions:  Persons:    type: array    items:      $ref: \"person.yaml#/Person\"  Editing splitted local files with the online editorTools will look for the referenced file (person.yaml) in the same directory as the file containing the reference.But when you use the online editor it does not make sense, such local reference cannot be resolved.                                                Fortunately the editor propose a configuration allowing to set a server to resolve these local references. This configuration is accessible in the Preferences-&gt;Preferences menu:                                                The Pointer Resolution Base Path configuration is on the bottom of the configuration screen:                                                All you need to do is put the referenced yaml files into a web server (with CORS activated) and modify the editor’s configuration to point this server.http-server a lightweight web serverYou can use http-server a lightweight node.js web server:                                                                                        npm install --global http-server  You now can start a web service on any folder:                                                                                        http-server --cors path/to/yaml/folder  or                                                                                        cd path/to/yaml/folderhttp-server --cors .  By default, http-server listens on 8080 port, files will be accessble through http://localhost:8080/&lt;path to file within folder&gt;.The --cors flag is used to activate CORS directive and allow XHR request to this local webserver from the online editor page.Without CORS activated, the editor will not be able to download files.Modifying online editor configurationOnce the web server is started you can modifiy the editor to set the URL to http://localhost:8080/:                                                Files referenced with $ref: &lt;filename&gt;#/example will be downloaded from  http://localhost:8080/&lt;filename&gt;.Once this is done, you may need to do a force refresh (clean cache) of the editor’s the page to get the green bar.                                                CacheWhen you add a reference to a new file (that was not already reference), this new file may not be downloaded automatically resulting in errors (Reference could not be resolved: newfile.yaml). You may need to refresh the editor’s page with cache cleaning to solve this error.FoldersYou’re under no obligation to put all sub-files on a “root” level, you can store them in differents sub-folders.Reference to a file in a folderLet’s move the person.yaml file into a sub-folder folder, the new reference will be like this:                                                                                                            $ref: \"folder/person.yaml#/Person\"  File referencing a file from an upper folderYou can also reference a file outside the current folder. Let’s create a persons.yaml file into a another-folder folder:                                                                                                Persons:  type: array  items:    $ref: \"../folder/person.yaml#/Person\"  This file reference the person.yaml file using .. to get to the upper level.To use persons.yaml, we proceed just like with person.yaml. We remove the Persons definition from the main file and we replace its reference #/definitions/Persons by another-folder/persons.yaml#Persons.Here’s the full file with all definitions externalized (the definitions section has been removed):                                                                                                swagger: \"2.0\"info:  version: 1.0.0  title: Simple API  description: A simple API to learn how to write OpenAPI Specificationschemes:  - httpshost: simple.apibasePath: /openapi101paths:  /persons:    get:      summary: Gets some persons      description: Returns a list containing all persons. The list supports paging.      parameters:       - name: pageSize         in: query         description: Number of persons returned         type: integer       - name: pageNumber         in: query         description: Page number         type: integer      responses:        200:          description: A list of Person          schema:            $ref: \"another-folder/persons.yaml#/Persons\"    post:      summary: Creates a person      description: Adds a new person to the persons list.      parameters:        - name: person          in: body          description: The person to create.          schema:            $ref: \"folder/person.yaml#/Person\"      responses:        204:          description: Persons succesfully created.        400:          description: Persons couldn't have been created.  /persons/{username}:    get:      summary: Gets a person      description: Returns a single person for its username.      parameters:        - name: username          in: path          required: true          description: The person's username          type: string      responses:        200:          description: A Person          schema:            $ref: \"folder/person.yaml#/Person\"        404:          description: The Person does not exists.  Referencing a remote filesAs you may have guess while modifying the references in the specification and editor configuration, it is also possible to reference a remote file.Remote filesAll we need to do is to put the full file’s URL in the reference:                                                                                        $ref: https://myserver.com/mypath/myfile.yaml#/example  Remember that the server MUST have CORS activated to allow the editor to download the file.We have launched a web server on 8080 port, so all we have to do is add http://localhost:8080/ to the references to Person:                                                                                                            $ref: \"http://localhost:8080/folder/person.yaml#/Person\"  Remote files containing local referencesWhat happen if the remote file reference a local file? (Main file -&gt; Remote file -&gt; Local file).The parser will seek this “local” file on the remote server providing the remote file.If we replace the local to Persons by a remote reference…                                                                                                            $ref: \"http://localhost:8080/another-folder/persons.yaml#/Persons\"  … the person.yaml file referenced “locally” in the persons.yaml file will be loaded from http://localhost:8080 which has served the persons.yaml.Remote files containing remote referencesIf a remote file contains a remote reference (Main file -&gt; Remote file -&gt; Remote file), it will be resolved like in 2.4.1 Remote files.We can replace the person.yaml file local reference by a remote reference in persons.yaml:                                                                                                Persons:  type: array  items:    $ref: \"http://localhost:8080/folder/person.yaml#/Person\"  Multiple items in a single sub-fileWe have put Person and Persons definitions in separate files: this is not an obligation. You can put more than one item in a single file, you only need to use the right JSON Pointer.Person and Person in a single fileIf we concatenate person.yaml and persons.yaml into a single file called definitions.yaml:                                                                                                Person:  required:    - username  properties:    firstName:      type: string    lastName:      type: string    username:      type: stringPersons:  type: array  items:    $ref: \"#/Person\"  Note that in Persons the reference to Person is now #/Person.In the main file we only need to change the filename when reference these two definitions:                                                                                                            $ref: \"definitions.yaml#/Persons\"                                                                                                              $ref: \"definitions.yaml#/Person\"  Organizing content in a sub-fileWithin the sub-file you can organize the content as you wish. Here Person is in SomeDefinitions and Persons is in OtherDefinitions:                                                                                                SomeDefinitions:  Person:    required:      - username    properties:      firstName:        type: string      lastName:        type: string      username:        type: stringOtherDefinitions:  Persons:    type: array    items:      $ref: \"#/SomeDefinitions/Person\"  Note that in Persons the reference to Person is now #/SomeDefinitions/Person.In the main file we have to modify the path to get the item in the sub-file for these two definitions:                                                                                                            $ref: \"definitions.yaml#/OtherDefinitions/Persons\"                                                                                                              $ref: \"definitions.yaml#/SomeDefinitions/Person\"  Definitions, Responses, ParametersWhat we have done with Person and Persons definitions can be done with any reusable items (i.e. using $ref) such as responses and parameters in the Open API Specification file.OpenAPI chainsaw massacreThanks to Mohsen Azimi’s post I’ve discovered that using sub-files for definitions, responses and parameters which obviously use $ref JSON Pointers is not the only way of using sub-files. You can use sub-files for almost anything in the specification.We will split the huge file created in previous post about documentation.Let the chainsaw massacre beginLet’s start with the info section:                                                                                                swagger: '2.0'info:  version: 1.1.0  title: Simple API  description: |    A simple API to learn how to write OpenAPI Specification.    This file uses almost every single aspect of the [Open API Specification](https://openapis.org/).      This API will use JSON.      JSON looks like this:          ```JSON    {      \"key\": \"value\",      \"anotherKey\": \"anotherValue\"    }    ```  termsOfService: http://simple.api/terms-of-service  contact:    name: John Doe    url: http://simple.api/contact    email: contact@simple.api  license:    name: Apache-2.0    url: http://www.apache.org/licenses/LICENSE-2.0  We can put its whole content in a file called info.yaml:                                                                                                version: 1.1.0title: Simple APIdescription: |  A simple API to learn how to write OpenAPI Specification.  This file uses almost every single aspect of the [Open API Specification](https://openapis.org/).    This API will use JSON.    JSON looks like this:      ```JSON  {    \"key\": \"value\",    \"anotherKey\": \"anotherValue\"  }  ```termsOfService: http://simple.api/terms-of-servicecontact:  name: John Doe  url: http://simple.api/contact  email: contact@simple.apilicense:  name: Apache-2.0  url: http://www.apache.org/licenses/LICENSE-2.0  And reference it just like this in info:                                                                                                swagger: '2.0'info:  $ref: info.yaml  The wizard of resolutionWe can do the same thing with paths, definitions, responses and parameters: copy the section content in a sub-file (paths.yaml, definitions.yaml, responses.yaml and parameters.yaml) and reference it in the main file:                                                                                                paths:  $ref: paths.yamldefinitions:  $ref: definitions.yaml  responses:  $ref: responses.yamlparameters:  $ref: parameters.yaml  If you remember previous posts, these sections references each other in many ways, for example in paths.yaml:                                                                                                '/persons/{username}':  parameters:    - $ref: '#/parameters/username'  The username parameter is no longer in the main file and is not in the paths.yaml file but in the parameters.yaml file:                                                                                                username:  name: username  in: path  required: true  description: The person's username  type: string  How could the main file be considered valid in the editor (or in any tool parsing the file)? It’s simply because the sub-files are loaded and then the whole content (file + sub-files) is validated.A less rough splitWe can use JSON pointers for almost anything in the specification as as long as the $ref JSON pointer reference something corresponding to the expected object (or value) in the OpenAPI specification.Referencing object in custom structureAnd as seen earlier in this post we can put many items in a sub-file.The documentation.yaml file contains the data for externalDocs and tags (note the custom structure on line 1 and 6):                                                                                                external:  description: |    **Complete** documentation describing how to use this API  url: http://doc.simple.api/categories:  - name: Persons    description: Everything you need to handle `users` and `friends`    externalDocs:      description: People category documentation      url: http://doc.simple.api/people  - name: Items    description: Everything you need to handle items collected by users    externalDocs:      description: Items category documentation      url: http://doc.simple.api/items  - name: Media    description: Everything you need to handle images    externalDocs:      description: Media category documentation      url: http://doc.simple.api/media  - name: JSLess    description: Specific operations for JS less consumers    externalDocs:      description: JS Less Consumers documentation      url: http://doc.simple.api/jsless  These data are referenced this way in the main file:                                                                                                externalDocs:   $ref: documentation.yaml#/externaltags:  $ref: documentation.yaml#/categories  The security.yaml file contains the data for securityDefinitions and security (note the custom structure on line 20):                                                                                                securityDefinitions:  OauthSecurity:    description: New Oauth security system. Do not use MediaSecurity or LegacySecurity.    type: oauth2    flow: accessCode    authorizationUrl: 'https://oauth.simple.api/authorization'    tokenUrl: 'https://oauth.simple.api/token'    scopes:      admin: Admin scope      user: User scope  MediaSecurity:    description: Specific media security for backward compatibility. Use OauthSecurity instead.    type: apiKey    in: query    name: media-api-key  LegacySecurity:    description: Legacy security system for backward compatibility. Use OauthSecurity instead.    type: basicdefaultSecurity:  - OauthSecurity:    - user  - LegacySecurity: []  Referencing a string or a simple listIt also work for simpler value like a string or a list of string. The schema, host and basepath values can be moved into a single file security.yaml (note the custom structure on line 3 and 4):                                                                                                schemes:  - httpsserver_and_port: simple.apipath: /openapi102  And referenced like this                                                                                                schemes:  $ref: endpoint.yaml#/schemeshost:  $ref: endpoint.yaml#/server_and_portbasePath:  $ref: endpoint.yaml#/path  Reusing a valueAs long as the API consumes and produces the same media types, we define a single value in the mediatypes.yaml file:                                                                                                default:  - application/json  - application/x-yaml  And then we reference this single value in both produces and consumes:                                                                                                consumes:  $ref: mediatypes.yaml#/defaultproduces:  $ref: mediatypes.yaml#/default  A smarter splitThe API we built with the previous parts could be divided in four parts:  Common items like headers, media types, security, definitions, parameters and responses  Persons operations, parameters, responses and definitions  Legacy operations  Images operationsWe can create 4 sub-files and reference them from a main file.commons.yamlIn the commons.yaml file we put every items that can be reused across other files:                                                                                                securityDefinitions:  OauthSecurity:    description: New Oauth security system. Do not use MediaSecurity or LegacySecurity.    type: oauth2    flow: accessCode    authorizationUrl: 'https://oauth.simple.api/authorization'    tokenUrl: 'https://oauth.simple.api/token'    scopes:      admin: Admin scope      user: User scope  MediaSecurity:    description: Specific media security for backward compatibility. Use OauthSecurity instead.    type: apiKey    in: query    name: media-api-key  LegacySecurity:    description: Legacy security system for backward compatibility. Use OauthSecurity instead.    type: basicdefaultSecurity:  - OauthSecurity:    - user  - LegacySecurity: []defaultMediatypes:  - application/json  - application/x-yamldefaultHeaders:  X-Rate-Limit-Remaining:    description: How many calls consumer can do    type: integer  X-Rate-Limit-Reset:    description: When rate limit will be reset    type: string    format: date-timeparameters:  userAgent:    name: User-Agent    description: All API consumers MUST provide a user agent    type: string    in: header    required: true  pageSize:    name: pageSize    in: query    description: Number of items returned    type: integer    format: int32    minimum: 0    exclusiveMinimum: true    maximum: 100    exclusiveMaximum: false    multipleOf: 10    default: 20  pageNumber:    name: pageNumber    in: query    description: Page number    type: integer    default: 1responses:  Standard500ErrorResponse:    description: An unexpected error occured.    headers:      $ref: '#/defaultHeaders'    schema:      $ref: '#/definitions/Error'  TotallyUnexpectedResponse:    description: A totally unexpected response    headers:      $ref: '#/defaultHeaders'definitions:  ErrorMessage:    title: MultiDeviceErrorMessage    description: An error message with a long and a short description    required:      - longMessage      - shortMessage    properties:      longMessage:        description: A long error description        type: string      shortMessage:        description: A short error description        type: string  MultilingualErrorMessage:    title: MultiLingualMultiDeviceErrorMessage    description: An multilingual error message (hashmap) with a long and a short description    additionalProperties:      $ref: '#/definitions/ErrorMessage'    properties:      defaultLanguage:        $ref: '#/definitions/ErrorMessage'    example:      defaultLanguage:        longMessage: We're deeply sorry but an error occured        shortMessage: Error      fr:        longMessage: Nous sommes désolé mais une erreur est survenu        shortMessage: Erreur          Error:    title: MultiLingualMultiDeviceError    description: Give full information about the problem    required:      - code      - message    properties:      code:        description: A human readable code (death to numeric error codes!)        type: string        enum:          - DBERR          - NTERR          - UNERR        example: UNERR      message:        $ref: '#/definitions/MultilingualErrorMessage'  Paging:    required:      - totalItems      - totalPages      - pageSize      - currentPage    properties:      totalItems:        type: integer      totalPages:        type: integer      pageSize:        type: integer      currentPage:        type: integer  images.yamlIn the images.yaml file we put both /images and /images/{id} paths informations:                                                                                                  images:    parameters:      - $ref: 'commons.yaml#/parameters/userAgent'    post:      summary: Uploads an image      description: Upload an image, will return an image id.       operationId: storeImage      externalDocs:        description: How to upload media        url: http://doc.simple.api/media/upload      tags:        - Media      security:        - MediaSecurity: []      consumes:        - multipart/form-data      parameters:        - name: image          in: formData          type: file      responses:        '200':          description: Image's ID          schema:            properties:              imageId:                type: string          headers:            $ref: commons.yaml#/defaultHeaders        '500':          $ref: 'commons.yaml#/responses/Standard500ErrorResponse'        default:          $ref: 'commons.yaml#/responses/TotallyUnexpectedResponse'  images-imageId:    parameters:      - $ref: 'commons.yaml#/parameters/userAgent'    get:      summary: Gets an image      description: Return an image       operationId: readImage      tags:        - Media      parameters:        - name: imageId          in: path          required: true          type: string      produces:        - image/png        - image/gif        - image/jpeg        - application/json        - application/x-yaml      responses:        '200':          description: The image          headers:            $ref: commons.yaml#/defaultHeaders        '404':          description: Image do not exists          headers:            $ref: commons.yaml#/defaultHeaders        '500':          $ref: 'commons.yaml#/responses/Standard500ErrorResponse'        default:          $ref: 'commons.yaml#/responses/TotallyUnexpectedResponse'  Note that all references to common items point to commons.yaml.legacy.yamlSame for the /js-less-consumer-persons path we put in legacy.yaml file in js-less-consumer-persons:                                                                                                js-less-consumer-persons:  parameters:    - $ref: 'commons.yaml#/parameters/userAgent'  post:    summary: Creates a person    description: For JS-less partners    operationId: createUserJS    deprecated: true    tags:      - JSLess      - Persons    security:      - OauthSecurity:        - admin      - LegacySecurity: []    consumes:      - application/x-www-form-urlencoded    produces:      - text/html    parameters:      - name: username        in: formData        required: true        pattern: '[a-z0-9]{8,64}'        minLength: 8        maxLength: 64        type: string      - name: firstname        in: formData        type: string      - name: lastname        in: formData        type: string      - name: dateOfBirth        in: formData        type: string        format: date    responses:      '204':        description: Person succesfully created.        headers:          $ref: 'commons.yaml#/defaultHeaders'      '400':        description: Person couldn't have been created.        headers:          $ref: 'commons.yaml#/defaultHeaders'      '500':        description: An error occured.        headers:          $ref: 'commons.yaml#/defaultHeaders'      default:        $ref: 'commons.yaml#/responses/TotallyUnexpectedResponse'  persons.yamlAll persons items go in the persons.yaml:  each path go in its own named section (like persons-username for /persons/{username})  all persons specific definitions goes in definitions (and can be referenced with #definition/name)  all persons specific responses goes in responses (and can be referenced with #responses/name)  all persons specific parameters goes in parameters (and can be referenced with #parameters/name)                                                                                                persons:  parameters:    - $ref: 'commons.yaml#/parameters/userAgent'  get:    summary: Gets some persons    description: Returns a list containing all persons. The list supports paging.    operationId: searchUsers    tags:      - Persons    parameters:      - $ref: 'commons.yaml#/parameters/pageSize'      - $ref: 'commons.yaml#/parameters/pageNumber'      - $ref: '#/parameters/includeNonVerifiedUsers'      - $ref: '#/parameters/sortPersons'    responses:      '200':        description: A list of Person        schema:          $ref: '#/definitions/Persons'        headers:          $ref: commons.yaml#/defaultHeaders      '500':        $ref: 'commons.yaml#/responses/Standard500ErrorResponse'      default:        $ref: 'commons.yaml#/responses/TotallyUnexpectedResponse'  post:    summary: Creates a person    description: Adds a new person to the persons list.    operationId: createUser    tags:      - Persons    security:      - OauthSecurity:        - admin      - LegacySecurity: []    parameters:      - name: person        in: body        required: true        description: The person to create.        schema:          $ref: '#/definitions/Person'    responses:      '204':        description: Person succesfully created.        headers:          $ref: commons.yaml#/defaultHeaders      '400':        description: Person couldn't have been created.        headers:          $ref: commons.yaml#/defaultHeaders      '500':        $ref: 'commons.yaml#/responses/Standard500ErrorResponse'      default:        $ref: 'commons.yaml#/responses/TotallyUnexpectedResponse'persons-username:  parameters:    - $ref: '#/parameters/username'    - $ref: 'commons.yaml#/parameters/userAgent'  get:    summary: Gets a person    description: Returns a single person for its username.    operationId: readPerson    tags:      - Persons    responses:      '200':        description: A Person        schema:          $ref: '#/definitions/Person'        headers:          $ref: commons.yaml#/defaultHeaders      '404':        $ref: '#/responses/PersonDoesNotExistResponse'      '500':        $ref: 'commons.yaml#/responses/Standard500ErrorResponse'      default:        $ref: 'commons.yaml#/responses/TotallyUnexpectedResponse'  delete:    summary: Deletes a person    description: Delete a single person identified via its username    operationId: deletePerson    tags:      - Persons    responses:      '204':        description: Person successfully deleted.        headers:          $ref: commons.yaml#/defaultHeaders      '404':        $ref: '#/responses/PersonDoesNotExistResponse'      '500':        $ref: 'commons.yaml#/responses/Standard500ErrorResponse'      default:        $ref: 'commons.yaml#/responses/TotallyUnexpectedResponse'persons-username-friends:  parameters:    - $ref: '#/parameters/username'    - $ref: 'commons.yaml#/parameters/userAgent'  get:    summary: Gets a person's friends    description: Returns a list containing all persons. The list supports paging.    operationId: readPersonsFriends    tags:      - Persons    parameters:      - $ref: 'commons.yaml#/parameters/pageSize'      - $ref: 'commons.yaml#/parameters/pageNumber'      - $ref: '#/parameters/includeNonVerifiedUsers'      - $ref: '#/parameters/sortPersons'    responses:      '200':        description: A person's friends list        schema:          $ref: '#/definitions/PagedPersons'        headers:          $ref: commons.yaml#/defaultHeaders      '404':        $ref: '#/responses/PersonDoesNotExistResponse'      '500':        $ref: 'commons.yaml#/responses/Standard500ErrorResponse'      default:        $ref: 'commons.yaml#/responses/TotallyUnexpectedResponse'persons-username-collecting-items:  parameters:    - $ref: '#/parameters/username'    - $ref: 'commons.yaml#/parameters/userAgent'  get:    summary: Gets a person's collecting items list    description: |      Returns a list containing all items this person is looking for.        The list supports paging.    operationId: readPersonsCollectingItems    tags:      - Items    parameters:      - $ref: 'commons.yaml#/parameters/pageSize'      - $ref: 'commons.yaml#/parameters/pageNumber'      - $ref: '#/parameters/filterItemTypes'    responses:      '200':        description: A collected items list        schema:          $ref: '#/definitions/PagedCollectingItems'        headers:          $ref: commons.yaml#/defaultHeaders        examples:          application/json:            {              \"totalItems\": 10,              \"totalPage\": 4,              \"pageSize\": 3,              \"currentPage\": 2,              \"items\":               [                {                   \"itemType\": \"Vinyl\",                  \"maxPrice\": 20,                  \"imageId\": \"98096838-04eb-4bac-b32e-cd5b7196de71\",                  \"albumName\": \"Captain Future Original Soundtrack\",                  \"artist\": \"Yuji Ohno\"                },                {                   \"itemType\": \"VHS\",                  \"maxPrice\": 10,                  \"imageId\": \"b74469bc-e6a1-4a90-858a-88ef94079356\",                  \"movieTitle\": \"Star Crash\",                  \"director\": \"Luigi Cozzi\"                },                {                   \"itemType\": \"AudioCassette\",                  \"maxPrice\": 10,                  \"imageId\": \"b74469bc-e6a1-4a90-858a-88ef94079356\",                  \"albumName\": \"Star Wars\",                  \"artist\": \"John Williams\"                }              ]            }      '404':        $ref: '#/responses/PersonDoesNotExistResponse'      '500':        $ref: 'commons.yaml#/responses/Standard500ErrorResponse'      default:        $ref: 'commons.yaml#/responses/TotallyUnexpectedResponse'definitions:  Person:    title: Human    description: A person which can be the user itself or one of his friend    required:      - username    properties:      firstName:        description: first name        type: string        example: John      lastName:        description: last name        type: string        example: Doe      username:        description: Username used to connect to the service        type: string        pattern: '[a-z0-9]{8,64}'        minLength: 8        maxLength: 64        example: john1doe6      dateOfBirth:        description: Date of birth        type: string        format: date        example: 1978-06-21      lastTimeOnline:        description: The last time this person was connected to the service as a         type: string        format: date-time        readOnly: true        example: 2016-06-10T12:36:58.014Z      avatarBase64PNG:        description: An avatar PNG image as a base64 encoded string ready to use as an src in img html tag        type: string        format: byte        default: data:image/png;base64,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      spokenLanguages:        $ref: '#/definitions/SpokenLanguages'  SpokenLanguages:    title: Languages    description: A hashmap of spoken languages    additionalProperties:      description: An additional spoken language      type: string    properties:      defaultLanguage:        description: Default spoken language        type: string        default: english    example:      defaultLanguage: french      it: italian      fr: french  Persons:    title: Humans    description: A list of users or friends    required:      - items    properties:      items:        description: Array containg the list        type: array        minItems: 10        maxItems: 100        uniqueItems: true        items:          $ref: '#/definitions/Person'        example:          - firstname: Robert            lastname\": Doe            username\": robdo            dateOfBirth: 1970-01-28            lastTimeOnline: 2016-04-10T14:36:58.014Z          - firstname: Jane            lastname: Doe            username: jdoe123            dateOfBirth: 1980-05-12            lastTimeOnline: 2016-05-12T19:23:59.014Z  CollectingItem:    discriminator: itemType    required:      - itemType    properties:      itemType:        description: |          An item can be of different type:                      type | definition          -----|-----------          Vinyl| #/definitions/Vinyl          VHS  | #/definitions/VHS          AudioCassette | #/definitions/AudioCassette        type: string        enum:          - AudioCassette          - Vinyl          - VHS      imageId:        type: string      maxPrice:        type: number        format: double        minimum: 0        maximum: 10000        exclusiveMinimum: true        exclusiveMaximum: false  Vinyl:    allOf:      - $ref: '#/definitions/CollectingItem'      - required:          - albumName          - artist        properties:          albumName:            type: string          artist:            type: string  VHS:    allOf:      - $ref: '#/definitions/CollectingItem'      - required:          - movieTitle        properties:          movieTitle:            type: string          director:            type: string  AudioCassette:    allOf:      - $ref: '#/definitions/CollectingItem'      - required:          - albumName          - artist        properties:          albumName:            type: string          artist:            type: string  PagedPersons:    allOf:      - $ref: '#/definitions/Persons'      - $ref: 'commons.yaml#/definitions/Paging'  PagedCollectingItems:    allOf:      - properties:          items:            type: array            minItems: 10            maxItems: 100            uniqueItems: true            items:              $ref: '#/definitions/CollectingItem'      - $ref: 'commons.yaml#/definitions/Paging'responses:  PersonDoesNotExistResponse:    description: Person does not exist.    headers:      $ref: commons.yaml#/defaultHeadersparameters:  username:    name: username    in: path    required: true    description: The person's username    type: string  includeNonVerifiedUsers:    name: includeNonVerifiedUsers    in: query    description: Result will not include non verified user by default if this parameter is not provided    type: boolean    default: false    allowEmptyValue: true  sortPersons:    name: sort    in: query    description: Result will be sorted by lastTimeOnline descending and username ascending by default if this parameter is not provided    type: array    uniqueItems: true    minItems: 1    maxItems: 3    collectionFormat: pipes    items:      type: string      pattern: '[-+](username|lastTimeOnline|firstname|lastname)'    default:      - -lastTimeOnline      - +username  filterItemTypes:    name: itemType    in: query    description: Filter collected items on their type    type: array    collectionFormat: multi    uniqueItems: true    items:      type: string      enum:        - AudioCassette        - Vinyl        - VHS  full main fileHere’s the full main file where we reference the 4 sub-files:                                                                                                swagger: '2.0'info:  version: 1.1.0  title: Simple API  description: |    A simple API to learn how to write OpenAPI Specification.    This file uses almost every single aspect of the [Open API Specification](https://openapis.org/).      This API will use JSON.      JSON looks like this:          ```JSON    {      \"key\": \"value\",      \"anotherKey\": \"anotherValue\"    }    ```  termsOfService: http://simple.api/terms-of-service  contact:    name: John Doe    url: http://simple.api/contact    email: contact@simple.api  license:    name: Apache-2.0    url: http://www.apache.org/licenses/LICENSE-2.0externalDocs:   description: |    **Complete** documentation describing how to use this API  url: http://doc.simple.api/tags:  - name: Persons    description: Everything you need to handle `users` and `friends`    externalDocs:      description: People category documentation      url: http://doc.simple.api/people  - name: Items    description: Everything you need to handle items collected by users    externalDocs:      description: Items category documentation      url: http://doc.simple.api/items  - name: Media    description: Everything you need to handle images    externalDocs:      description: Media category documentation      url: http://doc.simple.api/media  - name: JSLess    description: Specific operations for JS less consumers    externalDocs:      description: JS Less Consumers documentation      url: http://doc.simple.api/jsless      schemes:  - httpshost: simple.apibasePath: /openapi101consumes:  $ref: commons.yaml#/defaultMediatypesproduces:  $ref: commons.yaml#/defaultMediatypessecurityDefinitions:  $ref: commons.yaml#/securityDefinitionssecurity:  $ref: commons.yaml#/defaultSecuritypaths:  /persons:    $ref: 'persons.yaml#/persons'  /js-less-consumer-persons:    $ref: 'legacy.yaml#/js-less-consumer-persons'  '/persons/{username}':    $ref: 'persons.yaml#/persons-username'  '/persons/{username}/friends':    $ref: 'persons.yaml#/persons-username-friends'  '/persons/{username}/collecting-items':    $ref: 'persons.yaml#/persons-username-collecting-items'  /images:    $ref: 'images.yaml#/images'  /images/{imageId}:    $ref: 'images.yaml#/images-imageId'  Valid sub-filesIf we put the last persons.yaml file content in the editor, it ends with these errors:                                                Splitting a huge Open API Specification file to keep it maintainable is a great idea but if you cannot validate sub-files against the specification, you gain almost nothing.Making commons.yaml validIf we put the commons.yaml file created earlier in the editor we get these errors:  Missing required property: swagger  Missing required property: info  Missing required property: paths  Additional properties not allowed: defaultHeaders,defaultMediatypes,defaultSecurityLet’s see how we can fix these errors.Missing swagger propertyWe just need to add this line on file’s top:                                                                                                swagger: \"2.0\"  Missing info propertyWe add an short info section after swagger:                                                                                                info:  version: 1.0.0  title: Common elements  description: Shared elements in all API  Missing paths propertyAs we do not define any path in this file we just need to add an empty paths section:                                                                                                paths: {}  Property defaultSecurity not allowedAs the defaultSecurity correspond to the OpenAPI security section we just need to rename it:Invalid commons.yaml file:                                                                                                defaultSecurity:  - OauthSecurity:    - user  - LegacySecurity: []  Valid commons.yaml file:                                                                                                security:  - OauthSecurity:    - user  - LegacySecurity: []  Property defaultMediatypes not alloweddefaultMediaType is not a valid OpenAPI property:                                                                                                defaultMediatypes:  - application/json  - application/x-yaml  We will use produces and consumes to define the default media types. But as we want to define a single set of media type we will use this trick:                                                                                                produces:  - application/json  - application/x-yamlconsumes:  $ref: '#/produces'  In the future if we want to define different sets of media types for produces and consumes, we’ll be ready.Property defaultHeaders not alloweddefaultHeaders is not a valid OpenAPI property:                                                                                                defaultHeaders:  X-Rate-Limit-Remaining:    description: How many calls consumer can do    type: integer  X-Rate-Limit-Reset:    description: When rate limit will be reset    type: string    format: date-time  We will use a dummy response definition DefaultHeaders to declare these default headers:                                                                                                responses:  DefaultHeaders:    description: A dummy response to define default header    headers:      X-Rate-Limit-Remaining:        description: How many calls consumer can do        type: integer      X-Rate-Limit-Reset:        description: When rate limit will be reset        type: string        format: date-time  Of course we need to update common responses to use these headers:                                                                                                  Standard500ErrorResponse:    description: An unexpected error occured.    headers:      $ref: '#/responses/DefaultHeaders/headers'    schema:      $ref: '#/definitions/Error'  TotallyUnexpectedResponse:    description: A totally unexpected response    headers:      $ref: '#/responses/DefaultHeaders/headers'  Making persons.yaml validJust like with commons.yaml, if we put persons.yaml content in the editor we get some errors:  Missing required property: swagger  Missing required property: info  Reference could not be resolved: commons.yaml#/defaultHeaders  Missing required property: paths  Additional properties not allowed: persons-username-collecting-items,persons-username-friends,persons-username,personsMissing swagger and info propertiesWe just add swagger and info like for commons.yaml:                                                                                                swagger: \"2.0\"  info:  version: 1.0.0  title: Persons Sub-API  description: Persons operations, definitions, parameters and responsessecurityDefinitions:  $ref: commons.yaml#/securityDefinitions  commons.yaml#/defaultHeaders reference could not be resolvedAs the commons.yaml structure has been modified concerning default headers we need to replace these references:                                                                                                          $ref: commons.yaml#/defaultHeaders  by this one:                                                                                                              $ref: 'commons.yaml#/responses/DefaultHeaders/headers'  Missing paths and additional properties not allowedWe have defined custom properties for each path relative to persons operations, therefore there is no paths section and our custom properties (like persons) are not allowed by the OpenAPI specification.                                                                                                persons:  parameters:    - $ref: 'commons.yaml#/parameters/userAgent'  get:    summary: Gets some persons    description: Returns a list containing all persons. The list supports paging.    operationId: searchUsers  We need to add a paths section and put all our path in it using the correct path value as key:                                                                                                paths:  '/persons':      parameters:        - $ref: 'commons.yaml#/parameters/userAgent'      get:        summary: Gets some persons        description: Returns a list containing all persons. The list supports paging.        operationId: searchUsers  New errors: Security definition could not be resolvedOnce this is done, 2 new errors appear:  Security definition could not be resolved: OauthSecurity  Security definition could not be resolved: LegacySecurityNow that we have a valid structure, the paths have been parsed and the parser detected missing security definitions. To solve this error, we add these definitions by referencing the commons.yaml file:                                                                                                securityDefinitions:  $ref: commons.yaml#/securityDefinitions  images.yaml and legacy.yamlFor images.yaml and legacy.yaml we do exactly the same things as we’ve done with persons.yaml.Here the images.yaml file modified (partial view):                                                                                                swagger: \"2.0\"  info:  version: 1.0.0  title: Images Sub-API  description: images operationssecurityDefinitions:  $ref: commons.yaml#/securityDefinitionspaths:   /images:  Here the legacy.yaml file modified (partial view):                                                                                                swagger: \"2.0\"  info:  version: 1.0.0  title: Legacy Sub-API  description: Legacy operationssecurityDefinitions:  $ref: commons.yaml#/securityDefinitionspaths:  /js-less-consumer-persons:  Updating the main fileNow that we have modified all sub-files, if we try to edit the main file we get these errors  Reference could not be resolved: commons.yaml#/defaultMediatypes  Reference could not be resolved: commons.yaml#/defaultSecurity  Reference could not be resolved: persons.yaml#/persons  Reference could not be resolved: images.yaml#/images-imageId  Reference could not be resolved: persons.yaml#/persons-username  Reference could not be resolved: persons.yaml#/persons-username-friends  Reference could not be resolved: persons.yaml#/persons-username-collecting-items  Reference could not be resolved: images.yaml#/images  Reference could not be resolved: legacy.yaml#/js-less-consumer-personsThese errors are of 2 types:  those due to the commons.yaml structure modification  and those due to the persons.yaml, images.yaml and legacy.yaml paths structure modificationsModifiying commons.yaml referencesBefore:                                                                                                consumes:  $ref: commons.yaml#/defaultMediatypesproduces:  $ref: commons.yaml#/defaultMediatypessecurityDefinitions:  $ref: commons.yaml#/securityDefinitionssecurity:  $ref: commons.yaml#/defaultSecurity  After:                                                                                                consumes:  $ref: 'commons.yaml#/consumes'produces:  $ref: 'commons.yaml#/produces'securityDefinitions:  $ref: 'commons.yaml#/securityDefinitions'security:  $ref: 'commons.yaml#/security'  Modifying paths referencesThis is the trickyest part of this tutorial. To reference the /persons path in persons.yaml we used persons.yaml#/persons:                                                                                                paths:  /persons:    $ref: 'persons.yaml#/persons'  But persons.yaml structure has changed from :                                                                                                persons:  parameters:    - $ref: 'commons.yaml#/parameters/userAgent'  get:    summary: Gets some persons    description: Returns a list containing all persons. The list supports paging.    operationId: searchUsers  to:                                                                                                paths:  '/persons':      parameters:        - $ref: 'commons.yaml#/parameters/userAgent'      get:        summary: Gets some persons        description: Returns a list containing all persons. The list supports paging.        operationId: searchUsers  The new reference should be something like persons.yaml#/paths//persons but if we try it, the editor shows an error Reference could not be resolved: persons.yaml#/paths//persons. The / in /persons needs to be escaped, how can we do that?  Evaluation of each reference token begins by decoding any escaped character sequence.  This is performed by first transforming any occurrence of the sequence ‘~1’ to ‘/’RFC6901Before modification:                                                                                                paths:  /persons:    $ref: 'persons.yaml#/persons'  /js-less-consumer-persons:    $ref: 'legacy.yaml#/js-less-consumer-persons'  '/persons/{username}':    $ref: 'persons.yaml#/persons-username'  '/persons/{username}/friends':    $ref: 'persons.yaml#/persons-username-friends'  '/persons/{username}/collecting-items':    $ref: 'persons.yaml#/persons-username-collecting-items'  /images:    $ref: 'images.yaml#/images'  /images/{imageId}:    $ref: 'images.yaml#/images-imageId'  After modification (all / in reference name have been replaced by ~1):                                                                                                paths:  /persons:    $ref: 'persons.yaml#/paths/~1persons'  /js-less-consumer-persons:    $ref: 'legacy.yaml#/paths/~1js-less-consumer-persons'  '/persons/{username}':    $ref: 'persons.yaml#/paths/~1persons~1{username}'  '/persons/{username}/friends':    $ref: 'persons.yaml#/paths/~1persons~1{username}~1friends'  '/persons/{username}/collecting-items':    $ref: 'persons.yaml#/paths/~1persons~1{username}~1collecting-items'  /images:    $ref: 'images.yaml#/paths/~1images'  /images/{imageId}:    $ref: 'images.yaml#/paths/~1images~1{imageId}'  And now the main file and all its sub-files are considered valid by the editor.ConclusionYou are now ready to split any OpenAPI specification file into valid sub-files in any possible ways. In this 8th part you’ve learned how to use JSON pointers in almost any places in an OpenAPI specification to references items from other files and how to create valid sub-files containing partial information. In the next final part (at last) we will learn how to extend the OpenAPI specification."
},{
    "id": "74",
    "type": "post",
    "title": "Writing OpenAPI (Swagger) Specification Tutorial Series - Part 7 - Documentation",
    "url": "https://apihandyman.io/writing-openapi-swagger-specification-tutorial-part-7-documentation/",
    "banner": "https://apihandyman.io/images/writing-openapi-swagger-specification-tutorial-part-7-documentation/banner.png",
    "description": "Previous posts showed how to write a highly accurate description of an API interface contract with the OpenAPI specification. But an interface contract, no matter how brilliant, is nothing without some explainations. A fully documented OpenAPI specification file can provide some useful information and be used as a part of an API’s documentation.",
    "body": "Previous posts showed how to write a highly accurate description of an API interface contract with the OpenAPI specification. But an interface contract, no matter how brilliant, is nothing without some explainations. A fully documented OpenAPI specification file can provide some useful information and be used as a part of an API’s documentation.      Writing OpenAPI (Swagger) Specification Tutorial Series                      This tutorial teaches everything about the OpenAPI 2.0 Specification (fka. as Swagger), most of what you’ll read here can still be applied on version 3.If you’re a bit lost in the specification (version 2 or 3), take a look at the OpenAPI Map:                                                                                                      1 - Introduction                                      2 - The basics                                      3 - Simplifying specification file                                      4 - Advanced Data                                      5 - Advanced Input And Output Modeling                                      6 - Defining Security                                      7 - Documentation                                      8 - Splitting specification file                                      9 - Extending the OpenAPI specification                                      In previous parts we’ve learned to create highly accurate API description, in this seventh part we’ll learn how to use the OpenAPI specification to make it a valuable part of an API documentation.API’s general informationsFirst things first. When using an API, API consumers want to have some general informations about it like its version, its name, some description, term of service, how to contact the API provider, what kind of licencing it uses. The info object placed on root level can be used to provide such information:                                                                                                info:  version: 1.1.0  title: Simple API  description: A simple API to learn how to write OpenAPI Specification  termsOfService: http://simple.api/terms-of-service  contact:    name: John Doe    url: http://simple.api/contact    email: contact@simple.api  license:    name: Apache-2.0    url: http://www.apache.org/licenses/LICENSE-2.0  Categorizing operations with TagsBy using tags on operation level, we can categorize operations. tags is a simple list of names.Single tagThis operation belongs to the Person category:                                                                                                paths:  /persons:    parameters:      - $ref: '#/parameters/userAgent'    get:      summary: Gets some persons      description: Returns a list containing all persons. The list supports paging.      operationId: searchUsers      tags:        - Persons  Multiple tagsAn operation can belong to different categories:                                                                                                  /js-less-consumer-persons:    parameters:      - $ref: '#/parameters/userAgent'    post:      summary: Creates a person      description: For JS-less partners      operationId: createUserJS      deprecated: true      tags:        - JSLess        - Persons  Descriptions everywhereWe can add some descriptions at almost every level of the OpenAPI specification.Security definitionsA description can be added to security definitions:                                                                                                securityDefinitions:  OauthSecurity:    description: New Oauth security system. Do not use MediaSecurity or LegacySecurity.    type: oauth2    flow: accessCode    authorizationUrl: 'https://oauth.simple.api/authorization'    tokenUrl: 'https://oauth.simple.api/token'    scopes:      admin: Admin scope      user: User scope  MediaSecurity:    description: Specific media security for backward compatibility. Use OauthSecurity instead.    type: apiKey    in: query    name: media-api-key  LegacySecurity:    description: Legacy security system for backward compatibility. Use OauthSecurity instead.    type: basic  Schema title and descriptionEach schema (used in a definition, a parameter or a response) can have a title and a description:                                                                                                definitions:  Person:    title: Human    description: A person which can be the user itself or one of his friend                                                                                                    SpokenLanguages:    title: Languages    description: A hashmap of spoken languages  Property descriptionProperties can be described with description:                                                                                                    properties:      firstName:        description: first name        type: string  Parameter’s descriptionWhether defined inline or in parameters section, a parameter can have a description.Inline parameter’s description                                                                                                paths:  /persons:                                                                                                      post:                                                                                                        parameters:        - name: person          in: body          required: true          description: The person to create.          schema:            $ref: '#/definitions/Person'  Reusable parameter’s description                                                                                                parameters:  username:    name: username    in: path    required: true    description: The person's username    type: string  pageSize:    name: pageSize    in: query    description: Number of persons returned  Operation’s summary, description and operationId:An operation can be described with a summary and a longer description. An operationId can be added. It can be used as a link to the implementation running behind the API for example.                                                                                                paths:  /persons:    parameters:      - $ref: '#/parameters/userAgent'    get:      summary: Gets some persons      description: Returns a list containing all persons. The list supports paging.      operationId: searchUsers  Response’s descriptionWhether inline or defined in responses, a response can have a description.Inline response’s description                                                                                                paths:  /persons:    parameters:      - $ref: '#/parameters/userAgent'    get:                                                                                                        responses:        '200':          description: A list of Person  Reusable response’s description                                                                                                responses:  Standard500ErrorResponse:    description: An unexpected error occured.  Reponse’s header’s descriptionHeaders returned with a response can have a description:                                                                                                    headers:      X-Rate-Limit-Remaining:        description: How many calls consumer can do        type: integer      X-Rate-Limit-Reset:        description: When rate limit will be reset        type: string        format: date-time  Tags descriptionsTags can have descriptions. We need to add a tags section on specification file root level, on each item in this list we set a name (corresponding to the name used in tags list on operation level) and a description:                                                                                                tags:  - name: Persons    description: Everything you need to handle users and friends  Using GFM in descriptionsIn almost all description, we can use GFM (Github Flavored Markdown). To check if an object description support GFM, take a look at my visual documentation or the original specification.Note that GFM support can vary depending the tool processing the OpenAPI specification file.Simple multiline descriptionBy adding a | and a new line with a new tab, we can write multiline descriptions:                                                                                                  '/persons/{username}/collecting-items':    parameters:      - $ref: '#/parameters/username'      - $ref: '#/parameters/userAgent'    get:      summary: Gets a person's collecting items list      description: |        Returns a list containing all items this person is looking for.          The list supports paging.  Simple GFM description                                                                                                externalDocs:   description: |    **Complete** documentation describing how to use this API  url: http://doc.simple.api/  Description with array                                                                                                  CollectingItem:    discriminator: itemType    required:      - itemType    properties:      itemType:        description: |          An item can be of different type:                      type | definition          -----|-----------          Vinyl| #/definitions/Vinyl          VHS  | #/definitions/VHS          AudioCassette | #/definitions/AudioCassette        type: string        enum:          - AudioCassette          - Vinyl          - VHS  Description with code                                                                                                swagger: '2.0'info:  version: 1.1.0  title: Simple API  description: |    A simple API to learn how to write OpenAPI Specification.    This file uses almost every single aspect of the [Open API Specification](https://openapis.org/).      This API will use JSON.      JSON looks like this:          ```JSON    {      \"key\": \"value\",      \"anotherKey\": \"anotherValue\"    }    ```  termsOfService: http://simple.api/terms-of-service  ExamplesExamples can be provided for atomic or object properties, definitions, and responses.Atomic property exampleAtomic properties can be illustrated with an example:                                                                                                    properties:      firstName:        description: first name        type: string        example: John      lastName:        description: last name        type: string        example: Doe      username:        description: Username used to connect to the service        type: string        pattern: '[a-z0-9]{8,64}'        minLength: 8        maxLength: 64        example: john1doe6      dateOfBirth:        description: Date of birth        type: string        format: date        example: 1978-06-21      lastTimeOnline:        description: The last time this person was connected to the service as a         type: string        format: date-time        readOnly: true        example: 2016-06-10T12:36:58.014Z  Object property exampleObject properties, can also be illustrated with a complex example complying to the underlying JSON Schema:                                                                                                  Persons:    title: Humans    description: A list of users or friends    required:      - items    properties:      items:        description: Array containg the list        type: array        minItems: 10        maxItems: 100        uniqueItems: true        items:          $ref: '#/definitions/Person'        example:          - firstname: Robert            lastname\": Doe            username\": robdo            dateOfBirth: 1970-01-28            lastTimeOnline: 2016-04-10T14:36:58.014Z          - firstname: Jane            lastname: Doe            username: jdoe123            dateOfBirth: 1980-05-12            lastTimeOnline: 2016-05-12T19:23:59.014Z  Definition ExampleAn example can be defined for the entire definition just like for an object property (it must conforms to its underlying JSON schema):                                                                                                  MultilingualErrorMessage:    title: MultiLingualMultiDeviceErrorMessage    description: An multilingual error message (hashmap) with a long and a short description    additionalProperties:      $ref: '#/definitions/ErrorMessage'    properties:      defaultLanguage:        $ref: '#/definitions/ErrorMessage'    example:      defaultLanguage:        longMessage: We're deeply sorry but an error occured        shortMessage: Error      fr:        longMessage: Nous sommes désolé mais une erreur est survenu        shortMessage: Erreur  Response’s ExampleOn response level, we can provide example, each one corresponding to a media type returned by the operation. Here’s an example for an application/json media type:                                                                                                  '/persons/{username}/collecting-items':                                                                                                      get:                                                                                                        responses:        '200':                                                                                                            examples:            application/json:              {                \"totalItems\": 10,                \"totalPage\": 4,                \"pageSize\": 3,                \"currentPage\": 2,                \"items\":                 [                  {                     \"itemType\": \"Vinyl\",                    \"maxPrice\": 20,                    \"imageId\": \"98096838-04eb-4bac-b32e-cd5b7196de71\",                    \"albumName\": \"Captain Future Original Soundtrack\",                    \"artist\": \"Yuji Ohno\"                  },                  {                     \"itemType\": \"VHS\",                    \"maxPrice\": 10,                    \"imageId\": \"b74469bc-e6a1-4a90-858a-88ef94079356\",                    \"movieTitle\": \"Star Crash\",                    \"director\": \"Luigi Cozzi\"                  },                  {                     \"itemType\": \"AudioCassette\",                    \"maxPrice\": 10,                    \"imageId\": \"b74469bc-e6a1-4a90-858a-88ef94079356\",                    \"albumName\": \"Star Wars\",                    \"artist\": \"John Williams\"                  }                ]              }        '404':          $ref: '#/responses/PersonDoesNotExistResponse'        '500':          $ref: '#/responses/Standard500ErrorResponse'        default:          $ref: '#/responses/TotallyUnexpectedResponse'  Examples precedenceIf we defined examples on multiple levels (property, object, definition, response), it’s always the higher level which is taken into account by tools processing OpenAPI specification file.Operation’s deprecationAn operation can be deprecated by setting deprecated to true:                                                                                                  /js-less-consumer-persons:    parameters:      - $ref: '#/parameters/userAgent'    post:      summary: Creates a person      description: For JS-less partners      operationId: createUserJS      deprecated: true  Links to external API documentationIn most case, the OpenAPI specification file MUST NOT be the only API’s documentation. How to create an application key, use cases, operation chaining and many other things need to be documented. All these other documentations can be separated from the specification file.However, the OpenAPI specification allow to provide links to these other documentations when needed.Link to general API documentationWe can add an externalDoc object on root level with a link to the API documentation.                                                                                                externalDocs:   description: Complete documentation describing how to use this API  url: http://doc.simple.api/  Link to specific operation documentationEach operation can have its own link to an external documentation using the same externalDoc object:                                                                                                  /images:    parameters:      - $ref: '#/parameters/userAgent'    post:      summary: Uploads an image      description: Upload an image, will return an image id.       operationId: storeImage      externalDocs:        description: How to upload media        url: http://doc.simple.api/media/upload  Link to tag documentationA tag’s description can also provide an external link:                                                                                                tags:  - name: Persons    description: Everything you need to handle users and friends    externalDocs:      description: Peopls category documentation      url: http://doc.simple.api/people  ConclusionEven if an OpenAPI specification MUST NOT be the only documentation for an API, it can be a good part of it, and you now have mastered this aspect of the specification. In next post we’ll see how we can split a OpenAPI specification file in different files."
},{
    "id": "75",
    "type": "post",
    "title": "Writing OpenAPI (Swagger) Specification Tutorial Series - Part 6 - Defining Security",
    "url": "https://apihandyman.io/writing-openapi-swagger-specification-tutorial-part-6-defining-security/",
    "banner": "https://apihandyman.io/images/writing-openapi-swagger-specification-tutorial-part-6-defining-security/banner.png",
    "description": "After mastering input and output modeling like a Jedi, let’s see how we can describe API’s security with the OpenAPI specification’s.",
    "body": "After mastering input and output modeling like a Jedi, let’s see how we can describe API’s security with the OpenAPI specification’s.      Writing OpenAPI (Swagger) Specification Tutorial Series                      This tutorial teaches everything about the OpenAPI 2.0 Specification (fka. as Swagger), most of what you’ll read here can still be applied on version 3.If you’re a bit lost in the specification (version 2 or 3), take a look at the OpenAPI Map:                                                                                                      1 - Introduction                                      2 - The basics                                      3 - Simplifying specification file                                      4 - Advanced Data                                      5 - Advanced Input And Output Modeling                                      6 - Defining Security                                      7 - Documentation                                      8 - Splitting specification file                                      9 - Extending the OpenAPI specification                                      In previous parts we’ve learned to write efficiently highly accurate interface description, in this seventh part we’ll learn how to describe how an API is secured.Security definitionsFollowing (almost) the same principle used with parameters and definitions, security can be defined and then used on different levels.Security definition takes place on specification’s root level in securityDefinition section. It contains a list of named security definitions. Each definition can be of type:  basic for Basic Authentication  apiKey when using an API key to secure the API  oauth2 for Oauth 2Basic AuthenticationTo define a basic security it’s fairly easy, we only have to set its type to basic:                                                                                                securityDefinitions:  UserSecurity:    type: basic  AdminSecurity:    type: basic  MediaSecurity:    type: basic  In this example we have defined three security definitions (UserSecurity, AdminSecurity and MediaSecurity), each of them is of basic type.API KeyTo define an apiKey security we have to:  Set type to apiKey  Indicate where the API ley is located with in. An API can be in a header or a query parameter  And then give the parameter’s name                                                                                                securityDefinitions:  UserSecurity:    type: apiKey    in: header    name: SIMPLE-API-KEY  AdminSecurity:    type: apiKey    in: header    name: ADMIN-API-KEY  MediaSecurity:    type: apiKey    in: query    name: media-api-key  In this example, we have defined three security definitions of apiKey type:  UserSecurity uses a header parameter named SIMPLE-API-KEY  AdminSecurity uses a header parameter named ADMIN-API-KEY  MediaSecurity uses a query parameter named media-api-keyOauth 2Flow and URLsWhen defining an oauth2 security definition, we can define the Oauth2 flow used and corresponding authorizationUrl and/or tokenUrl depending on the chosen flow:            Flow      Required URLs                  implicit      authorizationUrl              password      tokenUrl              application      tokenUrl              accessCode      authorizationUrl and tokenUrl                                                                                                      securityDefinitions:  OauthSecurity:    type: oauth2    flow: accessCode    authorizationUrl: 'https://oauth.simple.api/authorization'    tokenUrl: 'https://oauth.simple.api/token'  In this example we have defined a OauthSecurity security definition of oauth2 type using an accessCode flow with an authorizationUrl and a tokenUrl.ScopesWe can also define scopes by using a hashmap, the key is the scope’s name and the value is its description.                                                                                                securityDefinitions:  OauthSecurity:    type: oauth2    flow: accessCode    authorizationUrl: 'https://oauth.simple.api/authorization'    tokenUrl: 'https://oauth.simple.api/token'    scopes:      admin: Admin scope      user: User scope      media: Media scope  In this example, we’ve added three scopes (admin, user and media) to our OauthSecurity security definitionUsing security definitionsOnce we have described security definitions in securityDefinition we can apply them to the overall API or to specific operations with the security sections.When we apply a security definition to an operation, it overrides API security.Basic AuthenticationLet’s see how we can use a basic security definition.API levelIn this example the security definition which apply to ALL API operations is UserSecurity:                                                                                                securityDefinitions:  UserSecurity:    type: basic  AdminSecurity:    type: basic  MediaSecurity:    type: basicsecurity:  - UserSecurity: [] paths:  /persons:  Operation levelAs GET /persons operation do not define a security, it’s the UserSecurity defined on top level which applies:                                                                                                paths:  /persons:    parameters:      - $ref: '#/parameters/userAgent'    get:      summary: Gets some persons      description: Returns a list containing all persons. The list supports paging.      parameters:        - $ref: '#/parameters/pageSize'        - $ref: '#/parameters/pageNumber'        - $ref: '#/parameters/includeNonVerifiedUsers'        - $ref: '#/parameters/sortPersons'  On POST /persons operation, the top level security is overridden by AdminSecurity:                                                                                                    post:      summary: Creates a person      description: Adds a new person to the persons list.      security:        - AdminSecurity: []  On POST /images operation, the top level security is also overridden, but this time it’s by MediaSecurity:                                                                                                  /images:    parameters:      - $ref: '#/parameters/userAgent'    post:      summary: Uploads an image      security:        - MediaSecurity: []  API KeyWe can do exactly the same things with an API key security definition.API levelIn this example the security definition which apply to ALL API operations is UserSecurity:                                                                                                securityDefinitions:  UserSecurity:    type: apiKey    in: header    name: SIMPLE-API-KEY  AdminSecurity:    type: apiKey    in: header    name: ADMIN-API-KEY  MediaSecurity:    type: apiKey    in: query    name: media-api-keysecurity:  - UserSecurity: [] paths:  /persons:  Operation levelAs GET /persons operation do not define a security, it’s the UserSecurity defined on top level which applies:                                                                                                paths:  /persons:    parameters:      - $ref: '#/parameters/userAgent'    get:      summary: Gets some persons      description: Returns a list containing all persons. The list supports paging.      parameters:        - $ref: '#/parameters/pageSize'        - $ref: '#/parameters/pageNumber'        - $ref: '#/parameters/includeNonVerifiedUsers'        - $ref: '#/parameters/sortPersons'  On POST /persons operation, the top level security is overridden by AdminSecurity:                                                                                                    post:      summary: Creates a person      description: Adds a new person to the persons list.      security:        - AdminSecurity: []  On POST /images operation, the top level security is also overridden, but this time it’s by MediaSecurity:                                                                                                  /images:    parameters:      - $ref: '#/parameters/userAgent'    post:      summary: Uploads an image      security:        - MediaSecurity: []  Oauth 2With an oauth2 the principle is the same but you can also define which scope(s) you use.API levelIn this example the security definition which apply to ALL API operations is OauthSecurity with the user scope:                                                                                                securityDefinitions:  OauthSecurity:    type: oauth2    flow: accessCode    authorizationUrl: 'https://oauth.simple.api/authorization'    tokenUrl: 'https://oauth.simple.api/token'    scopes:      admin: Admin scope      user: User scope      media: Media scopesecurity:  - OauthSecurity:    - userpaths:  /persons:  Operation levelAs GET /persons operation do not define a security, it’s the OauthSecurity with userscope defined on top level which applies:                                                                                                paths:  /persons:    parameters:      - $ref: '#/parameters/userAgent'    get:      summary: Gets some persons      description: Returns a list containing all persons. The list supports paging.      parameters:        - $ref: '#/parameters/pageSize'        - $ref: '#/parameters/pageNumber'        - $ref: '#/parameters/includeNonVerifiedUsers'        - $ref: '#/parameters/sortPersons'  On POST /persons operation, the top level security scope is overridden by admin:                                                                                                    post:      summary: Creates a person      description: Adds a new person to the persons list.      security:        - OauthSecurity:          - admin  On POST /images operation, the top level security is also overridden, but this time it’s by media:                                                                                                  /images:    parameters:      - $ref: '#/parameters/userAgent'    post:      summary: Uploads an image      security:        - OauthSecurity:          - media  Using multiple security typesIt’s not mandatory to define a single type of security definition and use only one at a time.The examples below show how we can define security definitions of different types and use more than one on operations.Security definitionsHere we define there different types of security:                                                                                                securityDefinitions:  OauthSecurity:    type: oauth2    flow: accessCode    authorizationUrl: 'https://oauth.simple.api/authorization'    tokenUrl: 'https://oauth.simple.api/token'    scopes:      admin: Admin scope      user: User scope  MediaSecurity:    type: apiKey    in: query    name: media-api-key  LegacySecurity:    type: basic  Global securityThen we choose to apply both of them globally:                                                                                                security:  - OauthSecurity:    - user  - LegacySecurity: []  It means that a consumer can call any operation (which do not override security) with one of those two security types.Overriding global securityAs GET /persons operation do not define a security, it’s the Oauth 2 OauthSecurity with userscope OR the basic authentication LegacySecurity defined on top level which applies:                                                                                                paths:  /persons:    parameters:      - $ref: '#/parameters/userAgent'    get:      summary: Gets some persons      description: Returns a list containing all persons. The list supports paging.      parameters:        - $ref: '#/parameters/pageSize'        - $ref: '#/parameters/pageNumber'        - $ref: '#/parameters/includeNonVerifiedUsers'        - $ref: '#/parameters/sortPersons'  On POST /persons operation, the top level security scope Oauth 2 OauthSecurity is overridden by admin and consumer can also still use the basic authentication LegacySecurity:                                                                                                    post:      summary: Creates a person      description: Adds a new person to the persons list.      security:        - OauthSecurity:          - admin        - LegacySecurity: []  On POST /images operation, the top level security is fully overridden by the API Key MediaSecurity:                                                                                                  /images:    parameters:      - $ref: '#/parameters/userAgent'    post:      summary: Uploads an image      security:        - MediaSecurity: []  ConclusionYou now have mastered security. With this new post you are now a full expert when it comes to describe an API interface with the OpenAPI specification. But an interface contract alone may not be easy to understand without some explainations. In next post we’ll learn how to document this interface description to ease its understanding."
},{
    "id": "76",
    "type": "post",
    "title": "Writing OpenAPI (Swagger) Specification Tutorial Series - Part 5 - Advanced Input And Output Modeling",
    "url": "https://apihandyman.io/writing-openapi-swagger-specification-tutorial-part-5-advanced-input-and-output-modeling/",
    "banner": "https://apihandyman.io/images/writing-openapi-swagger-specification-tutorial-part-5-advanced-input-and-output-modeling/banner.png",
    "description": "After learning how to create an accurate data model, we continue to delve into the OpenAPI specification’s and discover how to describe tailor made API’s inputs and outputs.",
    "body": "After learning how to create an accurate data model, we continue to delve into the OpenAPI specification’s and discover how to describe tailor made API’s inputs and outputs.      Writing OpenAPI (Swagger) Specification Tutorial Series                      This tutorial teaches everything about the OpenAPI 2.0 Specification (fka. as Swagger), most of what you’ll read here can still be applied on version 3.If you’re a bit lost in the specification (version 2 or 3), take a look at the OpenAPI Map:                                                                                                      1 - Introduction                                      2 - The basics                                      3 - Simplifying specification file                                      4 - Advanced Data                                      5 - Advanced Input And Output Modeling                                      6 - Defining Security                                      7 - Documentation                                      8 - Splitting specification file                                      9 - Extending the OpenAPI specification                                      In previous parts (especially The basics and Simplifying specification file we have learned how to describe simple operations parameters and responses using inline definitions or high level ones.In this fifth part you will discover all the tips and tricks to describe highly accurate parameters and responses.ParametersIn this section you will learn to define:  Required or optional parameter  Parameter with default value  Parameter with empty value  Array parameter  Header parameter  Form parameter  File parameter  Parameter’s media typeRequired or optional parameterWe already have used the required key word which is used to define a mandatory parameter or a mandatory value in definition.Defining a required or optional parameterIn a parameter, required is an optional value which type is boolean. Its default value is false.When used in a operation, the username parameter is mandatory:                                                                                                  username:    name: username    in: path    required: true    description: The person's username    type: string  When used in an operation, the pageSize parameter is NOT mandatory (required is not defined and therefore is false).                                                                                                  pageSize:    name: pageSize    in: query    description: Number of persons returned    type: integer    format: int32    minimum: 0    exclusiveMinimum: true    maximum: 100    exclusiveMaximum: false    multipleOf: 10    default: 20  Defining a required or optional property in a definition used as a parameterIn a definition, required is an optional value which type is a list of string. This list contains the mandatory properties names. A property which is not referenced in this list is NOT mandatory. If required is not defined, all object properties are not mandatory. When this definition is used on a request, all required properties MUST be provided.In the definition Person which is used as a body parameter in POST /persons, the username property is mandatory (present in required list) , all others are not mandatory (not referenced in required list).                                                                                                  Person:    required:      - username    properties:      firstName:        type: string      lastName:        type: string      username:        type: string        pattern: '[a-z0-9]{8,64}'        minLength: 8        maxLength: 64      dateOfBirth:        type: string        format: date      lastTimeOnline:        type: string        format: date-time        readOnly: true      avatarBase64PNG:        type: string        format: byte        default: data:image/png;base64,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      spokenLanguages:        $ref: '#/definitions/SpokenLanguages'  Parameter with default valueBy using the keyword default you can define a default value for a parameter or a default value for a property in a definition. This default value is the one that the server will use if none is provided. Using default does not make sense when a property or parameter is required.Defining a parameter’s default valueOn the parameter pageSize, we set its default value to 20. If this value is not provided, the server will then return pages containing 20 elements.                                                                                                  pageSize:    name: pageSize    in: query    description: Number of persons returned    type: integer    format: int32    minimum: 0    exclusiveMinimum: true    maximum: 100    exclusiveMaximum: false    multipleOf: 10    default: 20  On the parameter pageNumber, we set its default value to 1. If this value is not provided, the server will then return the first page.                                                                                                  pageNumber:    name: pageNumber    in: query    description: Page number    type: integer    default: 1  Defining a property’s default value in a definition used as a parameterOn the definition Person, the avatarBase64PNG property default value is a 64x64 pixels API Handyman PNG icon as a base64 string.Default Avatar                                                                                                  Person:    required:      - username    properties:      firstName:        type: string      lastName:        type: string      username:        type: string        pattern: '[a-z0-9]{8,64}'        minLength: 8        maxLength: 64      dateOfBirth:        type: string        format: date      lastTimeOnline:        type: string        format: date-time        readOnly: true      avatarBase64PNG:        type: string        format: byte        default: data:image/png;base64,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      spokenLanguages:        $ref: '#/definitions/SpokenLanguages'  Defining a default value in a hashmap definition used as a parameterIn previous post (Advanced data modeling) we’ve learned how to define hashmaps. We can set a default value in a an hashmap this way:                                                                                                  SpokenLanguages:    additionalProperties:      type: string    properties:      defaultLanguage:        type: string        default: english  Just like we’ve learned on previous post, we define a property defaultLanguage on SpokenLanguages definition and today we set a default value for this property. Therefore is the property spokenLanguages of the Person definition (which is a SpokenLanguages) is not provided on POST /persons, its value will be {\"defaultLanguage\": \"english\"}Parameter with empty valueIf we want to add a filter parameter to include non verified users on GET /persons a first idea would be to have something like GET /persons?page=2&amp;includeVerifiedUsers=true. But why should we have to set a value when the parameters name is sufficient to express what we want to do? Having GET /persons?page=2&amp;includeVerifiedUsers would be much better.To do that we just need to use the allowEmptyValue key word on the parameter’s description. We have also define a default value to false, therefore GET /persons?page=2&amp;includeVerifiedUsers will include verified users and GET /persons?page=2 will not.                                                                                                  includeNonVerifiedUsers:    name: includeNonVerifiedUsers    in: query    type: boolean    default: false    allowEmptyValue: true  Array parameterWhen it comes to sorting or filtering an API designer almost always ends asking himself: but how will I define an array parameter on a get request in my OpenAPI specification?It’s easy, he just need to define an array type attribute and use the accurate collectionFormat:            collectionFormat        Description                  csv (default value)      Comma separated values foo,bar              ssv      Space separated values foo bar              tsv      Tab separated values foo\\tbar              pipes      Pipes separated values foo|bar              multi      Corresponds to multiple parameter instances instead of multiple values for a single instance foo=bar&amp;foo=baz. This is valid only for parameters in query or formData.      Defining a separated values parameterIf we want to sort a persons list on multiple parameters (username, firstname, lastname, lastTimeOnline) ascending or descending we could use something like GET /persons?sort=-lastTimeOnline|+firtname|+lastname.The sort parameters are in a pipe separated array named sort, each of them starting with + for an ascending sort or - for a descending one.This sortparameter is defined with an array of string using a pipes collectionFormat:                                                                                                  sortPersons:    name: sort    in: query    type: array    uniqueItems: true    minItems: 1    maxItems: 3    collectionFormat: pipes    items:      type: string  We can now have requests like this: GET /persons?sort=String1|String2|String3. But how do we set the sorting direction and how can we we enforce the values within the array?In this specific use case we will define a pattern for the string within the array, just like we’ve learned on previous part when defining the username property. This pattern says that a value within the array may start with + (for ascending) and - (for descending) and be followed by username, firstname, lastname or lastTimeOnline.                                                                                                  sortPersons:    name: sort    in: query    type: array    uniqueItems: true    minItems: 1    maxItems: 3    collectionFormat: pipes    items:      type: string      pattern: '[-+](username|lastTimeOnline|firstname|lastname)'  Our API is now ready to handle a GET /persons?sort=-lastTimeOnline|+firtname|+lastname request.And icing on the cake, we can also define a default sort (last online time descending and username ascending) by adding a default value on the array level:                                                                                                  sortPersons:    name: sort    in: query    type: array    uniqueItems: true    minItems: 1    maxItems: 3    collectionFormat: pipes    items:      type: string      pattern: '[-+](username|lastTimeOnline|firstname|lastname)'    default:      - -lastTimeOnline      - +username  Defining a multiple values parameterIf we want to filter a persons collected items list on mutiple items types we could use something like GET /persons/apihandyman/collected-items?itemType=AudioCassette&amp;itemType=Vinyl.The filter parameters are in a multi array named itemType, each value corresponding to one of the item’s type we want to filter on.This filterItemTypes parameter is defined with an array of unique stringusing a multi colectionFormat:                                                                                                  filterItemTypes:    name: itemType    in: query    type: array    collectionFormat: multi    uniqueItems: true    items:      type: string  And icing on the cake we enforce the possible values by defining an enum on the string within the array:                                                                                                  filterItemTypes:    name: itemType    in: query    type: array    collectionFormat: multi    uniqueItems: true    items:      type: string      enum:        - AudioCassette        - Vinyl        - VHS  Parameter location is not only path, query or bodyWhen describing a parameter, the keyword in is used to set its location.We already have seen in previous parts the most common values of in are:  path  query  bodyBut they are not the only ones, there two others:  header  formDataWe’ll see in next sections how we can use them in an API definition to define  Header parameter  Form parameter  File parameterHeader parameterLet’s say we want our API consumer’s to provide some informations about themselves by using the good old User-Agent HTTP header (for tracking, debugging, or whatever you want).We define the parameter just like any other one, we just need to set the headervalue in in:                                                                                                  userAgent:    name: User-Agent    type: string    in: header    required: true  And we use it (on every path) just like any other parameter:                                                                                                paths:  /persons:    parameters:      - $ref: '#/parameters/userAgent'  There’s absolutely no way of telling once and for all that all operations needs this header parameter (for now).nb: This works also with custom HTTP header.Form parameterLet’s say we have a partner who need to use our API in a js-less-browser environment to create persons. He can only provide the creation information in a good old HTML form format:                                                                                                POST /js-less-personsusername=apihandyman&amp;firstname=API&amp;lastname=Handyman  No problem, we just need to define all form parameters with in sets to  formData and setting the consumes media type to application/x-www-form-urlencoded:                                                                                                    post:      summary: Creates a person      description: For JS-less partners      consumes:        - application/x-www-form-urlencoded      produces:        - text/html      parameters:        - name: username          in: formData          required: true          pattern: '[a-z0-9]{8,64}'          minLength: 8          maxLength: 64          type: string        - name: firstname          in: formData          type: string        - name: lastname          in: formData          type: string        - name: dateOfBirth          in: formData          type: string          format: date      responses:        '204':          description: Person succesfully created.  File parameterTo define an operation which will accept a file as input parameter, you need to:  use multipart/form-data media type  set parameter’s in value to formData  set parameter’s type value to file                                                                                                  /images:    parameters:      - $ref: '#/parameters/userAgent'    post:      summary: Uploads an image      consumes:        - multipart/form-data      parameters:        - name: image          in: formData          type: file      responses:        '200':          description: Image's ID          schema:            properties:              imageId:                type: string  And what if I want to restrict file’s media type? Unfortunately, it’s not possible for now:  The spec doesn’t allow specifying a content type for specific form data parameters. It’s a limitation of the spec.Ron Ratovsky comment in Swagger UI 609 issueParameter’s media typesAn API can consume various media types, the most common one is application/json, but it’s not the only one an API can use. The keyword consumes on root or operation level is used to describe the accepted media types list.We set the global media-type on the root level of the OpenAPI document, here our API consumes JSON and YAML:                                                                                                consumes:  - application/json  - application/x-yaml  This settings can be overriden on the operation level by redefining the consumes list:                                                                                                  /images:    parameters:      - $ref: '#/parameters/userAgent'    post:      summary: Uploads an image      consumes:        - multipart/form-data      parameters:        - name: image          in: formData          type: file      responses:        '200':          description: Image's ID          schema:            properties:              imageId:                type: string  ResponsesIn this section you will learn to define:  Response without a body  Required or optional values in response  Response’s headers  Default response  Response’s media typesResponse without a bodyIt’s a common feature in HTTP protocole and in REST API to have response without body. For example the 204 HTTP Status is used by a server which wants to indicate a succes without returning any content (or body).To define a response without a body, all you have to do is set its status and description:                                                                                                    post:      summary: Creates a person      description: Adds a new person to the persons list.      parameters:        - name: person          in: body          required: true          description: The person to create.          schema:            $ref: '#/definitions/Person'      responses:        '204':          description: Person succesfully created.  Required or optional values in responseJust like we’ve seen on parameters, we can define mandatory properties in definition used in responses.Mandatory properties are defined with the required list. A property referenced in this list MUST be sent by the server and a property absent from this list MAY be sent by the server.When GET /persons/apihandyman returns a Person, this person will surely contains a username, but all other values may not be sent:                                                                                                  Person:    required:      - username    properties:      firstName:        type: string      lastName:        type: string      username:        type: string        pattern: '[a-z0-9]{8,64}'        minLength: 8        maxLength: 64      dateOfBirth:        type: string        format: date      lastTimeOnline:        type: string        format: date-time        readOnly: true      avatarBase64PNG:        type: string        format: byte        default: data:image/png;base64,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      spokenLanguages:        $ref: '#/definitions/SpokenLanguages'  Response’s headersThe HTTP status and the body are not the only way to provide information on the result of an API call, HTTP headers can be used too.Let’s say we want to offer something like the Twitter’s API rate limiting information to provide the remaining number of API calls and when the limit will be reset. We have to define two header X-Rate-Limit-Remaining and X-Rate-Limit-Reset and each API response:                                                                                                    post:      summary: Creates a person      description: Adds a new person to the persons list.      parameters:        - name: person          in: body          required: true          description: The person to create.          schema:            $ref: '#/definitions/Person'      responses:        '204':          description: Person succesfully created.          headers:            X-Rate-Limit-Remaining:              type: integer            X-Rate-Limit-Reset:              type: string              format: date-time  Unfortunately there’s absolutely no way of defining such headers once and for all (for now).Default responseThe OpenAPI specification allow to define a default response on each operation.This could be used to define a single generic response but your API definition would not be easily understandable. I’d prefer to use it in conjunction with a full description of which HTTP status an API handle, and then use the default response to say if you have any other HTTP status than the ones I described explicitely, it do not comes from this API.A generic response defined once and for all in the responses section:                                                                                                  TotallyUnexpectedResponse:    description: A totally unexpected response  This response used as a default response on each operation:                                                                                                    delete:      summary: Deletes a person      description: Delete a single person identified via its username      responses:        '204':          description: Person successfully deleted.          headers:            X-Rate-Limit-Remaining:              type: integer            X-Rate-Limit-Reset:              type: string              format: date-time        '404':          $ref: '#/responses/PersonDoesNotExistResponse'        '500':          $ref: '#/responses/Standard500ErrorResponse'        default:          $ref: '#/responses/TotallyUnexpectedResponse'  Unfortunately there’s absolutely no way of defining a global response once and for all (for now).Response’s media typesAn API can produce various media types, the most common one is application/json, but it’s not the only one an API can use. The keyword produces on root or operation level is used to describe the returned media types list.We set the global media-type on the root level of the OpenAPI document, here our API produces JSON and YAML:                                                                                                produces:  - application/json  - application/x-yaml  This settings can be overriden on the operation level by redefining the local produces list, here’s an example on GET /images/{imageId} operation which return an image:                                                                                                  /images/{imageId}:    parameters:      - $ref: '#/parameters/userAgent'    get:      summary: Gets an image      parameters:        - name: imageId          in: path          required: true          type: string      produces:        - image/png        - image/gif        - image/jpeg        - application/json        - application/x-yaml      responses:        '200':          description: The image          headers:            X-Rate-Limit-Remaining:              type: integer            X-Rate-Limit-Reset:              type: string              format: date-time        '404':          description: Image do not exists          headers:            X-Rate-Limit-Remaining:              type: integer            X-Rate-Limit-Reset:              type: string              format: date-time        '500':          $ref: '#/responses/Standard500ErrorResponse'        default:          $ref: '#/responses/TotallyUnexpectedResponse'  Note that the produces contains images media types but also json and yaml media types as if there’s a 500 error, the message will be return with one of those 2 media types.How to use a single definition when output returns more data than input needsAnd finally, as already seen on previous part in section 2.1, in a definition the readOnly property is set to true to indicate that this property MAY be sent in a response and MUST NOT be sent in a request.It allows you to use a single definition when output returns more data than input needs.In the definition Person which is both used as a part of the response in GET /persons and a body parameter in POST /persons the lastTimeOnline property has readOnly set to true. Therefore this property MUST NOT be provided on POST /persons and MAY be returned by the server on GET /persons:                                                                                                  Person:    required:      - username    properties:      firstName:        type: string      lastName:        type: string      username:        type: string        pattern: '[a-z0-9]{8,64}'        minLength: 8        maxLength: 64      dateOfBirth:        type: string        format: date      lastTimeOnline:        type: string        format: date-time        readOnly: true      avatarBase64PNG:        type: string        format: byte        default: data:image/png;base64,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      spokenLanguages:        $ref: '#/definitions/SpokenLanguages'  Warning: SwaggerUI does not handle this yet (issue 884).ConclusionYou are now a Jedi of API’s input and ouput definition with the OpenAPI specification. In next post you’ll learn to describe how your API is secured."
},{
    "id": "77",
    "type": "post",
    "title": "Writing OpenAPI (Swagger) Specification Tutorial Series - Part 4 - Advanced Data",
    "url": "https://apihandyman.io/writing-openapi-swagger-specification-tutorial-part-4-advanced-data-modeling/",
    "banner": "https://apihandyman.io/images/writing-openapi-swagger-specification-tutorial-part-4-advanced-data-modeling/banner.png",
    "description": "After learning how to simplify specification files, let’s start delving into the OpenAPI specification’s and discover how to describe a high accuracy API’s data model.",
    "body": "After learning how to simplify specification files, let’s start delving into the OpenAPI specification’s and discover how to describe a high accuracy API’s data model.      Writing OpenAPI (Swagger) Specification Tutorial Series                      This tutorial teaches everything about the OpenAPI 2.0 Specification (fka. as Swagger), most of what you’ll read here can still be applied on version 3.If you’re a bit lost in the specification (version 2 or 3), take a look at the OpenAPI Map:                                                                                                      1 - Introduction                                      2 - The basics                                      3 - Simplifying specification file                                      4 - Advanced Data                                      5 - Advanced Input And Output Modeling                                      6 - Defining Security                                      7 - Documentation                                      8 - Splitting specification file                                      9 - Extending the OpenAPI specification                                      In this fourth part you will discover all the tips and tricks you can use to describe properties and definitions to describe an accurate API’s data model.Tailor made properties  Primitive data types in the Swagger Specification are based on the types supported by the JSON-Schema Draft 4. Models are described using the Schema Object which is a subset of JSON Schema Draft 4.OpenAPI Specification Data TypesUsing the JSON Schema Draft 4, the OpenAPI Specification allows to define every aspects of any type of property.Strings length and patternWhen defining a string property, we can specify its length range and its pattern:            Property      Type      Description                  minLength      number      String’s minimum length              maxLength      number      String’s maximum length              pattern      string      Regular expression (if you’re not a regex expert, you should try Regex 101)      The username in the Person definition is a string which length is between 8 and 64 and composed of lower case alphanumeric characters:                                                                                                      username:        type: string        pattern: \"[a-z0-9]{8,64}\"        minLength: 8        maxLength: 64  Dates and timesDate and time are handled with string properties conforming to RFC 3339, all you need to do is to use the appropriate format:            Format      Property contains      Property’s value example                  date      ISO8601 full-date      2016-04-01              date-time      ISO8601 date-time      2016-04-16T16:06:05Z      In the Person definition, dateOfBirth is a date and lastTimeOnline is a timestamp:                                                                                                      dateOfBirth:        type: string        format: date      lastTimeOnline:        type: string        format: date-time  You should read the 5 laws of API dates and times by Jason Harmon to learn how to handle date and time with an API.Numbers type and rangeWhen defining a number property, we can specify if this property is an integer, a long, a float or a double by using the appropriate type and format combination.            Value      Type      Format                  integer      integer      int32              long      integer      int64              float      number      float              double      number      double      And just like string, we can define additional properties like the value range and also indicate if the value is a multiple of something:            Property      Type      Description                  minimum      number      Minimum value              maximum      number      Maximum value              exclusiveMinimum      boolean      Value must be &gt; minimum              exclusiveMaximum      boolean      Value must be &lt; maximum              multipleOf      number      Value is a multiple of multipleOf      The pageSize parameter is an integer &gt; 0 and &lt;= 100 and a multiple of 10:                                                                                                  pageSize:    name: pageSize    in: query    description: Number of persons returned    type: integer    format: int32    minimum: 0    exclusiveMinimum: true    maximum: 100    exclusiveMaximum: false    multipleOf: 10  The maxPrice property of CollectingItem definition is a double value &gt; 0 and &lt;= 10000:                                                                                                      maxPrice:        type: number        format: double        minimum: 0        maximum: 10000        exclusiveMinimum: true        exclusiveMaximum: false  EnumerationsOn each property we can define a set of accepted value with the enum property.The property code of definition Error can take only three value (DBERR, NTERR and UNERR):                                                                                                      code:        type: string        enum:          - DBERR          - NTERR          - UNERR  Arrays size and uniquenessArrays size and uniqueness are defined by these properties:            Property      Type      Description                  minItems      number      Minimum number of items in the array              maxItem      number      Maximum number of items in the array              uniqueItems      boolean      Indicate if all array’s elements are unique      The Person definition contains a property items which is an array of Person. This array contain only unique elements and can have between 10 and 100 items:                                                                                                  Persons:    properties:      items:        type: array        minItems: 10        maxItems: 100        uniqueItems: true        items:          $ref: \"#/definitions/Person\"  Binary dataBinary data can be handled with string properties using the appropriate format:            Format      Property contains                  byte      Base64 encoded characters              binary      Any sequence of octets      The property avatarBase64PNG of Person definition is a base64 encoded PNG image:                                                                                                      avatarBase64PNG:        type: string        format: byte  Advanced definition modelingUsing same definitions on read and write operationsIt’s not unusual that reading a resource returns more than the data needed when creating or updating it. To solve this problem you’ll probably end having two different definitions, one for creating or updating and the other for reading. Fortunately, it can be avoided.When describing a property in a definition, we can set a readOnly property to true to explain that this property may be sent in a response and must not be sent in a request.In the example below, the lastTimeOnline property in the Person definition does not have sense when creating an Person. With readOnly set to true on this property, we can use the same Person definition in both post /persons and get /persons/{username}, lastTimeOnline will only be of interest when using get:                                                                                                      lastTimeOnline:        type: string        format: date-time        readOnly: true  Combining multiple definitions to ensure consistencyWhen designing an API, it is highly recommended to propose a consistent design. You can for example decide that paged collection data should always be accompanied on the root level by the same data explaining the current paging status (totalItems, totalPage, pageSize, currentPage).A first option would be to define this attribute on every single collection:                                                                                                  PagedPersonsV1:    properties:      items:        type: array        items:          $ref: \"#/definitions/Person\"      totalItems:        type: integer      totalPages:        type: integer      pageSize:        type: integer      currentPage:        type: integer  Having to describe again and again, endlessly the same properties on each collection is not only boring but also dangerous: you can forget some properties or misspelled them. And what will happen when you’ll want to add a new information on paging? You’ll have to update every single collection.A better option would be to define a Paging model and then use it in every collection:                                                                                                  PagedPersonsV2:    properties:      items:        type: array        items:          $ref: \"#/definitions/Person\"      paging:        $ref: \"#/definitions/Paging\"  Paging:    properties:      totalItems:        type: integer      totalPages:        type: integer      pageSize:        type: integer      currentPage:        type: integer  But the paging attributes are not on the root level anymore.The allOf JSON Schema v4 property can provide an elegant and simple solution to this problem:                                                                                                  PagedPersons:    allOf:      - $ref: \"#/definitions/Persons\"      - $ref: \"#/definitions/Paging\"  The allOf property allow to create a new definition composed of all referenced definitions attributes.It also functions perfectly with inline definitions:                                                                                                  PagedCollectingItems:    allOf:      - properties:          items:            type: array            minItems: 10            maxItems: 100            uniqueItems: true            items:              $ref: \"#/definitions/CollectingItem\"      - $ref: \"#/definitions/Paging\"  Create a hierarchy between definitions to implement inheritance (highly experimentatl)As stated in the OpenAPI Specification, composition do not imply hierarchy. The use of discriminator indicate the property used to know which is the type of the sub-definition or sub-class (this property MUST be in the required list).Here we define a CollectingItem super-definition, which is subclassed using the allOf property. The consumer will determine which sub-definition used by scanning the itemType property.                                                                                                  CollectingItem:    discriminator: itemType    required:      - itemType    properties:      itemType:        type: string        enum:          - Vinyl          - VHS      imageId:        type: string      maxPrice:        type: number        format: double        minimum: 0        maximum: 10000        exclusiveMinimum: true        exclusiveMaximum: false  Vinyl:    allOf:      - $ref: \"#/definitions/CollectingItem\"      - required:          - albumName          - artist        properties:          albumName:            type: string          artist:            type: string  VHS:    allOf:      - $ref: \"#/definitions/CollectingItem\"      - required:          - movieTitle        properties:          movieTitle:            type: string  This is highly experimental as the content of discriminator field is not clear in the specification’s current version (issue 403) and as far as I know it is not supported by any tool using OpenAPI specification.Maps, Hashmap, Associative array  A map is structure that can map key to valueHash table on WikipediaA string/string JSON map:                                                                                        {   &quot;key1&quot;: &quot;value1&quot;,  &quot;key2&quot;: &quot;value2&quot;}  A string/object JSON map:                                                                                        {   &quot;key1&quot;: {&quot;complexValue1&quot;: &quot;value1&quot;},  &quot;key2&quot;: {&quot;complexValue2&quot;: &quot;value2&quot;}}  In an OpenAPI specification the key is always a string and do not need to be defined (if the key is an integer, it will be considered as a string).The value’s type is defined within the property: additionalProperties.String to String Hashmap:If you want to have a string to string map property in the Person definition explaining which languages this person speaks, the resulting data would look like this:                                                                                        {&quot;username&quot;: &quot;apihandyman&quot;,&quot;spokenLanguage&quot;: {     &quot;en&quot;: &quot;english&quot;,    &quot;fr&quot;: &quot;French&quot;  }}  Defining the spokenLanguage property in the Person definition is done this way:                                                                                                definitions:  Person:    required:      - username    properties:      firstName:        type: string      lastName:        type: string      username:        type: string        pattern: \"[a-z0-9]{8,64}\"        minLength: 8        maxLength: 64      dateOfBirth:        type: string        format: date      lastTimeOnline:        type: string        format: date-time        readOnly: true      avatarBase64PNG:        type: string        format: byte      spokenLanguages:        $ref: \"#/definitions/SpokenLanguages\"    SpokenLanguages:    additionalProperties:      type: string  String to Object MapIf you want to have a string to object map property in the Error definition to provide a multilingual long and short error message, the resulting data would look like this:                                                                                        {  &quot;code&quot;: &quot;UNERR&quot;,  &quot;message&quot;: {     &quot;en&quot;: {        &quot;shortMessage&quot;:&quot;Error&quot;,         &quot;longMessage&quot;:&quot;Error. Sorry for the inconvenience.&quot;    },    &quot;fr&quot;: {        &quot;shortMessage&quot;:&quot;Erreur&quot;,         &quot;longMessage&quot;:&quot;Erreur. Désolé pour le dérangement.&quot;    }  }}  Defining the message property in the Error definition is done this way:                                                                                                  ErrorMessage:    properties:      longMessage:        type: string      shortMessage:        type: string    MultilingualErrorMessage:    additionalProperties:      $ref: \"#/definitions/ErrorMessage\"                                                                                                    Error:    required:      - code      - message    properties:      code:        type: string        enum:          - DBERR          - NTERR          - UNERR      message:        $ref: \"#/definitions/MultilingualErrorMessage\"  Hashmap with default value(s)And finally, if you want to add a default language multilingual error message in your map (i.e. adding a default value in the map).The returned structure do not differs from the precedent example:                                                                                        {  &quot;code&quot;: &quot;UNERR&quot;,  &quot;message&quot;: {    &quot;defaultLanguage&quot;: {        &quot;shortMessage&quot;:&quot;Error&quot;,         &quot;longMessage&quot;:&quot;Error. Sorry for the inconvenience.&quot;    },     &quot;en&quot;: {        &quot;shortMessage&quot;:&quot;Error&quot;,         &quot;longMessage&quot;:&quot;Error. Sorry for the inconvenience.&quot;    },    &quot;fr&quot;: {        &quot;shortMessage&quot;:&quot;Erreur&quot;,         &quot;longMessage&quot;:&quot;Erreur. Désolé pour le dérangement.&quot;    }  }}  But in the OpenAPI Specification, we add a defaultLanguage property to the MultilingualErrorMessage definition to the explicitly declare this value in the map:                                                                                                  ErrorMessage:    properties:      longMessage:        type: string      shortMessage:        type: string    MultilingualErrorMessage:    additionalProperties:      $ref: \"#/definitions/ErrorMessage\"    properties:      defaultLanguage:        $ref: \"#/definitions/ErrorMessage\"    Error:    required:      - code      - message    properties:      code:        type: string        enum:          - DBERR          - NTERR          - UNERR      message:        $ref: \"#/definitions/MultilingualErrorMessage\"  You can define as many as “default” values as you want.This also can be used for string to string map.Inspired by this stackoverflow question answered by Ron RatovskyConclusionYou now have mastered the art of defining an accurate data model with the OpenAPI Specification.Be aware that even if the OpenAPI Specification defines all this possibilities, some may not be supported/used by every tool working with OpenAPI specification files. But at least your API data model’s description will be highly accurate.In the next post we’ll continue our delving in the specification and learn all tips and tricks to describe the input and outputs of an API."
},{
    "id": "78",
    "type": "post",
    "title": "Writing OpenAPI (Swagger) Specification Tutorial Series - Part 3 - Simplifying specification file",
    "url": "https://apihandyman.io/writing-openapi-swagger-specification-tutorial-part-3-simplifying-specification-file/",
    "banner": "https://apihandyman.io/images/writing-openapi-swagger-specification-tutorial-part-3-simplifying-specification-file/banner.png",
    "description": "After learning the basics and having written a little bit huge file for a so simple API, you may be concerned by what nightmare it could be to handle a bigger and more complex API. REST assured that the OpenAPI Specification (formerly Swagger Specification) format offers all means to write really small and simple specification files whatever the described API’s size and complexity.",
    "body": "After learning the basics and having written a little bit huge file for a so simple API, you may be concerned by what nightmare it could be to handle a bigger and more complex API. REST assured that the OpenAPI Specification (formerly Swagger Specification) format offers all means to write really small and simple specification files whatever the described API’s size and complexity.      Writing OpenAPI (Swagger) Specification Tutorial Series                      This tutorial teaches everything about the OpenAPI 2.0 Specification (fka. as Swagger), most of what you’ll read here can still be applied on version 3.If you’re a bit lost in the specification (version 2 or 3), take a look at the OpenAPI Map:                                                                                                      1 - Introduction                                      2 - The basics                                      3 - Simplifying specification file                                      4 - Advanced Data                                      5 - Advanced Input And Output Modeling                                      6 - Defining Security                                      7 - Documentation                                      8 - Splitting specification file                                      9 - Extending the OpenAPI specification                                      In this third part you will learn how to simplifiy the specification file by defining reusable definitions, responses and parameters and using them with references and thus make the writing and reading of OpenAPI Specification fairly easy.Simplifying data model descriptionWe’ll use the final example of the previous part as starting point. When taking a look at this specification file, the obvious problem is that a Person is defined three times:                                                                                                swagger: \"2.0\"info:  version: 1.0.0  title: Simple API  description: A simple API to learn how to write OpenAPI Specificationschemes:  - httpshost: simple.apibasePath: /openapi101paths:  /persons:    get:      summary: Gets some persons      description: Returns a list containing all persons. The list supports paging.      parameters:       - name: pageSize         in: query         description: Number of persons returned         type: integer       - name: pageNumber         in: query         description: Page number         type: integer      responses:        200:          description: A list of Person          schema:            type: array            items:              required:                - username              properties:                firstName:                  type: string                lastName:                  type: string                username:                  type: string    post:      summary: Creates a person      description: Adds a new person to the persons list.      parameters:        - name: person          in: body          description: The person to create.          schema:            required:              - username            properties:              firstName:                type: string              lastName:                type: string              username:                type: string      responses:        204:          description: Persons succesfully created.        400:          description: Persons couldn't have been created.  /persons/{username}:    get:      summary: Gets a person      description: Returns a single person for its username.      parameters:        - name: username          in: path          required: true          description: The person's username          type: string      responses:        200:          description: A Person          schema:            required:              - username            properties:              firstName:                type: string              lastName:                type: string              username:                type: string        404:          description: The Person does not exists.  By using reusable definitions this not so simple specification will be transformed into this one:                                                                                                swagger: \"2.0\"info:  version: 1.0.0  title: Simple API  description: A simple API to learn how to write OpenAPI Specificationschemes:  - httpshost: simple.apibasePath: /openapi101paths:  /persons:    get:      summary: Gets some persons      description: Returns a list containing all persons. The list supports paging.      parameters:       - name: pageSize         in: query         description: Number of persons returned         type: integer       - name: pageNumber         in: query         description: Page number         type: integer      responses:        200:          description: A list of Person          schema:            $ref: \"#/definitions/Persons\"    post:      summary: Creates a person      description: Adds a new person to the persons list.      parameters:        - name: person          in: body          description: The person to create.          schema:            $ref: \"#/definitions/Person\"      responses:        204:          description: Persons succesfully created.        400:          description: Persons couldn't have been created.  /persons/{username}:    get:      summary: Gets a person      description: Returns a single person for its username.      parameters:        - name: username          in: path          required: true          description: The person's username          type: string      responses:        200:          description: A Person          schema:            $ref: \"#/definitions/Person\"        404:          description: The Person does not exists.definitions:  Person:    required:      - username    properties:      firstName:        type: string      lastName:        type: string      username:        type: string  Persons:    type: array    items:      $ref: \"#/definitions/Person\"  The OpenAPI Specification definitions section (Swagger Object) allows you to define once and for all objects/entities/models that can be used anywhere in the specification (i.e. where a schema is defined).Adding definitions sectionWe’ll start by adding a new definitions section at the end of the document (nb: it can be placed anywhere as long as it’s on the root of the OpenAPI Specification tree structure).                                                                                                        404:          description: The Person does not exists.definitions:  Defining a reusable definitionThen we define a Person once and for all in the definitions section:                                                                                                definitions:  Person:    required:      - username    properties:      firstName:        type: string      lastName:        type: string      username:        type: string  Note that the information provided in Person are exactly the same as the one provided in the three schemas describing a person in previous version. A definition is simply a named schema object.Referencing a definition from another definitionWe’ll start using this newly created definition by referencing it in another one. As we have defined a Person we’ll also define Persons which is an array (or a list) of Persons. The information provided in Persons are almost the same as the one provided in the get /persons response:                                                                                                          description: A list of Person          schema:            type: array            items:              required:                - username              properties:                firstName:                  type: string                lastName:                  type: string                username:                  type: string  The only difference is that the schema describing the array’s items has been replaced by a reference ($ref) to the Persons definition.                                                                                                  Persons:    type: array    items:      $ref: \"#/definitions/Person\"  A reference is only a path to another declaration within the OpenAPI Specification.Using definitions in responsesOnce we have defined Person and Persons, we can use them to replace the inline schemas by references in all operations responses.get /personsBefore                                                                                                      responses:        200:          description: A list of Person          schema:            type: array            items:              required:                - username              properties:                firstName:                  type: string                lastName:                  type: string  After                                                                                                      responses:        200:          description: A list of Person          schema:            $ref: \"#/definitions/Persons\"  get /persons/{username}Before                                                                                                      responses:        200:          description: A Person          schema:            required:              - username            properties:              firstName:                type: string              lastName:                type: string              username:                type: string  After                                                                                                      responses:        200:          description: A Person          schema:            $ref: \"#/definitions/Person\"  Using definitions in parametersDefinitions are not only meant to be used within the definitions section (it would be pointless), they can also be used in operations parameters.post /persons:Before                                                                                                    post:      summary: Creates a person      description: Adds a new person to the persons list.      parameters:        - name: person          in: body          description: The person to create.          schema:            required:              - username            properties:              firstName:                type: string              lastName:                type: string              username:                type: string  After                                                                                                    post:      summary: Creates a person      description: Adds a new person to the persons list.      parameters:        - name: person          in: body          description: The person to create.          schema:            $ref: \"#/definitions/Person\"  Simplifying responses descriptionNow we have discovered references ($ref), we’ll see they can be used for other matters like responses definition.                                                                                                swagger: \"2.0\"info:  version: 1.0.0  title: Simple API  description: A simple API to learn how to write OpenAPI Specificationschemes:  - httpshost: simple.apibasePath: /openapi101paths:  /persons:    get:      summary: Gets some persons      description: Returns a list containing all persons. The list supports paging.      parameters:       - name: pageSize         in: query         description: Number of persons returned         type: integer       - name: pageNumber         in: query         description: Page number         type: integer      responses:        200:          description: A list of Person          schema:            $ref: \"#/definitions/Persons\"        500:          $ref: \"#/responses/Standard500ErrorResponse\"    post:      summary: Creates a person      description: Adds a new person to the persons list.      parameters:        - name: person          in: body          description: The person to create.          schema:            $ref: \"#/definitions/Person\"      responses:        204:          description: Persons succesfully created.        400:          description: Persons couldn't have been created.        500:          $ref: \"#/responses/Standard500ErrorResponse\"            /persons/{username}:    get:      summary: Gets a person      description: Returns a single person for its username.      parameters:        - name: username          in: path          required: true          description: The person's username          type: string      responses:        200:          description: A Person          schema:            $ref: \"#/definitions/Person\"        404:          description: The Person does not exists.        500:          $ref: \"#/responses/Standard500ErrorResponse\"definitions:  Person:    required:      - username    properties:      firstName:        type: string      lastName:        type: string      username:        type: string  Persons:    type: array    items:      $ref: \"#/definitions/Person\"  Error:    properties:      code:        type: string      message:        type: stringresponses:  Standard500ErrorResponse:    description: An unexpected error occured.    schema:      $ref: \"#/definitions/Error\"  Defining a reusable HTTP 500 responseLet’s say, we want every API’s operation to return an error code and message to provide more detailed information about what happened when an operation failed with an HTTP 500 error.If we do that the basic way, we’ll end adding a 500 response on each operation like this:                                                                                                paths:  /persons:    get:      summary: Gets some persons      description: Returns a list containing all persons. The list supports paging.      parameters:       - name: pageSize         in: query         description: Number of persons returned         type: integer       - name: pageNumber         in: query         description: Page number         type: integer      responses:        200:          description: A list of Person          schema:            $ref: \"#/definitions/Persons\"        500:          description: An unexpected error occured.          schema:            properties:              code:                type: string              message:                type: string    post:      summary: Creates a person      description: Adds a new person to the persons list.      parameters:        - name: person          in: body          description: The person to create.          schema:            $ref: \"#/definitions/Person\"      responses:        204:          description: Persons succesfully created.        400:          description: Persons couldn't have been created.        500:          description: An unexpected error occured.          schema:            properties:              code:                type: string              message:                type: string            /persons/{username}:    get:      summary: Gets a person      description: Returns a single person for its username.      parameters:        - name: username          in: path          required: true          description: The person's username          type: string      responses:        200:          description: A Person          schema:            $ref: \"#/definitions/Person\"        404:          description: The Person does not exists.        500:          description: An unexpected error occured.          schema:            properties:              code:                type: string              message:                type: string  As every operation will handle HTTP 500 error exactly the same way, it’s a pity to have to declare three times exactly the same thing.Defining an Error definitionBut, we have learned that we can define a schema once and for all. So let’s create an Error definition containing string code and message in the definitions section.                                                                                                definitions:  Person:    required:      - username    properties:      firstName:        type: string      lastName:        type: string      username:        type: string  Persons:    type: array    items:      $ref: \"#/definitions/Person\"  Error:    properties:      code:        type: string      message:        type: string  A first almost good idea would be to use this definition in every operation for 500 response schema.                                                                                                paths:  /persons:    get:      summary: Gets some persons      description: Returns a list containing all persons. The list supports paging.      parameters:       - name: pageSize         in: query         description: Number of persons returned         type: integer       - name: pageNumber         in: query         description: Page number         type: integer      responses:        200:          description: A list of Person          schema:            $ref: \"#/definitions/Persons\"        500:          description: An unexpected error occured.          schema:            $ref: \"#/definitions/Error\"    post:      summary: Creates a person      description: Adds a new person to the persons list.      parameters:        - name: person          in: body          description: The person to create.          schema:            $ref: \"#/definitions/Person\"      responses:        204:          description: Persons succesfully created.        400:          description: Persons couldn't have been created.        500:          description: An unexpected error occured.          schema:            $ref: \"#/definitions/Error\"            /persons/{username}:    get:      summary: Gets a person      description: Returns a single person for its username.      parameters:        - name: username          in: path          required: true          description: The person's username          type: string      responses:        200:          description: A Person          schema:            $ref: \"#/definitions/Person\"        404:          description: The Person does not exists.        500:          description: An unexpected error occured.          schema:            $ref: \"#/definitions/Error\"  Defining a reusable responseBut it can be even more simple if we declare a response once and for all within the OpenAPI Specification responses section (Swagger Object). This section allows to define reusable responses definitions.                                                                                                definitions:  Person:    required:      - username    properties:      firstName:        type: string      lastName:        type: string      username:        type: string  Persons:    type: array    items:      $ref: \"#/definitions/Person\"  Error:    properties:      code:        type: string      message:        type: stringresponses:  Standard500ErrorResponse:    description: An unexpected error occured.    schema:      $ref: \"#/definitions/Error\"  Note that the response use the Error definition.Using the defined responseUsing a defined response is done through a $ref (just like we did when using definitions).get /users                                                                                                      responses:        200:          description: A list of Person          schema:            $ref: \"#/definitions/Persons\"        500:          $ref: \"#/responses/Standard500ErrorResponse\"  post /users                                                                                                      responses:        204:          description: Persons succesfully created.        400:          description: Persons couldn't have been created.        500:          $ref: \"#/responses/Standard500ErrorResponse\"  get /users/{username}                                                                                                      responses:        200:          description: A Person          schema:            $ref: \"#/definitions/Person\"        404:          description: The Person does not exists.        500:          $ref: \"#/responses/Standard500ErrorResponse\"  Simplifying parameters descriptionLike models/schemas and responses, parameters description can be simplified easily.                                                                                                swagger: \"2.0\"info:  version: 1.0.0  title: Simple API  description: A simple API to learn how to write OpenAPI Specificationschemes:  - httpshost: simple.apibasePath: /openapi101paths:  /persons:    get:      summary: Gets some persons      description: Returns a list containing all persons. The list supports paging.      parameters:       - $ref: \"#/parameters/pageSize\"       - $ref: \"#/parameters/pageNumber\"      responses:        200:          description: A list of Person          schema:            $ref: \"#/definitions/Persons\"        500:          $ref: \"#/responses/Standard500ErrorResponse\"    post:      summary: Creates a person      description: Adds a new person to the persons list.      parameters:        - name: person          in: body          description: The person to create.          schema:            $ref: \"#/definitions/Person\"      responses:        204:          description: Person succesfully created.        400:          description: Person couldn't have been created.        500:          $ref: \"#/responses/Standard500ErrorResponse\"            /persons/{username}:    parameters:      - $ref: \"#/parameters/username\"    get:      summary: Gets a person      description: Returns a single person for its username.      responses:        200:          description: A Person          schema:            $ref: \"#/definitions/Person\"        404:          $ref: \"#/responses/PersonDoesNotExistResponse\"        500:          $ref: \"#/responses/Standard500ErrorResponse\"    delete:      summary: Deletes a person      description: Delete a single person identified via its username      responses:        204:          description: Person successfully deleted.        404:          $ref: \"#/responses/PersonDoesNotExistResponse\"        500:          $ref: \"#/responses/Standard500ErrorResponse\"            /persons/{username}/friends:    parameters:      - $ref: \"#/parameters/username\"    get:      summary: Gets a person's friends      description: Returns a list containing all persons. The list supports paging.      parameters:       - $ref: \"#/parameters/pageSize\"       - $ref: \"#/parameters/pageNumber\"      responses:        200:          description: A person's friends list           schema:            $ref: \"#/definitions/Persons\"        404:          $ref: \"#/responses/PersonDoesNotExistResponse\"        500:          $ref: \"#/responses/Standard500ErrorResponse\"definitions:  Person:    required:      - username    properties:      firstName:        type: string      lastName:        type: string      username:        type: string  Persons:    type: array    items:      $ref: \"#/definitions/Person\"  Error:    required:      - code      - message    properties:      code:        type: string      message:        type: stringresponses:  Standard500ErrorResponse:    description: An unexpected error occured.    schema:      $ref: \"#/definitions/Error\"  PersonDoesNotExistResponse:    description: Person does not exist.parameters:  username:    name: username    in: path    required: true    description: The person's username    type: string  pageSize:    name: pageSize    in: query    description: Number of persons returned    type: integer  pageNumber:    name: pageNumber    in: query    description: Page number    type: integer      Defining a path parameter once for a pathIf we add a delete operation to the /persons/{username} path, a first idea could be to do it that way:                                                                                                  /persons/{username}:    get:      summary: Gets a person      description: Returns a single person for its username.      parameters:        - name: username          in: path          required: true          description: The person's username          type: string      responses:        200:          description: A Person          schema:            $ref: \"#/definitions/Person\"        404:          $ref: \"#/responses/PersonDoesNotExistResponse\"        500:          $ref: \"#/responses/Standard500ErrorResponse\"    delete:      summary: Deletes a person      description: Delete a single person identified via its username      parameters:        - name: username          in: path          required: true          description: The person's username          type: string      responses:        204:          description: Person successfully deleted.        404:          $ref: \"#/responses/PersonDoesNotExistResponse\"        500:          $ref: \"#/responses/Standard500ErrorResponse\"  Note that we had the good idea to create a reusable 404 response.But having to redefine the username parameter which is shared by each operation on /persons/{username} path is a bit cumbersome. Luckily you can define parameters on path level:                                                                                                  /persons/{username}:    parameters:      - name: username        in: path        required: true        description: The person's username        type: string    get:      summary: Gets a person      description: Returns a single person for its username.      responses:        200:          description: A Person          schema:            $ref: \"#/definitions/Person\"        404:          $ref: \"#/responses/PersonDoesNotExistResponse\"        500:          $ref: \"#/responses/Standard500ErrorResponse\"    delete:      summary: Deletes a person      description: Delete a single person identified via its username      responses:        204:          description: Person successfully deleted.        404:          $ref: \"#/responses/PersonDoesNotExistResponse\"        500:          $ref: \"#/responses/Standard500ErrorResponse\"  Defining reusable parametersIf we add a get /persons/{username}/friends operations to get a paginated list of a person’s friends, a first idea could be to do it that way:                                                                                                  /persons/{username}/friends:    parameters:      - name: username        in: path        required: true        description: The person's username        type: string    get:      summary: Gets a person's friends      description: Returns a list containing all persons. The list supports paging.      parameters:       - name: pageSize         in: query         description: Number of persons returned         type: integer       - name: pageNumber         in: query         description: Page number         type: integer      responses:        200:          description: A person's friends list           schema:            $ref: \"#/definitions/Persons\"        404:          $ref: \"#/responses/PersonDoesNotExistResponse\"        500:          $ref: \"#/responses/Standard500ErrorResponse\"  Note that we reuse the 500 and 404 responses.But that way, we redefine the username parameter just like on path /persons/{username}:                                                                                                  /persons/{username}:    parameters:      - name: username        in: path        required: true        description: The person's username        type: string  And we also redefine the pageNumber and pageSize parameters which already exist on get /persons:                                                                                                  /persons:    get:      summary: Gets some persons      description: Returns a list containing all persons. The list supports paging.      parameters:       - name: pageSize         in: query         description: Number of persons returned         type: integer       - name: pageNumber         in: query         description: Page number         type: integer  Define reusable parametersAs we have done with definitions and responses, we can define reusable parameters within the OpenAPI Specification parameters section (Swagger Object).                                                                                                parameters:  username:    name: username    in: path    required: true    description: The person's username    type: string  pageSize:    name: pageSize    in: query    description: Number of persons returned    type: integer  pageNumber:    name: pageNumber    in: query    description: Page number    type: integer  Use reusable parametersThese reusable parameters can be used with a reference just like definitions and responses.get /personsBefore                                                                                                  /persons:    get:      summary: Gets some persons      description: Returns a list containing all persons. The list supports paging.      parameters:       - name: pageSize         in: query         description: Number of persons returned         type: integer       - name: pageNumber         in: query         description: Page number         type: integer  After                                                                                                  /persons:    get:      summary: Gets some persons      description: Returns a list containing all persons. The list supports paging.      parameters:       - $ref: \"#/parameters/pageSize\"       - $ref: \"#/parameters/pageNumber\"  get and delete /persons/{username}Before                                                                                                  /persons/{username}:    parameters:      - name: username        in: path        required: true        description: The person's username        type: string  After                                                                                                  /persons/{username}:    parameters:      - $ref: \"#/parameters/username\"  get /persons/{username}/friendsBefore                                                                                                  /persons/{username}/friends:    parameters:      - name: username        in: path        required: true        description: The person's username        type: string    get:      summary: Gets a person's friends      description: Returns a list containing all persons. The list supports paging.      parameters:       - name: pageSize         in: query         description: Number of persons returned         type: integer       - name: pageNumber         in: query         description: Page number         type: integer  After                                                                                                  /persons/{username}/friends:    parameters:      - $ref: \"#/parameters/username\"    get:      summary: Gets a person's friends      description: Returns a list containing all persons. The list supports paging.      parameters:       - $ref: \"#/parameters/pageSize\"       - $ref: \"#/parameters/pageNumber\"  ConclusionBy defining reusable definitions, responses and parameters and using them with references you can easily write OpenAPI Specification files which are simple and easily understandable. In next post, we’ll dig deeper in various aspect of the OpenAPI Specification."
},{
    "id": "79",
    "type": "post",
    "title": "Writing OpenAPI (Swagger) Specification Tutorial Series - Part 2 - The basics",
    "url": "https://apihandyman.io/writing-openapi-swagger-specification-tutorial-part-2-the-basics/",
    "banner": "https://apihandyman.io/images/writing-openapi-swagger-specification-tutorial-part-2-the-basics/banner.png",
    "description": "After discovering what is the OpenAPI Specification format, it’s now time to write a first simple OpenAPI Specification file to learn the basics.",
    "body": "After discovering what is the OpenAPI Specification format, it’s now time to write a first simple OpenAPI Specification file to learn the basics.      Writing OpenAPI (Swagger) Specification Tutorial Series                      This tutorial teaches everything about the OpenAPI 2.0 Specification (fka. as Swagger), most of what you’ll read here can still be applied on version 3.If you’re a bit lost in the specification (version 2 or 3), take a look at the OpenAPI Map:                                                                                                      1 - Introduction                                      2 - The basics                                      3 - Simplifying specification file                                      4 - Advanced Data                                      5 - Advanced Input And Output Modeling                                      6 - Defining Security                                      7 - Documentation                                      8 - Splitting specification file                                      9 - Extending the OpenAPI specification                                      In this second part you will learn how to give some basic informations about your API, describe endpoints using various HTTP methods with path, query and body parameters and returning various HTTP status and responses.An almost empty OpenAPI SpecificationWe’ll start with an almost empty, yet valid, file giving some basic informations.                                                                                                swagger: \"2.0\"info:  version: 1.0.0  title: Simple API  description: A simple API to learn how to write OpenAPI Specificationschemes:  - httpshost: simple.apibasePath: /openapi101paths: {}  OpenAPI Specification versionFirst we need to tell which version of the OpenAPI specification we are using via the swagger attribute…                                                                                                swagger: \"2.0\"  Yes, swagger. As explained in the introduction, the OpenAPI specification is based on Swagger. It will probably be replaced by something else in the next version of the specification.The only possible value is (for now) 2.0.API descriptionThen we give some informations about our API with info: the API’s version (not to be confused with the specification version and the file version) a title and an optionnal description.                                                                                                info:  version: 1.0.0  title: Simple API  description: A simple API to learn how to write OpenAPI Specification  API URLSpeaking of web API, an important information is the root URL which people and programs will use to call it.This is described by giving a list of accepted schemes (or protocols, like http or https), a host, and a basepath.                                                                                                schemes:  - httpshost: simple.apibasePath: /openapi101  All of these APIs endpoints URL will use https://simple.api/open101 as base URL.These informations are not required, an OpenAPI specification without these data is still valid.API operationsFinally, as our API does absolutely nothing for now, we add an empty paths list. (nb. in YAML an empty object is describe using {}).                                                                                                paths: {}  Defining an operationLet our API do something by adding an operation to list some persons.                                                                                                swagger: \"2.0\"info:  version: 1.0.0  title: Simple API  description: A simple API to learn how to write OpenAPI Specificationschemes:  - httpshost: simple.apibasePath: /openapi101paths:  /persons:    get:      summary: Gets some persons      description: Returns a list containing all persons.      responses:        200:          description: A list of Person          schema:            type: array            items:              required:                - username              properties:                firstName:                  type: string                lastName:                  type: string                username:                  type: string  Adding a pathIn the paths section we add a new path /persons corresponding to the persons resource.                                                                                                paths:  /persons:  Adding an http method on pathOn each path we can add any http verb (like get, post, put or delete) to manipulate the corresponding resource.To list some persons, we need to apply the get http method to the /persons resource (or path). We also give a short description (summary) and a longer one if necessary (description).                                                                                                    get:      summary: Gets some persons      description: Returns a list containing all persons.  Therefore to list some persons we’ll have to call get /persons (or get https://simple.api/open101/persons to be precise).Describing responseFor each operation, you can describe any response matching an http status code (like 200 OK or 404 Not Found) in the responses section.We’ll only handle 200 when responding to get /persons and we’ll tell what the response means via its description.                                                                                                      responses:        200:          description: A list of Person  Describing response’s contentThe get /persons operation returns a list of persons, we describe what it is with the schema section of the response.A list of person is an object which type is array. Each item in this array is an object containing three properties of type string: firstName, lastName and username. Only username will be always provided (i.e. required).                                                                                                          schema:            type: array            items:              required:                - username              properties:                firstName:                  type: string                lastName:                  type: string                username:                  type: string  Defining query parametersAs we’ll have to handle many persons, it could be a good idea to add paging capabilities to the get /resources operation. We’ll do that by adding query parameters to define the requested page and number of items per page.                                                                                                swagger: \"2.0\"info:  version: 1.0.0  title: Simple API  description: A simple API to learn how to write OpenAPI Specificationschemes:  - httpshost: simple.apibasePath: /openapi101paths:  /persons:    get:      summary: Gets some persons      description: Returns a list containing all persons. The list supports paging.      parameters:       - name: pageSize         in: query         description: Number of persons returned         type: integer       - name: pageNumber         in: query         description: Page number         type: integer      responses:        200:          description: A list of Person          schema:            type: array            items:              required:                - username              properties:                firstName:                  type: string                lastName:                  type: string                username:                  type: string  Adding a parameters section to the get /persons operationFirst we add a parameters section in get http method for /persons path.                                                                                                paths:  /persons:    get:      summary: Gets some persons      description: Returns a list containing all persons. The list supports paging.      parameters:  Adding paging query parametersThen in the parameters list we define two optional parameters named pageSize and pageNumber of type integer located in query. We also provide a description for each one.                                                                                                      parameters:       - name: pageSize         in: query         description: Number of persons returned         type: integer       - name: pageNumber         in: query         description: Page number         type: integer      responses:  Therefore to list some persons we can use get /persons?pageSize=20&amp;pageNumber=2 and we’ll get the page number 2 with 20 persons max.Defining a path parameterWe would like to access directly a specific person by it’s username, so we’ll add a get /persons/{username} operation to our API. {username} is called a path parameter.                                                                                                swagger: \"2.0\"info:  version: 1.0.0  title: Simple API  description: A simple API to learn how to write OpenAPI Specificationschemes:  - httpshost: simple.apibasePath: /openapi101paths:  /persons:    get:      summary: Gets some persons      description: Returns a list containing all persons. The list supports paging.      parameters:       - name: pageSize         in: query         description: Number of persons returned         type: integer       - name: pageNumber         in: query         description: Page number         type: integer      responses:        200:          description: A list of Person          schema:            type: array            items:              required:                - username              properties:                firstName:                  type: string                lastName:                  type: string                username:                  type: string  /persons/{username}:    get:      summary: Gets a person      description: Returns a single person for its username      parameters:        - name: username          in: path          required: true          description: The person's username          type: string      responses:        200:          description: A Person          schema:            required:              - username            properties:              firstName:                type: string              lastName:                type: string              username:                type: string        404:          description: The Person does not exists.  Adding a get /persons/{username} operationFirst we add a /persons/{username} path, after the /persons one, in the paths section and define the get operation for this path.                                                                                                swagger: \"2.0\"info:  version: 1.0.0  title: Simple API  description: A simple API to learn how to write OpenAPI Specificationschemes:  - httpshost: simple.apibasePath: /openapi101paths:  /persons:                                                                                                                  username:                  type: string  /persons/{username}:    get:      summary: Gets a person      description: Returns a single person for its username  Describing username path parameterAs {username} is a path parameter, we need to describe it. It is done by adding a parameters section to the get operation and adding a required parameter with a name matching the parameter defined in the path (here username) located in path of type string. We also provide an optional description.                                                                                                      parameters:        - name: username          in: path          required: true          description: The person's username          type: string  A common problem when defining path parameter is to forget required: true (as the Swagger Editor snippet do not provide it). If required is not provided, its default value is false, meaning that the parameter is optional. A path parameter is always required.Adding responsesDon’t forget to add 200 response returning a person. Note that the schema used in 200 is the same as the array’s item in get /persons 200 response.                                                                                                      responses:        200:          description: A Person          schema:            required:              - username            properties:              firstName:                type: string              lastName:                type: string              username:                type: string  As a username may not match an existing person we also add a 404 response. Note that this response do not return anything besides the 404 http status code.                                                                                                        404:          description: The Person does not exists.  Defining a body parameterWe would like to have the capability of adding a person to our list of persons so we’ll add a post /persons operation to our API.                                                                                                swagger: \"2.0\"info:  version: 1.0.0  title: Simple API  description: A simple API to learn how to write OpenAPI Specificationschemes:  - httpshost: simple.apibasePath: /openapi101paths:  /persons:    get:      summary: Gets some persons      description: Returns a list containing all persons. The list supports paging.      parameters:       - name: pageSize         in: query         description: Number of persons returned         type: integer       - name: pageNumber         in: query         description: Page number         type: integer      responses:        200:          description: A list of Person          schema:            type: array            items:              required:                - username              properties:                firstName:                  type: string                lastName:                  type: string                username:                  type: string    post:      summary: Creates a person      description: Adds a new person to the persons list.      parameters:        - name: person          in: body          description: The person to create.          schema:            required:              - username            properties:              firstName:                type: string              lastName:                type: string              username:                type: string      responses:        204:          description: Persons succesfully created.        400:          description: Persons couldn't have been created.  /persons/{username}:    get:      summary: Gets a person      description: Returns a single person for its username.      parameters:        - name: username          in: path          required: true          description: The person's username          type: string      responses:        200:          description: A Person          schema:            required:              - username            properties:              firstName:                type: string              lastName:                type: string              username:                type: string        404:          description: The Person does not exists.  Adding post /persons operationWe first add a post method to the /persons path (after the get one) in the paths section.                                                                                                paths:  /persons:                                                                                                      post:      summary: Creates a person      description: Adds a new person to the persons list.  Describing a person body parameterThen we define a parameter named person located in body of type object. The person object’s is described via it’s schema. Note that this schema is the same as the 200 response of get /persons/{username}. The firstName and lastName attributes are optional and username is required.                                                                                                      parameters:        - name: person          in: body          description: The person to create.          schema:            required:              - username            properties:              firstName:                type: string              lastName:                type: string              username:                type: string  Defining responsesDon’t forget to define responses for this new operation.                                                                                                      responses:        204:          description: Persons succesfully created.        400:          description: Persons couldn't have been created.  To simplicity and beyondYou now have learned the basics of the OpenAPI Specification. But as you may have guess, working that way on huge API may not be so easy. But rest assured, the OpenAPI Specification files we’ve seen can be simplified. We’ll learn in the next part how to describe swiftly and easily even the hugest API by using factorization and references."
},{
    "id": "80",
    "type": "post",
    "title": "Writing OpenAPI (Swagger) Specification Tutorial Series - Part 1 - Introduction",
    "url": "https://apihandyman.io/writing-openapi-swagger-specification-tutorial-part-1-introduction/",
    "banner": "https://apihandyman.io/images/writing-openapi-swagger-specification-tutorial-part-1-introduction/banner.png",
    "description": "Previously in the APIverse… Since I started my Swagger journey, there have been some changes. The Swagger Specification has been donated to the newly created OpenAPI Initiative under the Linux foundation and is reborn as the OpenAPI Specification. Therefore, my Swagger Journey will become an OpenAPI Specification (fka Swagger Specification) Journey.",
    "body": "Previously in the APIverse…Since I started my Swagger journey, there have been some changes. The Swagger Specification has been donated to the newly created OpenAPI Initiative under the Linux foundation and is reborn as the OpenAPI Specification. Therefore, my Swagger Journey will become an OpenAPI Specification (fka Swagger Specification) Journey.This first part explains what is the OpenAPI Specification, why you will use it and what tools you can use to write these specifications.      Writing OpenAPI (Swagger) Specification Tutorial Series                      This tutorial teaches everything about the OpenAPI 2.0 Specification (fka. as Swagger), most of what you’ll read here can still be applied on version 3.If you’re a bit lost in the specification (version 2 or 3), take a look at the OpenAPI Map:                                                                                                      1 - Introduction                                      2 - The basics                                      3 - Simplifying specification file                                      4 - Advanced Data                                      5 - Advanced Input And Output Modeling                                      6 - Defining Security                                      7 - Documentation                                      8 - Splitting specification file                                      9 - Extending the OpenAPI specification                                      The OpenAPI SpecificationThe OpenAPI Specification is an API description format or API definition language. Basically, an OpenAPI Specification file allow you to describe an API including (among other things):  General information about the API  Available paths (/resources)  Available operations on each path (get /resources)  Input/Output for each operationThe Open API Specification’s specification can be found in the github repository of the Open API Initiative. This document describes every aspect of the Open API Specification.Even if this documentation is fairly easy to read, I was sometimes a little bit lost. So, based on this text specification, I have created the OpenAPI Map a visual documentation which can help to figure how a OpenAPI specification file is structured for people who are more visual like me.                                      OpenAPI Map          Reading the specification is not mandatory to do this tutorial, you can dig into the specification as you discover it through this tutorial.Why using an API definition language such as OpenAPI specification?Using an API definition language such as OpenAPI specification helps to describe easily and quickly an API. It’s particularly useful when you’re in the design process of your API (cf. my first post in the series).Being a simple text file, the OpenAPI specification file can be shared and managed within any VCS just like [code]/code.Once written, OpenAPI specification file can also be used as:  source material for documentation  specification for developers  partial or complete code generation  and many other things…Writing OpenAPI SpecificationWhat can we use to write an OpenAPI Specification file?  You kids keep your noses clean, you understand? You’ll be hearing from me if you don’t! We ain’t gonna stand for any weirdness out here! Officer Dorf about OpenAPI Specification writingJSON vs YAML                                                An Open API Specification file can be written either in JSON or YAML. But, if you intend to write and not generate this file, I urge you to do that in YAML as YAML is far more easy to write and read than JSON.A picture is worth a thousand words, let’s compare a simple definition in JSON…                                                                                                {    \"swagger\": \"2.0\",    \"info\": {        \"version\": \"1.0.0\",        \"title\": \"Simple API\",        \"description\": \"A simple API to learn how to write OpenAPI Specification\"    },    \"schemes\": [        \"https\"    ],    \"host\": \"simple.api\",    \"basePath\": \"/openapi101\",    \"paths\": {        \"/persons\": {            \"get\": {                \"summary\": \"Gets some persons\",                \"description\": \"Returns a list containing all persons.\",                \"responses\": {                    \"200\": {                        \"description\": \"A list of Person\",                        \"schema\": {                            \"type\": \"array\",                            \"items\": {                                \"properties\": {                                    \"firstName\": {                                        \"type\": \"string\"                                    },                                    \"lastName\": {                                        \"type\": \"string\"                                    },                                    \"username\": {                                        \"type\": \"string\"                                    }                                }                            }                        }                    }                }            }        }    }}  …to the same definition in YAML:                                                                                                swagger: \"2.0\"info:  version: 1.0.0  title: Simple API  description: A simple API to learn how to write OpenAPI Specificationschemes:  - httpshost: simple.apibasePath: /openapi101paths:  /persons:    get:      summary: Gets some persons      description: Returns a list containing all persons.      responses:        200:          description: A list of Person          schema:            type: array            items:              required:                - username              properties:                firstName:                  type: string                lastName:                  type: string                username:                  type: string  YAML seems definitely more easy to write and read for humans. And almost every tool using OpenAPI specification files handle YAML. In last resort, you can easiliy convert YAML to JSON (and vice versa).EditorEven if an OpenAPI specification is a simple text file which can be edited with any text editor, it’s better to use a specialized one. The best available tool to write Open API Specification file is Swagger Editor. It’s a set of static file allowing you to write and validate Open API Specification in YAML and see a rendering of the written specification.                                                On the left pane, you write your API definition.On the right one you see a rendering of your definition and potential syntax errors.The editor also provides useful snippets to guide you:                                                You can use the online version but you can also have your own editor instance on any http server. You just need to download the lastest build and serve it with an http server. Go to Swagger Editor Github repository for a complete how-to.What about writing your first OpenAPI Specification?                                      YAML + editor. You've been warned.          We are now ready to proceed to Part 2 - The basics and write our first API definition using the Open API Specification."
},{
    "id": "81",
    "type": "post",
    "title": "Don't mess with hypermedia controls (REST Fest 2015)",
    "url": "https://apihandyman.io/dont-mess-with-hypermedia-controls-rest-fest-2015/",
    "banner": "https://apihandyman.io/images/dont-mess-with-hypermedia-controls-rest-fest-2015/banner.png",
    "description": "I had the pleasure to participate to REST Fest 2015, here are my 5 in 5 video and slide deck about hypermedia controls. If you can attend only one API conference, this is the one.",
    "body": "I had the pleasure to participate to REST Fest 2015, here are my 5 in 5 video and slide deck about hypermedia controls. If you can attend only one API conference, this is the one.Video                                                This content is hosted on vimeo.com.                By showing this third party content you accept Vimeo's                     cookie policy.                                                    Show third party content                                                                    Remember my choice                        (can be changed in privacy settings)                                                                                      SlidesDownload PDFOpen PDF    "
},{
    "id": "82",
    "type": "post",
    "title": "A quest for simplicity (API Days London 2015)",
    "url": "https://apihandyman.io/a-quest-for-simplicity-api-days-london-2015/",
    "banner": "https://apihandyman.io/images/a-quest-for-simplicity-api-days-london-2015/banner.png",
    "description": "A ROAST API is a SOAP API made by people who have vaguely heard of REST API Right after REST Fest, I had the honor to give my first keynote at the first edition of API Days London in September 2015. Join me in a quest for simplicity from an imaginary bank’s IS depth to its API’s heights.",
    "body": "  A ROAST API is a SOAP API made by people who have vaguely heard of REST APIRight after REST Fest, I had the honor to give my first keynote at the first edition of API Days London in September 2015.Join me in a quest for simplicity from an imaginary bank’s IS depth to its API’s heights.  It’s time to take the API matter seriouslyHere are this keynote’s video and slidedeck.Video                                                This content is hosted on youtube.com.                By showing this third party content you accept YouTube (Google)'s                     privacy policy.                                                    Show third party content                                                                    Remember my choice                        (can be changed in privacy settings)                                                                                      Here’s API Days London 2015 teaser … watch well there may be some API Handyman subliminal images…                                                This content is hosted on youtube.com.                By showing this third party content you accept YouTube (Google)'s                     privacy policy.                                                    Show third party content                                                                    Remember my choice                        (can be changed in privacy settings)                                                                                      SlidesDownload PDFOpen PDF    "
},{
    "id": "83",
    "type": "post",
    "title": "Read The Utopia Of API Documentation on Smartbear Blog",
    "url": "https://apihandyman.io/read-the-utopia-of-api-documentation-on-smartbear-blog/",
    "banner": "https://apihandyman.io/images/read-the-utopia-of-api-documentation-on-smartbear-blog/banner.png",
    "description": "Jennifer Riggins wrote a blog post about my Document-API-topia talk, you can read the Utopia of API documentation on Smartbear blog.",
    "body": "Jennifer Riggins wrote a blog post about my Document-API-topia talk, you can read the Utopia of API documentation on Smartbear blog."
},{
    "id": "84",
    "type": "post",
    "title": "Document-API-topia (API Days Paris 2015)",
    "url": "https://apihandyman.io/document-api-topia-api-days-paris-2015/",
    "banner": "https://apihandyman.io/images/document-api-topia-api-days-paris-2015/banner.png",
    "description": "I gave a Star Wars themed talk with a lightsaber about my new passion, documentation, at API Days Paris 2015. Yes, a talk about D-O-C-U-M-E-N-T-A-T-I-O-N. Yes, a S-T-A-R W-A-R-S themed talk. Yes, I gave this talk holding a L-I-G-H-T-S-A-B-E-R.",
    "body": "I gave a Star Wars themed talk with a lightsaber about my new passion, documentation, at API Days Paris 2015.Yes, a talk about D-O-C-U-M-E-N-T-A-T-I-O-N. Yes, a S-T-A-R W-A-R-S themed talk.Yes, I gave this talk holding a L-I-G-H-T-S-A-B-E-R.I had the luck to be helped by two great persons when preparing this talk, Jennifer Riggins and Paul Bruce. Both gave me precious feedbacks and tips. Many great thanks to them!I talked about an ideal world where API (and software) and documentation live in perfect harmony, describing some crazy ideas such as documentation continuous delivery or documentation package manager but also stating that we need both machines and humans to create this ideal world. Jennifer Riggins wrote a blog post about my Document-API-topia published on Smartbear’s Blog.If you want to know more about what happened at this awesome conference, you can read my API Days Paris 2015 recap with a light saber.Here are my talk’s video (thanks to Guillaume Laforge) and slidedeck.Video                                                This content is hosted on youtube.com.                By showing this third party content you accept YouTube (Google)'s                     privacy policy.                                                    Show third party content                                                                    Remember my choice                        (can be changed in privacy settings)                                                                                      SlidesDownload PDFOpen PDF    "
},{
    "id": "85",
    "type": "post",
    "title": "API Days Paris 2015 with a lightsaber",
    "url": "https://apihandyman.io/api-days-paris-2015-with-a-lightsaber/",
    "banner": "https://apihandyman.io/images/api-days-paris-2015-with-a-lightsaber/banner.png",
    "description": "API Days Paris just finished this Thursday, leaving me both sad and exhausted and happy and full of energy. Sad and exhausted because this awesome and intense API conference is over. Happy and full of energy because this awesome and intense API conference exists.",
    "body": "API Days Paris just finished this Thursday, leaving me both sad and exhausted and happy and full of energy.Sad and exhausted because this awesome and intense API conference is over.Happy and full of energy because this awesome and intense API conference exists.Two days about automating IT business and the whole society with APIs.Two days about humanity, society, philosophy and technology.Two days listening and talking to great people from the APIverse.Two days of discussion and discovery.Two days hanging with old and new friends. Two days tweeting like a berserk.API Days Paris 2015 in a few numbers and wordsThis year API Days Paris numbers are:  1 light saber  1 REST Fest hack day  2 long days  3 short nights  3 custom Commitstrips  4 tracks  73 talks and workshops  800 attendees  1600 tweets (around 450 by myself!)  Thousands of “bouchées”, petit four, … and drinksBehind the numbers, the main topics I’ve took away are:  Man vs Machine  Composite Enterprise  Hypermedia APIs  Design efficient APIs  Event driven efficient APIs  AutomationMan vs MachineChristan Fauré stated we fear that automation means less jobs. We must put humanity at the center of automation and question what we want automate, de-automate, not automate.As letters were the root of humanism, APIs are the root of digital humanism. But we need a fertile ground for our API strategy.  Culture eats strategy at breakfastPeter DruckerWe must change our culture, our social automatisms to create this fertile ground.Do not oppose automation and creativity, stay creative when working on API projects. Let the human drive these projects.Steven Willmott wondered if automation is a good thing? It depends, and the question should be does automation creates or consumes value?  Software is eating the world.Marc AndreessenBoth Willmot and Bernard Stiegler stated that automation MUST creates new jobs, create value.Willmott also pointed that we should not teach everybody to be engineers. Not everybody needs it. We are building solutions for humans.Louis Dorard explained that machine alone is not the only answer.Human, machine learning and automation enable a new level of human productivity.As always, choosing between machine alone, human alone or human + machine will depend on the context.Ashley Hathaway reassured us, Skynet and HAL9000 are not upon us.We need all the people, the whole is greater than the sum of its parts. Providing tools to developers to make things happens.Daniel Benoilid said that Human can empower APIs.Composite EnterpriseKirsten Moyer told us that if the business model doesn’t change, its not digital transformation. APIs will be the most common reference platform for mapping next generation business models.These business models will need technology. Peter Matthews stated that digital disruptors understand the benefits of technology.Neha Sampat predicted that CEOs will start to ask about APIs (not APPS).  Traditional IT becomes irrelevant, companies have to think out of the box. API management becomes business critical. Delivering, visualizing, metrics,…Saul Caganoff warned us that enterprises must become digital or others will become for them. Even if the Web is now programmable, enterprises need to enable composite enterprise. There are many SAAS services (infrastructure,commodity,functionnal,industry) and a growing ecosystem of iPaas and cloud bpm.  But unique business value will come out of how companies operate/orchestrate all this stated both Caganoff and Sempat.Hypermedia APIsLike last year, Hypermedia was a huge concern.Hypermedia 101REST Fest alumnis Shelby Switzer, Benjamin Young and Darrel Miller gave a clear 101 on REST (hypermedia) APIs. Identifying resources, manipulate through representation, self descriptive message, and hypermedia.Finding the right balance between cache, linked and embedded resources will provide network efficiency. Darrel reminded us the importance of hypermedia:  Hypermedia contraint is greater than the sum of rest constraintsAristotle Pagaltzis in The REST Architectural Style ListPragmatic HypermediaWhen Jason Harmon asked the audience who was doing hypermedia API, not so many hands raised. People have to be pragmatic: implementing hypermedia must be questionned. First concern must be the value added for developers.Both Jason and REST Fest alumnis agreed on the fact that making an API predictable by just having a good design (use right HTTP verbs, status, consistent paths structures, …) will already enhance developer experience.But providing an hypermedia API will definitely improve developer experience.With an hypermedia API, developers only have to follow the links and will be aware of what they can do or not by analyzing the hypermedia controls without the need of business knowledge.Hypermedia EnterpriseFor Saul Caganoff enterprise need to focus on the S in REST: State.Enterprise needs hypermedia to handle business processes with their APIs.A business process is a path through the state model.Design efficient APIsThere are situations where REST/web APIs should be questioned. Any tool MUST be chosen wisely.REST vs SparQLFor Ruben Verborgh we need simple server and clever clients enabled by hypermedia APIs and especially the use of linked data.When evaluating API design and implementation, the question is not is it good or bad but how you can impact positively and meaningfully noth server and consumer (CPU, network).Verborgh compare the usage of classic REST API and SparQL on both consumer and server side. The SparQL query language can be seen as the GraphQL of linked data.REST API tend to generate many calls but can be easily cached, and tend also to be not enough adaptive to the client need. On the other SparQL enable the creation of tailor made APIs but consumes many resources on the server side.The conclusion is: if you have the money use GraphQL or SparQL, if not, be clever.Think design carefullyRoss Garrett reminded us that you don’t get a prize on level 3 of Richardson’ Maturity Model as stated Leonard Richardson himself at last REST Fest.Web APIs can sting you. As many request as resources, data redundancy, scalability, payload size, all this has an impact on user experience and has a cost. Don’t over-deliver data, don’t forget HTTP status 304 and think carefully your design.Eric Horesnyi promote the use of JSON PATCH to diminished data volume.Be adaptiveHugo Hache reminded us that some of API consumers are mobile.Latency, bandwidth, network absence, you have to be adaptive on both server and client.Parallelizing request or nesting resource? 4 little request replaced by 1 bigger, is more efficient when considering latency.Server should be able to modulate response size on client demand.Event driven efficient APIs  A new trending topic arose: Events.Events become first-class citizenNeha Sampat, Saul Caganoff,Ross Garrett and Eric Horesnyi agree about the importance of events.  Caganoff stated that there’s a duality between business processes transitions and events.Events can be handle through webhooks and syndication.Stream And Think ReactiveInternet is an hostile environment especially mobile internet (latency, drop connection), Ross Garrett ask us to stop polling, diminish payload. There is no one size does fit all solution, but new solutions are not adopted easily (HTTP2 push, MQTT).Eric Horesnyi compared streaming technologies: web socket vs server side events. They are almost the same from the consumer point of view, the differences lie on the server side.  SSE is HTTP standard, HTTP2 compliant, infrastructure is ready for it  Web Socket is TCP, error handling is not defined, protocol upgradeBoth Horesnyi and Garret asked us to think Reactive.  AutomationAutomation and documentationJakub Nesetril pointed that APIs can rapidly be inconsistent, incompatible, infuriating especially when you have more than one API.Generated documentation will not solve API last or API after thought strategy.Both Nesetril and myself stated that there’s a need for API production lifecycle tools. Tools which can help to create a worflow covering design, prototype, implementation (TDD), delivery of documents, feedback.I described an ideal automated world where API and documentation live in a perfect harmony. Jennifer Riggins wrote a blog post about my Document-API-topia.Design needs the definition of style guides, many companies have published their guides. But these style guides needs to be enforced into design tools. Apiary propose such tools, Jason Harmon work on checkstyle tools for Swagger definitions.Easy automation  Luis Borger Quina and Philippe Sultan told us that bots are the new apps and no UI is the new UI. Slack, IFFTT, Zapier enable easy automation.Julien Mession explained that taking time to build APIs for devops is worth the cost and that it’s easy to test API in devops context.Webhooks and APIs facilitate closing the gaps between tools.Very special thanks and see you at next API conferenceFirst and foremost I would like to thank Mehdi Medjaoui, Mark Boyd and the API Days staff for creating such an awesome event and giving me the opportunity to share my Document-API-topia.I would also like to thank Jennifer Riggins and Paul Bruce for helping preparing my talk.Heartfelt thanks to Kin Lane for being such a huge inspiration.And finally big thank to all speakers and attendees for making this event so awesome.Looking forward to next API conference to see y’all again!SlidedecksHere are some slide decks:  Automating developer adoption (Nicolas Garnier)  State of Web API Languages (Jérôme Louvel)  Hypermedia and Civi Hacking (Shelby Switzer)  More power to API clients (Yann Simon)  Simple Servers Clever Clients (Ruben Verborgh)  APIs and the creation of wealth in the digital economy (Steven Willmott)  Bold Predictions for the 2016 API economy (Neha Sampat)  Automating business process with APIs (Saul Caganoff)  Document-API-topia (Arnaud Lauret)  Build a successful API Overnight : Kill the Unicorn ! (Olivier Etienne)  Future of AI-powered automation in business (Louis Dorard)  When RESTful maybe considered harmful (Ross Garrett)  Bots are the new app. Disrupting communications with slackbots (Luis Borges-Quina and Philippe Sultan)"
},{
    "id": "86",
    "type": "post",
    "title": "Starting a Swagger journey beyond generated Swagger UI",
    "url": "https://apihandyman.io/starting-a-swagger-journey-beyond-generated-swagger-ui/",
    "banner": "https://apihandyman.io/images/starting-a-swagger-journey-beyond-generated-swagger-ui/banner.png",
    "description": "When watching a movie, have you ever noticed how characters interact with computers? If someone wants to destroy a computer, what does he or she smash? The computer’s screen…",
    "body": "When watching a movie, have you ever noticed how characters interact with computers? If someone wants to destroy a computer, what does he or she smash?The computer’s screen…                                                With Swagger, it’s almost the same thing. Many people focus only on generated Swagger UI and only see Swagger as a useful way to generate documentation from an API implementation.But reducing Swagger to an auto-generated interactive API documentation is a terrible mistake.  Swagger is a simple yet powerful representation of your RESTful API.Swagger.io… and it’s far from the truth.In this first post of a new series, I will tell you how I’ve stopped being a computer’s screen smasher and started my Swagger journey.Lessons from the trenches of an API projectWhen I started to work on my company’s new API project, Swagger was only Swagger UI, the thing that generate interactive API documentation using annotation in a java application.It was only a by-product of the project.But after working for a while on this project, some concerns, not all related to the generated Swagger UI, arise.Documentation tightly coupled with implementation                                      Documentation (Henry Jones Sr) tightly coupled with implementation (Henry Jones Jr)          Even if our new API is not an open one, it is used by people outside our company so I started to take a closer look at the generated documentation to check if everything was ok. It was… on the surface:  Swagger UI was working  Users could browse the documentation  Users could test the API through this interactive documentationBut when taking a closer look at this generated documentation, some problems appear.                                      Pet Store Swagger model view example          Even if the resulting API was matching the specification, the model view of Swagger UI reveal some holes in the specification and was not satisfying:  The model names were reflecting poorly named java classes.  The model hierarchy was not consistent and poorly designed.  Some attributes format were not the good ones.There were also some typing errors and missing informations in operations or attributes descriptions.Nothing serious, but to correct the generated documentation, we had to modify the application, rebuild it and deploy it. This tight coupling between the generated API documentation and its implementation was annoying in our context.From API last to API firstEven if our new API is not a ROAST one (really dumb SOAP to pseudo REST conversion), it is still tightly coupled to our SOA as it was designed last and with not much hindsight. Just like a by-product, just like a necessary evil.  I wanted to change that and make the API a first class citizen in our system just like our website or mobile application.I wanted to really have an API first approach with tools to help us design faster and mock to test easily the design to ensure a good quality from the start.A good Word specification is the one you didn’t wroteWether you design your API last or first, you need something to describe it. We were using Word and Excel documents to describe our API, just like we’ve always done with our SOA.Working with such documents has never been an easy task:  Templates are not constraining enough and lead to inconsistent documentations.  If you change your template, you have to modify all previously written ones manually (and of course you don’t do it).  It takes far too long time to write a simple description.  Have you ever try to compare to different versions of a word document?  These documents are only (barely) readable by humans and you cannot use them with programs.  Documentation is written twice: on design time and on development time.I wanted to get rid of all this and have something more fast, more simple, more consistent, more maintainable, more documentation as code and both human and machine readable.Eureka! Swagger 2.0Hopefully, it was at that time that Swagger 2.0 was released with the YAML editor and its tools.Thanks to this new version, I realized my mistake, I realized that Swagger was not only generated Swagger UI.  Eureka!API handyman taking a bathSwagger is an API definition language and there are so many tools using it.                                      Swagger API definition in Swagger Editor          By really using Swagger and its ecosystem I thought we could:  Write better and more consistent API definition once and faster, especially with the YAML editor.  Decouple API documentation from its implementation.  Have machine readable documentation useable with many existing tools (like mock generator, Postman and many others).  Treat documentation as code.  Facilitate the API first approach and the building of an API governance.  And also do many other things I couldn’t imagine at that time…To boldly go …So this is how I started my Swagger journey, with so many ideas in mind and so many hopes. But I was confident and I knew I would not be alone on this journey as the Swagger community is large and friendly.On the next post, I’ll explain how I use standard Swagger tools to write API definitions."
},{
    "id": "87",
    "type": "post",
    "title": "Interview with an API Handyman",
    "url": "https://apihandyman.io/interview-with-an-api-handyman/",
    "banner": "https://apihandyman.io/images/interview-with-an-api-handyman/banner.png",
    "description": "I’ve been interviewed by Lexy Mayko from API2Cart, you can read the interview here.",
    "body": "I’ve been interviewed by Lexy Mayko from API2Cart, you can read the interview here."
},{
    "id": "88",
    "type": "post",
    "title": "Read How to Provide APIs With an Existing Information System on Nordic APIs blog",
    "url": "https://apihandyman.io/read-how-to-provide-apis-with-an-existing-information-system-on-nordic-apis-blog/",
    "banner": "https://apihandyman.io/images/read-how-to-provide-apis-with-an-existing-information-system-on-nordic-apis-blog/banner.png",
    "description": "If you want to know why an existing IS is not a good API, you should read my last post on Nordic APIs blog How to Provide APIs With an Existing Information System.",
    "body": "If you want to know why an existing IS is not a good API, you should read my last post on Nordic APIs blog How to Provide APIs With an Existing Information System."
},{
    "id": "89",
    "type": "post",
    "title": "Read Should Every Company Consider Providing an API? on Nordic APIs blog",
    "url": "https://apihandyman.io/read-should-every-company-consider-providing-an-api-on-nordic-apis-blog/",
    "banner": "https://apihandyman.io/images/read-should-every-company-consider-providing-an-api-on-nordic-apis-blog/banner.png",
    "description": "My other self Arnaud Lauret writes about APIs too. This week you can read Should Every Company Consider Providing an API? on Nordic APIs blog.",
    "body": "My other self Arnaud Lauret writes about APIs too. This week you can read Should Every Company Consider Providing an API? on Nordic APIs blog."
},{
    "id": "90",
    "type": "post",
    "title": "Do you really know why you prefer REST over RPC?",
    "url": "https://apihandyman.io/do-you-really-know-why-you-prefer-rest-over-rpc/",
    "banner": "https://apihandyman.io/images/do-you-really-know-why-you-prefer-rest-over-rpc/banner.png",
    "description": "A few weeks ago I’ve seen an interesting flock of tweets initiated by this question: This question and the tweets that followed put my brain on quite an animated discussion…",
    "body": "A few weeks ago I’ve seen an interesting flock of tweets initiated by this question:  This question and the tweets that followed put my brain on quite an animated discussion…                                                After this internal discussion, I realized that this question (and all the tweet debate that follows it) could help me highlight a dark corner of my librainry: why should I considered REST’s request style (resource oriented) better than RPC’s (operation oriented)? Is RPC’s request style so evil? Is REST’s the panacea?What RPC’s and REST’s requests styles look likeBefore comparing the two request styles let’s see what they look like.The HTTP requestBoth RPC and REST use HTTP protocol which is a request/response protocol.A basic HTTP request consists of:  A verb (or method)  A resource (or endpoint)Each HTTP verb:  Has a meaning  Is idempotent or not: A request method is considered “idempotent” if the intended effect on the server of multiple identical requests with that method is the same as the effect for a single such request (see RFC7231: Idempotent methods).  Is safe or not: Request methods are considered “safe” if their defined semantics are essentially read-only (see RFC7231: Safe methods).  Is cacheable or not            Verb      Meaning       Idempotent        Safe        Cacheable                   GET      Reads a resource      Yes      Yes      Yes              POST      Creates a resource or triggers a data-handling process      No      No      Only cacheable if response contains explicit freshness information              PUT      Fully updates (replaces) an existing resource or create a resource      Yes      No      No              PATCH      Partially updates a resources      No      No      Only cacheable if response contains explicit freshness information              DELETE      Deletes a resource      Yes      No      No      The table above shows only the HTTP verbs used commonly by RPC and REST APIs.RPC: The operation request styleThe RPC acronym has many meanings and Remote Procedure Call has many forms.In this post, when I talk about RPC I talk about WYGOPIAO: What You GET Or POST Is An Operation.With this type of RPC, you expose operations to manipulate data through HTTP as a transport protocol.As far as I know, there are no particular rules for this style but generally:  The endpoint contains the name of the operation you want to invoke.  This type of API generally only uses GET and POST HTTP verbs.                                                                                        GET /someoperation?data=anIdPOST /anotheroperation{  &quot;data&quot;:&quot;anId&quot;;   &quot;anotherdata&quot;:&quot;another value&quot;}  How do people choose between GET and POST?  For those who care a little about HTTP protocol this type of API tends to use GET for operations that don’t modify anything and POST for other cases.  For those who don’t care much about HTTP protocol, this type of API tends to use GET for operations that don’t need too much parameters and POST for other cases.  Those who really don’t care or who don’t even think about it choose between GET and POST on a random basis or always use POST.REST: The resource request styleI will not explain in detail what REST is, you can read Roy Fielding’s dissertation and The REST cookbook for more details.To make it short and focus on the matter of this post, with a REST API you expose data as resources that you manipulate through HTTP protocol using the right HTTP verb :  The endpoint contains the resource you manipulate.  Many use the CRUD analogy to explain REST requests principles. The HTTP verb indicates what you want to do (Create/Read/Update/Delete) with that resource as defined earlier in this post and by RFC7231 (Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content) and RFC5789 (PATCH Method for HTTP).                                                                                        GET /someresources/anIdPUT /someresources/anId{&quot;anotherdata&quot;:&quot;another value&quot;}  ExamplesHere are some of my CarBoN API requests presented in RPC and REST ways:            Operation      RPC (operation)      REST (resource)                  Signup      POST /signup      POST /persons              Resign      POST /resign      DELETE /persons/1234              Read a person      GET /readPerson?personid=1234      GET /persons/1234              Read a person’s items list      GET /readUsersItemsList?userid=1234      GET /persons/1234/items              Add an item to a person’s list      POST /addItemToUsersItemsList      POST /persons/1234/items              Update an item      POST /modifyItem      PUT /items/456              Delete an item      POST /removeItem?itemId=456      DELETE /items/456      Comparing RPC’s and REST’s requests stylesI’ve selected some items to compare RPC’s and REST’s requests styles:  Beauty  Designability  API definition language  Predictability and semantic  Hypermediability  Cacheability  UsabilityBeautyEven if this item is irrelevant, as beauty is in the eye of the beholder, both styles can produce beautiful API as they can produce ugly ones.            Operation      RPC      REST                  Read a person pretty version      GET /readPerson?personid=1234      GET /persons/1234              Read a person ugly version      GET /rdXbzv01?i=1234      GET /xbzv01/1234      So that’s a draw for this one.DesignabilityIs it easier to design RPC ou REST endpoints?Designing a RPC API may seem easier:  when you have to deal with an existing system as it is generally operation oriented but you’ll have to simplify and clean this vision to expose it.  when you deal mainly with processes and operations (as transform them into REST resources is not always trivial).The design of an RPC API needs the designers to be strict to achieve a consistant API as you do not really have constraints.Designing a REST API may seem easier when you deal mainly with data.But even if in some certain case , designing a REST API seems a little harder than an RPC one, it gives you a frame that let you achieve more easily a consistent API.And in both case you’ll have to deal with naming consistency.Both style have pros and cons depending on the context but I don’t find that one style is more easier to design than the other. As I don’t really see a winner, that’s another draw.API definition languagesYou can perfectly describe both styles with API definition languages like Swagger, RAML or blueprint.So that’s a draw, again.Predictability and semanticWith RPC the semantic relies (mostly) on the endpoint and there are no global shared understanding of its meaning.For example, to delete an item you could have:  GET (or POST) /deleteItem?itemId=456  GET (or POST) /removeIt?itemId=456  GET (or POST) /trash?itemId=456To resign from the service you could have:  POST (or GET) /resign  POST (or GET) /goodbye  POST (or GET) /seeyaWith RPC you rely on your human interpretation of the endpoint’s meaning to understand what it does but you can therefore have a fine human readable description of what is happening when you call this endpoint.With REST the semantic relies (mostly) on the HTTP verb. The verb’s semantic is globally shared. The only way to delete an item is:  DELETE /items/456If a user want to stop using your service, you’ll do this (not so obvious) call:  DELETE /users/1234REST is more predictable than RPC as it relies on the shared semantic of HTTP verbs. You don’t know what happen exactly but you have a general idea of what you do.REST wins (but shortly).HypermediabilityIn both style you end making HTTP request, so there is no problem do design an hypermedia API with any of these styles.This is a draw.CacheabilityI’ve often seen (http) caching used as a killer reason to choose REST over RPC.But after reading HTTP RFCs, I do not agree with this argument (maybe I missed something).Of course if your RPC API only use POST for all requests, caching may be a little tricky to handle (but not impossible).If you use GET and POST wisely, your RPC API will be able to obtain the same level of cacheability as a REST API.This is a draw.UsabilityFrom a developer point of view both styles are using HTTP protocol so there’s basically no difference between RPC and REST request.No difference on the documentation (machine of human readable) level too.This is a draw.Totalling points            Item      Who wins?                  Beauty      Draw              Designability      Draw              API definition language      Draw              Predictability and semantic      REST              Hypermediability      Draw              Cachability      Draw              Usability      Draw      Do REST really wins?REST wins thanks to the predictability and semantic item.So, is the resource approach better than the operation one?No.RPC and REST are only different approaches with pros and cons and both are valueable depending on the context. You can even mix these two approaches in a single API.The context, that’s the key. There are no panacea solution, don’t follow fashion blindly, you always have to think within a context and must be pragmatic when choosing a solution.At least, I know now why I like the resource approach: its predictability and the frame given by the full use of HTTP protocol. What about you?One last word to leave you with food for thought: in this time of advent of functionnal programming, having operation request style could make sense…"
},{
    "id": "91",
    "type": "post",
    "title": "The data, the hypermedia and the documentation",
    "url": "https://apihandyman.io/the-data-the-hypermedia-and-the-documentation/",
    "banner": "https://apihandyman.io/images/the-data-the-hypermedia-and-the-documentation/banner.png",
    "description": "When I look at hypermedia media-types and API definition languages I feel that the frontier between data and documentation is becoming thinner as my knowledge of the API world grows and as the API world evolves.",
    "body": "When I look at hypermedia media-types and API definition languages I feel that the frontier between data and documentation is becoming thinner as my knowledge of the API world grows and as the API world evolves.Some complain that hypermedia APIs are overloaded with useless, redundant, ugly, complex, …  data and/or tend to be hardly readable and/or are inefficient in environments where 1 byte is what separates total failure from awesome success (have you ever feared the E icon on your smartphone when using an app relying on data?) .Others complain that some APIs are not developer/consumer friendly and it’s boring, hard, painful, … to find , when needed, the accurate documentation or information, wether it’s machine or human readable (have you ever feared the enigmatic 1138 error and we will not tell you more message or the cryptic understandableButEnigmaticName field while using an API?).The API inquisition may find all this a bit exaggerated and put you on trial for even thinking about these heretic opinions, but we can’t deny there’s some truth in that.  REST is defined by four interface constraints: identification of resources; manipulation of resources through representations; self-descriptive messages; and, hypermedia as the engine of application state.[…] the messages are self-descriptive and their semantics are visible to intermediaries.Roy Fielding, Architectural Styles andthe Design of Network-based Software ArchitecturesWhen I read that, I understand message = data + hypermedia + documentation but I’ve no clue about what it means concerning the organization of the message.  Documentation is data. Hypermedia is data. All is data. My new motto.Let’s see how data, documentation and hypermedia are intertwined in REST APIs, I sense there’s something to dig in there…API documentationIn the API world there are two types of API:  The good ones: those which have a documentation  The bad ones: those which don’tIn the good API world there are two types of documentations:  Machine readable documentation  Human readable documentationMachine readable documentationNowadays, talking about machine readable API documentation, is talking about API definition language. This post is not intended to be a detailed description and comparison of API definition languages. For more information you may take a look at these Mike Stowe’s and Kin Lane’s posts.The most known are RAML, Swagger and Blueprint. These API definition languages allow you to define and describe:  Endpoints  HTTP verbs you can use on endpoints  Input needed when calling an endpoint with a specific HTTP verb  Output returned when calling an endpoint with a specific HTTP verb  Error handling  Data models used on input and output (to avoid defining multiple times the same resource)  Security  Media-types awaited and returnedNone of them, for now, handles hypermedia APIs definition.By the way, actually many people (like myself some time ago) think that Swagger UI (or equivalent) aka The Swagger is an end in itself, but it’s only a representation of an API’s Swagger definition. You can use API definitions to generate SDK, mocks, server stubs, Postman collections or whatever you wish related to your API’s definition.You may also have heard about another thing called ALPS.  Not Alps, the european mountain range, but ALPS, the Application-Level Profile Semantics created by Mike Amundsen, Leonard Richardson and Mark Foster.  ALPS describes the operations (actions) and data elements of a service. that’s all. that description is the same no matter the designtime tooling, protocol, or message format used. that description is the same whether you are implementing code on the client-side or server-side. Kin Lane, What is ALPSTo be frank, I have not yet fully grasp ALPS, how it differs from RAML, Swagger and Blueprint and all its implications. I’ll have to dig into the IETF draft, discuss with smart people, test via my API crash test and write some post(s) about this.But, for now, I understand that ALPS allows you to describe your data and what you can do with them.It can be used as source material to generate:  Swagger, RAML or Blueprint API definition  Simple CRUD service  The hypermedia meta-data for your hypermedia APII also understand that using ALPS to describe a service, even as a simple specification/contract, on each level (client/server) you ensure that implementation are sharing the same “vision” of the limits of the service.To learn more about ALPS you can read this introduction by Kin Lane and the IETF draft.Putting all these machine readable documentations together we’re able to define and describe:  Data and relations between data  Possible actions on these data  What we need to do these actions  What we get in return  How errors are handled  How consumer and provider could talk to each other (security, data format)Of course nowadays not every API in the world offers this level of completeness in machine readable documentation. And even if this level is reached, there are always a few things, that do not fit in this kind of documentation, to explain to poor humans who have to use your API.Human readable documentationHuman readable documentation takes roughly three forms:  Pretty machine readable documention  Novel documentation  Dark documentationPretty machine readable documentationMachine readable documentation is written by humans and therefore is readable by humans (but not all of them).This kind of documentation can be displayed in a more accessible and visually appealing way with tools like Swagger UI for example.This kind of documentation is not only pretty it’s also smart, it offers users a way of testing the API within its documentation.Novel documentationAPI’s definition is only the Alpha of documentation.The Omega is every single thing you think to explain and that do not fit in API’s definition:  How to connect using Oauth 3.2b3  Throttling limitations (3,5 calls every 56 seconds for bronze users)  How the Cobol/Pascal/Basic sdk works on an Apple ][  …                                      Oops, I did memegenerate Charlton Heston again. I just loved this picture.          You explain these things by writting (ed. and drawing!) plain good old documentation with text, snippets, diagrams… You provide it to users in HTML, PDF, markdown, printed books with rich illuminations or even engraved stones (for gold users only).You can also use tools like API notebook to make this documentation more interactive.Dark documentationDark documentation (in reference to dark matter) is all that’s between the Alpha (pretty machine readable documentation) and the Omega (novel documentation).It’s all the piece of informations we can find in the API designers and developers brains, by contacting the support, searching stackoverflow, reading blog posts or forums.Data and Hypermedia media-types vs documentationAfter documentation comes implementation, what do we get with our data in API’s message? Many things.A good practice when handling error with your API is to give a link pointing to documentation concerning the error (human readable documentation).Some APIs, like PayPal’s, allow developers to choose the level of information they get when there’s an error.When you add the hypermedia dimension (ed. sounds like a sci-fi book or movie title) to your API, you add data that define and describe:  Data and relations between data  Possible actions on these data  What we need to do these actions  What we get in return  How errors are handledAll of this sounds familiar, no? It looks like a lot of what we have with machine readable documentation and a bit a human readable documentation!But there’s more. If documentation describes what could be, hypermedia describes what is. Hypermedia gives you informations based on the context:  The actions that are actually possible in the context  Prefilled links with ids and parameters (or templates to build this links)  Prefilled value for actions                                      Let's do some cool Venn diagram          What I see now is that most of hypermedia data comes from the documentation and even part of the informations based on context could come from the documentation.What else?Here comes the true purpose of this post.The web browsing analogyWhen you browse a website:  Your web client first loads an HTML file /persons/1234/items.html  Then it loads all resources (css, js, images) referenced by this file  It can therefore present you a rendering of all these elements  If you click on a link, the browser loads another HTML file /persons/1235/items.html  But, then it will only load new or modified referenced resources  It can therefore present you faster and with less data a rendering of all these elementsWhen you build a website:  If you want, you could choose to only load the HTML and read it  If you use tools like Firebug you can actually have a complete vision of HTML, css, js and other resources in one placeWhy couldn’t we do all that with hypermedia APIs?Browsing hypermedia APIsWe could apply a separation between concepts when browsing a hypermedia API like we do with HTML:  Your API client first load some data GET /persons/1234/items  Within these data (or in headers) you have a (or some) reference(s) to the machine and human readable documentation  It can therefore build a complete message including all data, hypermedia and documentation  If you make another call GET /persons/1235/items  Within these data (or in headers)  The API client can build a consolidated message including all data, hypermedia and documentation faster as all redundant data has already been loadedLet’s push the enveloppe on this, we could also imagine to modulate the level of enhancement we apply to the data, we could:  have the data alone  add linked resources to hypermedia data  add linked resources to human readable documentation  embed hypermedia data  embed human readable documentationYou may ask: but why would we do all that? We would do that to propose the necessary level of information depending on the context:  A developer wants to discover the API? Let’s put all we have and present it via the ultimate API playground: a hypermedia API browser able to present all these informations (data, hypermedia, human readable documentation) in a cool way  After playing with the API, the developer starts to build an application to consume it. Let’s give then data + hypermedia data + a part of documentation (detailed errors for example)  The application goes on the App Store, we juste give then data + hypermedia  We could also send data only (don’t know why… but why not)To be continuedThis ideal is not yet real but as things evolves around hypermedia APIs I think we could see quickly arisen the tools which will help to create this ideal.Stay tuned, I’ll be back with other posts about this.PS: I had the pleasure to finish this post after #apisberlin birds of a feather where I had the opportunity to talk about this subject with other API nerds. That was great to talk hypermedia with you guys!"
},{
    "id": "92",
    "type": "post",
    "title": "The API crash test project",
    "url": "https://apihandyman.io/the-api-crash-test-project/",
    "banner": "https://apihandyman.io/images/the-api-crash-test-project/banner.png",
    "description": "As I was writing my HAMM and ways of API smartness posts, I wanted more. As I was discussing with smart people about APIs, I wanted ever more. I want to delve deeply into the API ways.",
    "body": "As I was writing my HAMM and ways of API smartness posts, I wanted more.As I was discussing with smart people about APIs, I wanted ever more.I want to delve deeply into the API ways.The API crash test projectMy brain is boiling with ideas and there are so many existing concepts, techniques, best (and bad) practices concerning APIs.For now, I have used some more or less inconsistent fictional examples for my posts and even if my examples are mainly based on what I’ve experiment, I’m not satisfied with that.I want something more practical to try out the things I see and imagine.I want something more clear to make my posts more easier to understand.I want something more concrete to help people understand/choose/find their way(s) in this fascinating/crazy/complex/boiling API world.                                                So, I came up with the concept of API crash test.  An API crash test is a form of constructive testing usually performed to ensure safe design standards in usefulness and usage compatibility for various modes of API designs or related systems and componentsTo realize these crash tests, I will define a concrete product and use it in my posts and experiments to test many API related things.                                      A big fuzzy draft overview of the API crash test project.          The main objective is to work on the designing of (hypermedia) APIs based on this product, but through this project I also want to work on:  Defining a product.  Documenting every aspect of the project for internal (provider) and external use (consumer), for human and machine needs.  Designing software architectures.  Implementing services.  Exposing APIs.  Consuming APIs.  Handling code on demand.  Organizing my work around all this :o).  And probably many other things I’ve not think of at this time.By using a more or less invariant concept, I hope that:  It will be more easy to test new features as I already have a solid existing base (both conceptual and technical) with my past experiments  It will help me compare the results of tests carried out not a the same moment.  It will be more easy to upgrade past tests to handle new features.  The journey of a thousand miles begins with a single step.Lao TzuOf course I cannot define a panacea product able to cover every API related things at first try.I will start with a basic version of this concrete product and make it evolve with my needs.I will share with you all my experiments on this blog and github, the good ones and the bad ones as I believe that we can learn many things from our mistakes (and from others’ mistakes).How will I use it?In my HAMM posts I showed some examples of hypermedia implementations.With the API crash test project, I would have implemented the API based on my product and gives you the hability to test and compare all hypermedia implementations with a system like this:                                                Another example. Let’s say that I want to test some kind of backend as a service or an API framework. I’ll take then my crash test API definition and see how I can implement it with these things.The productWith my wife, we’re serial car boot buyers. We love to roam the countryside to find old things (70’s/80’s toys, books, vinyls, tableware, furnitures).We use shared Evernote notebook and Google sheet to track all the things we buy, list the things we have or we want, and manage our budget. For the last two years I think about an application (and a API) to handle all this, I started and abandonned many times… but with this new project I have a good opportunity to settle this.I’ll give a more complete description of this product in later posts.To somewhere and beyondI need some time to build the basic components of this project so I’ll probably have to write a few post without a concrete usable platform but I’l try at least to use the concepts of my product in my examples. I will write posts about the construction of this platform.I don’t know where all this gonna lead me, but I feel like this is going to be a great journey and I hope you’ll enjoy it too!"
},{
    "id": "93",
    "type": "post",
    "title": "The ways of the API smartness",
    "url": "https://apihandyman.io/the-ways-of-the-api-smartness/",
    "banner": "https://apihandyman.io/images/the-ways-of-the-api-smartness/banner.png",
    "description": "An API must be smart to ensure that consumers will want to use it and remain dumb when they consume it.",
    "body": "An API must be smart to ensure that consumers will want to use it and remain dumb when they consume it.  smartsmɑːt      (of a person) clean, tidy, and well dressed.    (informal) having or showing a quick-witted intelligence.  Whether an API is dark internal, open external or everything in between (cf. Mark O’Neil classification), its provider (both human and application) must take whatever steps to ensure that this API (and everything surrounding it) is smart enough so the consumer (both human and application) do not need to be as skilled as the provider concerning the field of this API or what run behind it to use it.Depending on your API and your needs, you can achieve the API smartness by using some of these ways:  The (other) API way.  The RTCFM way.  The hypster way.  The mad scientist way.  The empathic listening way.Diving into a single of these ways could will take many posts even entire books and maybe movies, and there are probably other ways.I’m myself only at the beginning of this journey to API smartness, I’ll try with this post to give you a glimpse of these ways based on what I have learned and experimented so far.The (other) APl way: Application Pleasant InterfaceIf you follow only one way of the API smartness, this is the way.  Design, mock, test.Iterate until you get something pleasant.API design mantraAn API is designed by humans to expose data to humans building applications and not for applications only.An API is an Application Programming Interface but it should also be an Application Pleasant Interface (other API acronyms) so the humans who build the application consuming this API do not need to struggle to understand it and its data.So, whatever the type of your API, take time to design it.Some directions for this (other) API way:  Aim at least at level 2 of Richardson Maturity Model by using resources and HTTP protocol.  Choose a language  Do not expose your back-office.  Avoid inconsistency by levelling your endpoint, resources and error handling (standardize your API).  Try to stick to best practices like this describe in RESTful Web Services Cookbook or NARWHL.  Avoid cryptic data, for example use human readable codes instead of puzzling integer values or at least give labels corresponding to these codes.  Use API definition/description/modelling language like Swagger, Blueprint or RAML  Mock your API to test it in early stage.The RTCFM way: Read The Consumer Friendly ManualEven if you achieve the (other) API way brilliantly, consumers will probably need a little help to use your API.  To most developers, writing API documentation is nothing short of torture. But to a few of us, it’s a fascinating area. What gets us so excited?Kin Lane, The API Evangelist, Why we write API documentationAPI documentation must be exhaustive and consumer friendly:  Make it human readable: so people using your APIs can actually understand it.  Make it machine readable: so people using your APIs can build clients automatically and in the future Skynet could destroy humanity applications can talk to your API without someone coding.  Use API definition/description/modelling language like Swagger, Blueprint or RAML to help you create both human and machine readable documentation.  Beware to include all aspects of your API. A beautiful Swagger UI or equivalent documentation is sometime not enough, there are other things to document:          How connect to your API.      Rate limits.      Service chaining.        Keep it light, keep it simple. Consumers do not want to read a documentation as long and hard to understand as In search of lost time to use your API and as difficult as The Phenomenology of Spirit:          Use good old diagrams.      Write tutorials.      Give code snippets.        If your documentation is In search of lost time or The Phenomenology of Spirit type, you may have missed something in the API design.The hypster way: HypermediaThis way is a subpath of the (other) API way.  The best definition of hypermediaAdding hypermedia will lead your API to level 3 of Richardson Maturity Model and help consumers to know what they can do with your data on the fly.This way could be considered experimental by some and is the subject of many debates in the API community (read, for example, Mike Stowe’s post concerning objections to HATEOAS).But you really can use it to solve concrete problems for more informations you can read my posts concerning HAMM (Hypermedia API Maturity Model) part I and part II.The mad scientist way: Code on demandAnother subpath of the (other) API way.  The final addition to our constraint set for REST comes from the code-on-demand style of Section 3.5.3 (Figure 5-8). REST allows client functionality to be extended by downloading and executing code in the form of applets or scriptsRoy Fielding,  Architectural Styles and the Design of Network-based Software ArchitecturesMaybe one day you’ll be confronting a problem that even a good combination of (other) API, RTFCM and Hypster ways cannot solve.This day, you should try the Konami code on level 3 of Richardson Maturity Model to gain access the the secret lost level 4: code on demand.This way is highly experimental and I haven’t use it (yet…).You could use it for example to send a “control amount” function to the consumer to validate input on a money transfer locally and avoid some API calls.You can read Mike Stowe’s post about his experiments on this field.The empathic listening wayLast but not least, he empathic listening way.  One Ring Way to rule them all, One Ring Way to find them,One Ring Way to bring them all and in the darkness brightness bind them.J.R.R. Tolkien,  The Lord of the Rings ways of API smartnessThis is the alpha and omega way. Whatever the ways you choose to take, you’ll have to follow this way.  Empathic listening (also called active listening or reflective listening) is a way of listening and responding to another person that improves mutual understanding and trust.It is an essential skill for third parties and disputants alike, as it enables the listener to receive and accurately interpret the speaker’s message, and then provide an appropriate response.Richard Salem, The benefits of empathic listenerYou must listen to consumers because everything cannot be perfect the first time.You’ll have to listen to them, learn from them and then adapt.You’ll also have to listen to you because a provider must be his first own consumer.Another classification?In a nutshell, the ways of API smartness are:  The (other) API way. Design a Application Pleasant Interface for your data.  The RTCFM way. Read The Consumer Friendly Manual. Document all aspects of your API.  The hyptser way. Add Hypermedia to explain what you can do with the API’s data.  The mad scientist way. Use code on demand to lend some of your business intelligence to the consumer.  The empathic listening way. Listen, learn and adapt. The alpha and omega way.                                                Répertoire bibliographique universel, Paul Otlet“Mundaneum Tiräng Karteikaarten” by Zinneke - Own work. Licensed under CC BY-SA 3.0 via Wikimedia Commons.As I was writing this post, I was wondering if these ways could be used for a sort of (meta) classification/evaluation/maturity model of API and API providers including RMM, HAMM and other things… I feel like some sort of Paul Otlet for APIs… I’ll think about it."
},{
    "id": "94",
    "type": "post",
    "title": "Hypermedia API maturity model Series - Part  - Part II – The missing links",
    "url": "https://apihandyman.io/hypermedia-api-maturity-model-part-ii-the-missing-links/",
    "banner": "https://apihandyman.io/images/hypermedia-api-maturity-model-part-ii-the-missing-links/banner.png",
    "description": "Hypermedia is not only a conceptual and philosophical subject of interesting and animate debates among the API community, it’s also a concrete solution we can use to cover concrete needs. In this second part of hypermedia API maturity model (HAMM) series I will talk about my own experience to expose two missing (in my humble opinon) notions in common implementations and include these missing links in an updated version of the HAMM.",
    "body": "Hypermedia is not only a conceptual and philosophical subject of interesting and animate debates among the API community, it’s also a concrete solution we can use to cover concrete needs.In this second part of hypermedia API maturity model (HAMM) series I will talk about my own experience to expose two missing (in my humble opinon) notions in common implementations and include these missing links in an updated version of the HAMM.If you have not read part I you can read it here.Crossing the hypermedia pathHypermedia in general and the concepts described in this post in particular are not only concepts but also concrete solutions to needs that I had to deal with on a project.This project consisted in designing and building an API offering the same functionalities as my company’s web site as a prelude of a complete rewriting of this web site. This was also a first step in the (re)building of our API platform which will be used by all our websites and mobile applications.n.b. This API is, for now, a ninja dark internal API (cf. Mark O’Neil API’s categorization).I wanted to offer a good user experience with our API and in particular to limit business logic implementation in consumers.Based on:  An analysis of the web application and what runs behind it from functionnal and technical point of view  My experience making evolve this web application and its mobile counterpart (which offers less functionnalities)I determined that if I wanted to offer the expected good user experience with this API, I needed some things, among many others, like:  the possibility of activate/deactivate some functionalities on the fly  some kind of habilitations system as          two users can have different rights on the same /resources/ID      one user can have different rights on on two resources of the same type /resources/ID1 and /resources/ID2      two resources /resources/ID1 and /resources/ID2 of the same type may not share the same possibilities (actions)        giving informations about how to chain actions on complex processes  handling different processes on different consumers for the same action (mainly based on security matters)  and most important: being proactive and exhaustive when informing the consumer (and therefore the end user) about the points above.As I was documenting myself about REST APIs, I (re)discovered the notion of hypermedia for REST APIs in Richardson’s Maturity Model.                                      Me, figuring that hypermedia can handle this (re-enactment).          If in the web application, all of these needs are handled (from the user point view) mostly via hypermedia (the user browse from page to page by clicking on links) why wouldn’t we do the same with the API?The missing linksAll those needs can be summarised by:  Inform at runtime about what you can do  Inform at runtime about what you can’t do and why.  Inform at runtime about how to do itThe first item, as seen in part I, is well covered by common hypermedia techniques, but I did not found informations for the two others, they are the missing links.This concepts have not been implemented in reality exactly as described in this post because as I was writting I had new ideas concerning representations of this informations, but the spirit is still the same.What you can’t do and whyAll hypermedia systems I’ve seen so far focus on what you can do. On each resource you get a list of things you can do. But what happens when you can’t do something?There are two common answers to this question:  If it’s impossible to do, it’s not in the list (you can try to do it but you’ll get an error)  If it’s impossible to do, it’s in the list but you’ll get an error when you’ll try to do it (because it’s impossible to do).For many use case, these answers will fit perfectly.But sometimes not.                                                Sometimes it would be better for user experience to explicitly say that a thing is impossible to do before someone actually try to do that thing.Status propertyLet’s take the dummy API described in part I and work with the add photo operation for location resource (still using NARWHL).How it looks like in last post:                                                                                        GET https://api.dummy.com/locations/IDL1                                                                                          {  &quot;_links&quot;:   [    ...     {      &quot;rel&quot;: &quot;https://api.dummy.com/photos/definitions#add&quot;,      &quot;href&quot;: &quot;https://api.dummy.com/photos&quot;,      &quot;method&quot;: &quot;POST&quot;,      &quot;parameters&quot; :      {        &quot;locationId&quot; : &quot;IDL1&quot;,        &quot;url&quot; : &quot;http://example.com/your/photo&quot;       }    }  ],  ...}  Now I add a status property to indicate if the operation is possible or not and explain why if it’s not possible:  The status.usable property indicates if the operation is possible or not.  The status.cause property indicates the origin (details[].name) of the impossibility.  The status.details array contains all the elements used to evaluate status.usable.In this case, the usability is based on two notions: availability and authorization.The operation in unavailable due to maintenance                                                                                        GET https://api.dummy.com/locations/IDL1                                                                                          {  &quot;_links&quot;:   [    ...     {      &quot;rel&quot;: &quot;https://api.dummy.com/photos/definitions#add&quot;,      &quot;href&quot;: &quot;https://api.dummy.com/photos&quot;,      &quot;method&quot;: &quot;POST&quot;,      &quot;parameters&quot; :      {        &quot;locationId&quot; : &quot;IDL1&quot;,        &quot;url&quot; : &quot;http://example.com/your/photo&quot;       },      &quot;status&quot;:       {           &quot;usable&quot;:&quot;false&quot;,           &quot;cause&quot; : &quot;available&quot; ,           &quot;details&quot; :           [               {                   &quot;name&quot;: &quot;available&quot;,                  &quot;value&quot; : &quot;false&quot;                  &quot;reason&quot;: &quot;Temporarly down for programmed maintenance&quot;                  &quot;extraValues&quot;:                   [                       {&quot;name&quot; : &quot;endDate&quot;, &quot;value&quot;: &quot;1426432120002&quot;},                       {&quot;name&quot; : &quot;cause&quot;, &quot;value&quot;: &quot;maintenance&quot;}                   ]              }              {                  &quot;name&quot;: &quot;authorized&quot;,                  &quot;value&quot;: &quot;true&quot;              }          ]       }          }  ],  ...}  The operation in unauthorized for this resource (location)                                                                                        GET https://api.dummy.com/locations/IDL1                                                                                          {  &quot;_links&quot;:   [    ...     {      &quot;rel&quot;: &quot;https://api.dummy.com/photos/definitions#add&quot;,      &quot;href&quot;: &quot;https://api.dummy.com/photos&quot;,      &quot;method&quot;: &quot;POST&quot;,      &quot;parameters&quot; :      {        &quot;locationId&quot; : &quot;IDL1&quot;,        &quot;url&quot; : &quot;http://example.com/your/photo&quot;       },      &quot;status&quot;:       {           &quot;usable&quot;:&quot;false&quot;,           &quot;cause&quot; : &quot;available&quot; ,           &quot;details&quot; :           [               {                   &quot;name&quot;: &quot;available&quot;,                  &quot;value&quot; : &quot;true&quot;              }              {                  &quot;name&quot;: &quot;authorized&quot;,                  &quot;value&quot;: &quot;false&quot;,                  &quot;reason&quot;: &quot;Maximum number of photos reached for this location&quot;,                  &quot;extraValues&quot;:                   [                        {&quot;name&quot; : &quot;cause&quot;, &quot;value&quot;: &quot;locationMaximumNumberOfPhotos&quot;}                   ]              }          ]       }          }  ],  ...}  The operation in unauthorized for the user                                                                                        GET https://api.dummy.com/locations/IDL1                                                                                          {  &quot;_links&quot;:   [    ...     {      &quot;rel&quot;: &quot;https://api.dummy.com/photos/definitions#add&quot;,      &quot;href&quot;: &quot;https://api.dummy.com/photos&quot;,      &quot;method&quot;: &quot;POST&quot;,      &quot;parameters&quot; :      {        &quot;locationId&quot; : &quot;IDL1&quot;,        &quot;url&quot; : &quot;http://example.com/your/photo&quot;       },      &quot;status&quot;:       {           &quot;usable&quot;:&quot;false&quot;,           &quot;cause&quot; : &quot;available&quot; ,           &quot;details&quot; :           [               {                   &quot;name&quot;: &quot;available&quot;,                  &quot;value&quot; : &quot;true&quot;              }              {                  &quot;name&quot;: &quot;authorized&quot;,                  &quot;value&quot;: &quot;false&quot;,                  &quot;reason&quot;: &quot;Daily maximum upload volume reached for this user&quot;,                  &quot;extraValues&quot;:                   [                        {&quot;name&quot; : &quot;cause&quot;, &quot;value&quot;: &quot;userDailyMaximumUpload&quot;}                    ]              }          ]       }          }  ],  ...}  Everything is OK                                                                                        GET https://api.dummy.com/locations/IDL1                                                                                          {  &quot;_links&quot;:   [    ...     {      &quot;rel&quot;: &quot;https://api.dummy.com/photos/definitions#add&quot;,      &quot;href&quot;: &quot;https://api.dummy.com/photos&quot;,      &quot;method&quot;: &quot;POST&quot;,      &quot;parameters&quot; :      {        &quot;locationId&quot; : &quot;IDL1&quot;,        &quot;url&quot; : &quot;http://example.com/your/photo&quot;       },      &quot;status&quot;:       {           &quot;usable&quot;:&quot;true&quot;,            &quot;details&quot; :           [               {                   &quot;name&quot;: &quot;available&quot;,                  &quot;value&quot; : &quot;true&quot;              }              {                  &quot;name&quot;: &quot;authorized&quot;,                  &quot;value&quot;: &quot;true&quot;              }          ]       }          }  ],  ...}  How you do thingsActual techniques for hypermedia implementation I’ve seen for now can tell you what actions you can do with a resource and what you need to do it but sometimes you need more information for processes involving more than one action.                                      Djiloriann manual, www.collegehumor.com          For example, when you use Twitter API, if you want to tweet with one media you have to  upload a media using POST media/upload (you’ll get an ID in return)  then tweet using POST update/statuses with this ID in media_ids attributeThis is cleary explain in the documentation, but what about machine readability? For machine readibility an evolution of swagger or blueprint or RAML could handle this but what if this process could change depending on the consumer/user/whatever rule you want?You need information at runtime about this.The process propertyThe process property describes how actions are chained and what is next step:  process.type: the name of the process  process.step: the next step  process.steps: lists all steps of the processLet’s see what we can do with the media tweet case.First we get the tweetWithMedia actionThis action could placed be in _links property of GET https://api.twitter.com/1.1/.                                                                                        {  &quot;_links&quot;:   [    ...     {      &quot;process&quot; :       {          &quot;type&quot;: &quot;tweetWithMedia&quot;,          &quot;step&quot;: &quot;uploadMedia&quot;,          &quot;steps&quot; : [ &quot;uploadMedia&quot;, &quot;updateStatus&quot;]      },      &quot;href&quot;: &quot;https://twitter.com/1.1/media/upload.json&quot;,      &quot;method&quot;: &quot;POST&quot;,      &quot;parameters&quot; :      {        ...       },    }  ],  ...}  We get a first step: we have to upload a media.So we do the POST https://api.twitter.com/1.1/media/upload.json                                                                                        {  &quot;_links&quot;:   [    ...     {      &quot;process&quot; :       {          &quot;type&quot;: &quot;tweetWithMedia&quot;,          &quot;step&quot;: &quot;updateStatus&quot;,          &quot;steps&quot; : [ &quot;uploadMedia&quot;, &quot;updateStatus&quot;]      },      &quot;href&quot;: &quot;https://api.twitter.com/1.1/statuses/update.json&quot;,      &quot;method&quot;: &quot;POST&quot;,      &quot;parameters&quot; :      {        &quot;media_ids&quot;: &quot;1234567890123456789&quot;,        ...       },    }  ],  ...}  In return we get the next step updateStatus for process tweetWithMedia with property media_ids containing the id of the uploaded media.So finally, we do POST https://api.twitter.com/1.1/statuses/update.jsonThis is the last step, process tweetWithMedia is over so it’s not present anymore in _links.I’m not really satisfied with that implementation of the *how you do it item but the spirit is here.*Hypermedia API maturity model v1.0.0-alpha-2It’s now time to update HAMM with these two new items and find a way to handle Collection+JSON that would not fit in v1.0.0-alpha-1 version.With this update, HAMM consists now in 5 characteristics, each one gets a score:  Where you can go, score 1 (00001)  What you can do, score 2 (00010)  What you need to do things, score 4 (00100)  What you can’t do and why, score 8 (01000)  How you do things, score 16 (10000)You get the level of hypermedianess by adding the scores of the characteristics you comply with.You can also decode a level to know what are its characteristics.With systems referenced in previous post we have:  JSON-LD, HAL, jsonapi.org: level 1 (where you can go)  Collection+JSON: level 5 (where you can go + what you need to do things)  Siren, JSON-LD+Hydra and NARWHL: level 11 (where you can go, what you can do, what you need to do things)This is the end?This is it for now about the HAMM version 1.0.0.alpha-2, this is still a work in progress I’ll write other posts about this later.Thank you for reading, I hope it’s not over complicated. I’m really looking forward to your comments here or on Twitter about all this. Does anybody encounter the same needs? What do you think about HAMM? Did I miss something in common hypermedia systems?"
},{
    "id": "95",
    "type": "post",
    "title": "Hypermedia API maturity model Series - Part  - Part I - Hypermedia-ness",
    "url": "https://apihandyman.io/hypermedia-api-maturity-model-part-i-hypermedia-ness/",
    "banner": "https://apihandyman.io/images/hypermedia-api-maturity-model-part-i-hypermedia-ness/banner.png",
    "description": "When we talk about hypermedia for an API, we’re talking about making it discoverable or browsable. Adding hypermedia to an API potentially brings flexibility, loose coupling, better human readability on the fly and even machine readability on the fly. But nowadays, the hypermedia area for APIs is still a work in progress and it can be implemented in many ways leading to different levels of hypermedia-ness.",
    "body": "When we talk about hypermedia for an API, we’re talking about making it discoverable or browsable. Adding hypermedia to an API potentially brings flexibility, loose coupling, better human readability on the fly and even machine readability on the fly. But nowadays, the hypermedia area for APIs is still a work in progress and it can be implemented in many ways leading to different levels of hypermedia-ness.Hypermedia API maturity model v1.0.0-alpha.1Leonard Richardson described a phased approach of REST API known as Richardson Maturity Model (RMM, Martin Fowler wrote a great post to explain it). This model ends with level 3, hypermedia controls, where it deals with hypermedia API.I tried to build a hypermedia API maturity model to evaluate the level of hypermedia-ness of an API. This model is based on current techniques and systems commonly described (and sometime used) to implement REST/JSON hypermedia APIs.Level 0: RTFMOn level 0, an API do not implement hypermedia (such an API is RMM level &lt; 3).If you want to know how resources are linked and what you can do with them, you’ll have to read the documentation.Let’s take a dummy non-hypermedia API dealing with locations and photos as an example for next levels. This API allows you to:  Get a specific location details                                                                                        GET https://api.dummy.com/locations/IDL1                                                                                          {  &quot;id&quot;: &quot;IDL1&quot;,   &quot;name&quot;:&quot;a location&quot;}    Add a photo to a location                                                                                        POST https://api.dummy.com/photos                                                                                          {  &quot;locationId&quot;: &quot;IDL1&quot;,  &quot;url&quot;: &quot;http://im.gur/myphoto&quot;}    Get photos for a location                                                                                        GET https://api.dummy.com/locations/IDL1/photos                                                                                          [ {&quot;id&quot;: &quot;IDP1&quot;},  {&quot;id&quot;: &quot;IDP2&quot;}, ...,  {&quot;id&quot;: &quot;IDPn&quot;}]    Get a specific photo details                                                                                        GET https://api.dummy.com/photos/IDP1                                                                                          {  &quot;id&quot;: &quot;IDP1&quot;,   &quot;locationId&quot;: &quot;IDL1&quot;,  &quot;url&quot;: &quot;https://media.dummy.com/xlvc265z&quot;}    Delete a specific photo                                                                                        DELETE https://api.dummy.com/photos/IDP1  Level 1: Where you can goOn level 1, you define relations/links between your resources. You can do this by using:  JSON-LD  HAL  jsonapi.orgLet’s see what we can do using jsonapi.org on our dummy API:  Get a specific location details                                                                                        GET https://api.dummy.com/locations/IDL1                                                                                          {  &quot;links&quot;: { &quot;self&quot;: &quot;https://api.dummy.com/locations/IDL1&quot;},  &quot;linked&quot;:[    {     &quot;type&quot;: &quot;photos&quot;,     &quot;links&quot;: { &quot;self&quot;: &quot;https://api.dummy.com/locations/IDL1/photos&quot;}   }  ],  &quot;id&quot;: &quot;IDL1&quot;,  &quot;name&quot;: &quot;a location&quot;}    Get photos for a location                                                                                        GET https://api.dummy.com/locations/IDL1/photos                                                                                          {  &quot;links&quot; :   {    &quot;self&quot;:&quot;https://api.dummy.com/locations/IDL1/photos&quot;,    &quot;next&quot;:&quot;https://api.dummy.com/locations/IDL1/photos?page=2&quot;   },  &quot;data&quot;:  [     {      &quot;links&quot; : { &quot;self&quot;: &quot;https://api.dummy.com/photos/IDP1&quot; },      &quot;id&quot;: &quot;IDP1&quot;    }, ...  ]}    Get a specific photo details                                                                                        GET https://api.dummy.com/photos/IDP1                                                                                          {  &quot;links&quot;: { &quot;self&quot;: &quot;https://api.dummy.com/photos/IDP1&quot;},  &quot;linked&quot;:  [    {      &quot;type&quot;: &quot;location&quot;,      &quot;links&quot;: { &quot;self&quot;: &quot;https://api.dummy.com/locations/IDL1&quot;}    }  ],  &quot;id&quot;: &quot;IDP1&quot;,  &quot;locationId&quot;: &quot;IDL1&quot;,  &quot;url&quot;: &quot;https://media.dummy.com/xlvc265z&quot;}  As you can see we have added links (URL related to primary data)  and linked (linked resources) values to existing data. These new data:  Make the API browsing easier.  Allow to see the relations between locations and photos.  Bring a potential flexibility as you can modify the provided links without impacting the consumers hoping those consumers use the provided links…But there’s no clue concerning adding or deleting a photo. You’ll still have to read documentation to find informations about these operations.Level 2: What you can doOn level 2, you add HTTP methods and description to the links to explicitly tell what you can do. You can do this using:  NARWHL  JSON-LD+Hydra  SirenLet’s see how it looks with NARWHL:  Get a specific location details                                                                                        GET https://api.dummy.com/locations/IDL1                                                                                          {  &quot;_links&quot;:  [    {         &quot;rel&quot;: &quot;self&quot;,      &quot;href&quot;: &quot;https://api.dummy.com/locations/IDL1&quot;,      &quot;method&quot;: &quot;GET&quot;    },    {      &quot;rel&quot;: &quot;https://api.dummy.com/photos/definitions&quot;,      &quot;href&quot;: &quot;https://api.dummy.com/locations/IDL1/photos&quot;,      &quot;method&quot;: &quot;GET&quot;    },     {       &quot;rel&quot;: &quot;https://api.dummy.com/photos/definitions#add&quot;,       &quot;href&quot;: &quot;https://api.dummy.com/photos&quot;,       &quot;method&quot;: &quot;POST&quot;    }  ],  &quot;id&quot;: &quot;IDL1&quot;,  &quot;name&quot;: &quot;a location&quot;}    Get photos for a location                                                                                        GET https://api.dummy.com/locations/IDL1/photos                                                                                          {  &quot;_links&quot;:  [    {          &quot;rel&quot;:&quot;self&quot;,      &quot;href&quot;:&quot;https://api.dummy.com/locations/IDL1/photos&quot;,      &quot;method&quot;: &quot;GET&quot;    },    {      &quot;rel&quot;: &quot;next&quot;,      &quot;href&quot;:&quot;https://api.dummy.com/locations/IDL1/photos?page=2&quot;,      &quot;method&quot;: &quot;GET&quot;    },     {      &quot;rel&quot;: &quot;https://api.dummy.com/photos/definitions#add&quot;,      &quot;href&quot;: &quot;https://api.dummy.com/photos&quot;,      &quot;method&quot;: &quot;POST&quot;    }  ],  &quot;data&quot;:   [    {      &quot;_links&quot;:      [        {          &quot;rel&quot; : &quot;self&quot;,          &quot;href&quot; : &quot;https://api.dummy.com/photos/IDP1&quot;,          &quot;method&quot; : &quot;GET&quot;        }         ],      &quot;id&quot;: &quot;IDP1&quot;    }, ...  ]}    Get a specific photo details                                                                                        GET https://api.dummy.com/photos/IDP1                                                                                          {   &quot;_links&quot;:  [    {      &quot;rel&quot;: &quot;self&quot;,      &quot;href&quot;: &quot;https://api.dummy.com/photos/IDP1&quot;,      &quot;method&quot; : &quot;GET&quot;    },    {      &quot;rel&quot;: &quot;https://api.dummy.com/locations/definition&quot;,      &quot;href&quot;: &quot;https://api.dummy.com/locations/IDL1&quot;,      &quot;method&quot;: &quot;GET&quot;    },    {      &quot;rel&quot; : &quot;https://api.dummy.com/photos/definitions#delete&quot;,      &quot;href&quot; : &quot;https://api.dummy.com/photos/IDP1&quot;,      &quot;method&quot; : &quot;DELETE&quot;    }  ],  &quot;id&quot;: &quot;IDP1&quot;,  &quot;locationId&quot;: &quot;IDL1&quot;,  &quot;url&quot;: &quot;https://media.dummy.com/xlvc265z&quot;}  With NARWHL, all links are defined within _links values and for each of them you explicitly define the HTTP method to use with the method value.I have to admit that I prefer the more explicits concepts of class or type brought by Siren or Hydra to describe the action/operation you can do instead of the rel value based on IANA relation types (I probably miss something about this).However you represent these informations (action description, href, method):  You explicitly know on this level all you can do on the fly. You can fully browse this API as the add and delete photos operations are now explicitely handled.  The potential flexibility for the consumers concerns now every possible action within the API (hoping again the consumers really use the provided links…).But you still need documentation for the add photo operation as there’s no information concerning the expected inputs.Level 3: What you need to do itOn level 3, you add a full description (and maybe some values) of the needed inputs for an action. You can generally do this by using the same systems as on level 2:  NARWHL  JSON-LD+Hydra  Siren  Collection+JSONLet’s see how NARWHL handle this on the “add photo” operation:                                                                                        GET https://api.dummy.com/locations/IDL1                                                                                          {  &quot;_links&quot;:   [    {         &quot;rel&quot;:&quot;self&quot;,      &quot;href&quot;:&quot;https://api.dummy.com/locations/IDL1&quot;,      &quot;method&quot;: &quot;GET&quot;    },    {      &quot;rel&quot;: &quot;https://api.dummy.com/photos/definitions&quot;,      &quot;href&quot;: &quot;https://api.dummy.com/locations/IDL1/photos&quot;,      &quot;method&quot;: &quot;GET&quot;    },     {      &quot;rel&quot;: &quot;https://api.dummy.com/photos/definitions#add&quot;,      &quot;href&quot;: &quot;https://api.dummy.com/photos&quot;,      &quot;method&quot;: &quot;POST&quot;,      &quot;parameters&quot; :      {        &quot;locationId&quot; : &quot;IDL1&quot;,        &quot;url&quot; : &quot;http://example.com/your/photo&quot;       }    }  ],  &quot;id&quot;: &quot;IDL1&quot;,  &quot;name&quot;: &quot;a location&quot;}  With NARWHL, by adding parameters value you give a description (and some default values) of the needed inputs for the operations.Collection+JSON, Siren and Hydra use a more precise way of describing these inputs. You can see more examples using HAL, JSON-LD, Hydra, Collection+JSON and Siren in Kevin Sookocheff’s post comparing some hypermedia systems. As Kevin’s post do not talk about NARWHL and jsonapi.org I have focused this post’s examples on these ones.Whatever, with this last level we have action/operation descriptions, href, method and input description: we known exactly what we can do and how to do it on the fly.Hypermedia API maturity model v1.0.0-alpha.1 in 4 lines  Level 0: RTFM.  Level 1: Where you can go.  Level 2: What you can do.  Level 3: What you need to do it.Frequently asked questionsWhen you start defining or classifying things, some people tends to overreact, arguing over which level is better than the other, what is the perfect way of doing things, counting how many API evangelists can stand on the header of a GET request and then they start wearing funny costumes and act in utterly surreal stupid way to boldly defend a so-called truth…                                                  My friends/colleagues/parents are yelling at each other about “is hypermedia evil or not?”. Should I call the API inquisition to settle this conflict?No, tell them to read this API Evangelist’s post instead.If they are still yelling at each other after that, you can call the API inquisition.  My API is level 0.Will the API inquisition come and put me on trial?No, implementing hypermedia in your API is definitely not an obligation.Hypermedia should be implemented only if a real need is covered by it.And don’t be scared, hypermedia can be added later to your existing API when needed.  My API is only level 1 or 2.Will the API inquisition come put me on trial?No, implementing hypermedia in your API must cover a real need.If you’re satisfied with level 1 or 2 it’s OK, and you can evolve to a higher level later.  My API is level 3.Will I be praised to the skies?If you have implemented it to cover a real need, maybe.If it’s just a show off and you don’t know what to do with it, the API inquisition will come and put you on trial.  It seems that Collection+JSON do not fit completely in this model.Did I miss something?That’s right Collection+JSON does not fit exactly in my model’s progression system because the templating mechanism puts it on level 3 but it does not explicitly define what HTTP method you can use (so it’s not level 2).I think I will settle this problem on my next post by transforming the progression system into a multiclass system (like in Dungeons &amp; Dragons) hoping the API inquisition will not come and put me on trial for that.To be continued…Now I’m able to evaluate the level of hypermedia-ness of an API based on common systems/techniques but this is only the tip of the hypermedia iceberg. The main point of hypermedia is finally not how you will implement it and what level of hypermedia-ness you achieve, but for what purpose you will implement it.In next post Hypermedia API maturity model - Part II - The missing links, I’ll explain why I have crossed the path hypermedia API, what is missing in actual systems/techniques to fulfil all my needs and propose a revised version of this hypermedia API maturity model based on all this (mess).Images credits:  Southbound lane on Jianguo Rd Exit of Kaohsuing IC on the Taiwan No2 National Highway, Howard61313.  The spanish inquisition, The Monty Python"
},{
    "id": "96",
    "type": "post",
    "title": "The beautiful API and the bestial back-office",
    "url": "https://apihandyman.io/the-beautiful-api-and-the-bestial-back-office/",
    "banner": "https://apihandyman.io/images/the-beautiful-api-and-the-bestial-back-office/banner.png",
    "description": "When you design an API (even an internal/private one) upon an existing back office (to plug a mobile application on it for example), you should take care of one thing: an API is a display, not a window. An API’s purpose is to expose your data and data processing but an API is only a representation and you’re under no obligation to directly expose the crude reality.",
    "body": "When you design an API (even an internal/private one) upon an existing back office (to plug a mobile application on it for example), you should take care of one thing: an API is a display, not a window.An API’s purpose is to expose your data and data processing but an API is only a representation and you’re under no obligation to directly expose the crude reality.  What happens in Vegas back office stays in Vegas back office(famous tag line)This is even more true if you have a bestial back-office. It’s definitely not a good idea to expose it as it is, you really must hide it behind a beautiful API. It might even brings unexpected benefits.Disclaimer: The events depicted in this post are fictitious. Any similarity to any person or software living or dead is merely coincidental. All inappropriate expressions have been replaced by fonz words. No toys were harmed during the making of this post.A bestial back officeYou own coolvintageornottoys.com the famous cool vintage-or-not toys database and exchange platform.This website consists of some kind of a more or less monolithic web application plugged on some kind of service oriented architecture.How your data and the way you process them look like is the result of years of evolution in a close environment leading to a functional but maybe complex system including some fancy things like these…                                                                                                                                                                                                                                                                                                                                                … functional but maybe complex system, that’s a pretty euphemism.The window: a bestial APIYou think it’s time to have a cool mobile application.You’ve read some things about this and it seems that a mobile application needs an API, so you decide to build one.This is a very good idea…                                                                                                … but not this way.Exposing your back-office as it is may sound a simple, quick and cheap way to create an API (for those who have think about it a little before starting coding…) especially for a private/internal API, but this is a very short term strategy.In fact, in the end it will reveal complex, you will spend a lot of time, a lot of money and gain absolutely nothing:  Your API will reflect perfectly your bestial back-office and nobody outside of your company will understand it and be able to use it (and probably inside too…).  The development of your mobile application will be a nightmare. The guys you will hire to develop it will screw up because they will not understand how does this fonzing API works and because they will have to re-code in the application what should be back-office business logic.  You will not be ready for other consumers. What had happened for your mobile application will happen again and again with all other consumers of your API.  You will face high cross-maintenance costs as all your API consumers include heavy business logic.  Opening your API will be useless (because nobody will be able to use it) and potentially dangerous (if your system’s integrity relies on the consumer).  Your back-office will not gain anything in the process.The display: a beautiful APIExposing your back-office as it is is definitely not a good idea, but you may ask if it is really possible to create a beautiful API upon all this mess. The answer is yes.I will not detail fully the designing of such an API and how to plug it on your existing back office. There are many ways to do this and many posts to write about these things and this is not the point of this post.A montage will show you a quick overview of one way of doing it to help the understanding of the potentials unexpected benefits of building a beautiful API to hide your bestial back-office.Beautiful API design and implementation montage starts.To design a beautiful API offering the same functionalities as your website for your mobile application, you could:  Lists your web site functions and data.  Rationalize and simplify those functions and data.  Define rules for your API (data naming, data format, URI definition, HTTP method usage, error handling, …). You could use some things like Rob Zazueta’s NARWHL or Steve Klabnick and Yehuda Katz json:api.  Design your API based on these refined data, functions and new rules.Then you could plug your newly design beautiful API to your bestial back office by:  Mapping your API to back-office functions/services.  Extracting business logic from your web application if necessary.  Refactoring some services (aggregation, web application business logic integration, …). It would be a good idea to define rules for your new components (you may reuse some rules defined for your API).  Using a service mediation layer and/or gang of 4 facade pattern to adapt services interfaces.Beautiful API design and implementation montage ends.And now that you have a beautiful API in front of your bestial back office, there are obvious benefits brought by the API itself:  Your API is not only beautiful but it is understandable, usable and reusable by anyone.  The creation of your mobile application will be fast and easy.  You’re ready for whatever comes next (opening your API, new consumers, …).An happy endingBut what about the unexpected benefits?  Beast was disappeared, and she saw, at her feet, one of the loveliest princes that eye ever beheld(The beauty and the beast, Jeanne-Marie LePrince de Beaumont)Like in the fairy tale, the beautiful API has improved the bestial back-office:  You have a rationalized vision of your back-office that will help you for future evolutions or refactoring.  Some parts of your back-office may have been (beautifully) refactored in the process.  Some lost knowledge may have been rediscovered.  You have defined rules (naming, format, error handling, …) you could apply to all your new back office components.  What about a web site refactoring to plug it to your new API and minimize business logic cross maintenance?  His subjects received him with joy; he married Beauty, and lived with her many years; and their happiness, as it was founded on virtue, was complete.The end.(The beauty and the beast, Jeanne-Marie LePrince de Beaumont)This is not a fairy tale, it’s reality. Building an API can really help you improve your back-office.And whatever the case an API must be beautiful (or fear the wrath of your consumers and API believers).I know, beauty is in the eye of the beholder, but that’s a subject for another post…"
},{
    "id": "97",
    "type": "post",
    "title": "Why you must design your private API in english",
    "url": "https://apihandyman.io/why-you-must-design-your-private-api-in-english/",
    "banner": "https://apihandyman.io/images/why-you-must-design-your-private-api-in-english/banner.png",
    "description": "Why you must design your private API in english. Pourquoi vous devez concevoir votre API privée en anglais. Perché è necessario progettare la vostra API privata in inglese. Por qué debe diseñar su API privada en Inglés. Deshalb müssen Sie Ihre private API in Englisch entwerfen. なぜあなたは英語であなたのプライベートAPIを設計する必要があります. As you might have guess, this post targets people designing APIs in non english speaking countries. When you design an API there are many little things that you risk to forget or not take into account, especially when this API is private/internal, and later you may bitterly regret it. Choosing a language for your API is one of them.",
    "body": "  Why you must design your private API in english.Pourquoi vous devez concevoir votre API privée en anglais.Perché è necessario progettare la vostra API privata in inglese.Por qué debe diseñar su API privada en Inglés.Deshalb müssen Sie Ihre private API in Englisch entwerfen.なぜあなたは英語であなたのプライベートAPIを設計する必要があります.As you might have guess, this post targets people designing APIs in non english speaking countries.When you design an API there are many little things that you risk to forget or not take into account, especially when this API is private/internal, and later you may bitterly regret it.Choosing a language for your API is one of them.The eNut projectYou work for Complètement Noix Cie (Totally Nut Co) a small family nutgrowing company in France.This company launches the project eNoix (eNut) based on patent US 2427486 A which will cut nuts collection costs by 300%.You have to design a private API to control and monitor this totally awesome device. You’ll have to deal with nuts, squirrels and …. Wait! Stop!Before designing anything you have to choose a language for your API.Choosing a language to design an API?I’m not talking about internationalization or choosing a programming language …I’m talking about choosing a human language for the interface: english, french, italian, spanish, german, japanese…  Jean-Philippe wants to get a list of squirrels, how does he get it?GET /squirrelsGET /ecureuilsGET /scoiattoliGET /ardillasGET /eichhornchenGET /リスThe choice should be quite simple because this should be a single-choice question instead of a multiple-choice question.The only possible response should be english.The only possible response IS english.  But this API is private and will only be used by squirrels or us or people understanding our language. Why should we care to design it in english instead of (whatever language you speak)?(me some time ago, I could just kick myself)There are two reasons rhyming with “ization”: standardization and externalization.Follow the standards  Stop building super custom APIs.(Steve Klabnick, API Days Paris 2014)Even if your API is private, it must be standard, the more your conform to standards the more your API is simple to design and to use.In IT field, standard generally means english.You could for example want to:  use {json:api} format which define some attributes in english.  use schema.org schemas for some of your data. Everything is in english.  use Hydra to build a powerful hypermedia API (and use automatic tools to create a console for your API), english attributes again.  integrate other APIs with yours. These APIs will probably be in english (for example the famous Poké API). Depending on the integration level, the combination of two APIs using different languages might  be weird and hard to understand.And even if now you don’t need any of these english things, you may need one someday.Using a language other than english for your API might complicate its design and evolution when you want to integrate existing things and lead to a too-much-custom-two-languages API.Too much custom APIs are hard to understand and use so imagine one with two languages.Assume that your API will not be private forever  Anyone who doesn’t do this will be fired.(Jeff Bezos, about service interface externalization and other things)When you create an API you must always design it as it will be externalized, exposed to the outside world (read this post from API Evangelist about Amazon’s internal APIs).  You may need developers outside of your company to build the application which will consume it on the eNoix (iNut) device          They can be foreigner and not speak your language (try to explain a french API to indian developers…).      Even if they speak your language, they may have problems understanding your too-much-custom-two-languages API.        You may work for a small entity in a big multinational group, your API may be used or taken as a model by other entities and/or in other countries.  You may want to show what you have done to the world because it’s cool.  And because it’s cool, everybody wants to use it, so you want to open it.The success of this externalization may be tempered by your non-english API.API design’s commandment  English shalt be the language thou use to design an API, and the language of the API designing shalt be english.(Book of Armaments API Design)But even if you design your API in english, you can at least write documentation in your language… and in english.If my poor argumentation do not convince you to design your API in english, I hope that at least you will choose a language for your API in full knowledge of the facts and not build your API without thinking about it.If someone has a really good reason to not design an API in english (or others good reasons to design in english), let me know, I’ll be happy to discuss on this subject.Image credit: The tower of Babel, Peter Bruegel."
},{
    "id": "98",
    "type": "post",
    "title": "Hello World!",
    "url": "https://apihandyman.io/hello-world/",
    "banner": "https://apihandyman.io/images/commons/mask-home-banner.jpg",
    "description": "Welcome to the API Handyman blog! You can read a more complete presentation of the API Handyman blog here. The API Handyman blog is about sharing my views and experiences on the API field from both provider and consumer points of view with (I hope) a pragmatic and unvarnished approach. I hope you’ll enjoy reading my posts and I’m looking forward to your feedback and comments.",
    "body": "Welcome to the API Handyman blog!You can read a more complete presentation of the API Handyman blog here.The API Handyman blog is about sharing my views and experiences on the API field from both provider and consumer points of view with (I hope) a pragmatic and unvarnished approach.I hope you’ll enjoy reading my posts and I’m looking forward to your feedback and comments."
}]